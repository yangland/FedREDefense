{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "cos = nn.CosineSimilarity(dim=0, eps=1e-9)\n",
    "from torchvision import transforms\n",
    "# from codes.models import ConvNet, resnet8, MLP\n",
    "from utils import *\n",
    "from torch.utils.data import DataLoader\n",
    "from models import *\n",
    "import random\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "device = \"cuda\"\n",
    "\n",
    "# adjustable parameters\n",
    "alpha_d = 10\n",
    "local_ep = 5\n",
    "mali_local_ep = 20\n",
    "points = 41\n",
    "global attack \n",
    "attack = \"backdoor\" #\"backdoor\", \"tlp\"\n",
    "model_name = \"resnet8\" # \"resnet8\", \"ConvNet\"\n",
    "num_classes = 10\n",
    "dataset =\"fmnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_delta_cos(model1, model2, model0_sd):\n",
    "    flat_model0 = flat_dict(model0_sd)\n",
    "    flat_model1 = flat_dict(model1.state_dict())\n",
    "    flat_model2 = flat_dict(model2.state_dict())\n",
    "    \n",
    "    delta = torch.abs(flat_model1 - flat_model2)\n",
    "    org_cos = cos((flat_model1 - flat_model0), (flat_model2 - flat_model0))\n",
    "    return delta, 1-org_cos.item()\n",
    "\n",
    "def model_eval(model, test_loader, attack):\n",
    "    acc = eval_op_ensemble([model], test_loader)\n",
    "    if attack == \"tlp\":\n",
    "        asr = eval_op_ensemble_tr_lf_attack([model], test_loader)\n",
    "    elif attack == \"backdoor\":\n",
    "        asr = eval_op_ensemble_attack([model], test_loader)\n",
    "    return list(acc.values())[0], list(asr.values())[0]\n",
    "\n",
    "\n",
    "def sample_and_replace(model1, model2, model3, k_percent):\n",
    "    \"\"\"\n",
    "    Randomly selects k% of parameters within each layer from model2 and replaces them in model1.\n",
    "    Returns a new model (model3) with mixed parameters and a dictionary of replaced indices.\n",
    "    \"\"\"\n",
    "    model_1_sd = {key: value.clone() for key, value in model1.state_dict().items()}\n",
    "    model3.load_state_dict(model_1_sd)  # Start with model1's parameters\n",
    "    replaced_params = {}\n",
    "    \n",
    "    state_dict = model3.state_dict()\n",
    "    for param_name in model1.state_dict().keys():\n",
    "        param1 = model1.state_dict()[param_name].clone()\n",
    "        param2 = model2.state_dict()[param_name].clone()\n",
    "        num_elements = param1.numel()\n",
    "        num_replace = int((k_percent / 100) * num_elements)\n",
    "        \n",
    "        if num_replace > 0:\n",
    "            indices = random.sample(range(num_elements), num_replace)\n",
    "            param1.view(-1)[indices] = param2.view(-1)[indices]\n",
    "            param1_flat = param1.view(-1)\n",
    "            param2_flat = param2.view(-1)\n",
    "            param1_flat[indices] = param2_flat[indices]\n",
    "            state_dict[param_name] = param1.view(param1.shape)\n",
    "            replaced_params[param_name] = indices\n",
    "    \n",
    "    model3.load_state_dict(state_dict)\n",
    "    return model3, replaced_params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sampling_experiment(model1, model2, model3, model0_sd, main_dataloader, device, k_percent, p):\n",
    "    \"\"\"\n",
    "    Runs p sampling experiments, evaluates model3 on both main and side tasks.\n",
    "    \"\"\"\n",
    "    model_1_sd = {key: value.clone() for key, value in model1.state_dict().items()}\n",
    "    \n",
    "    results = {}\n",
    "    replaced_params_list=[]\n",
    "    for i in range(p):    \n",
    "        model3.load_state_dict(model_1_sd)\n",
    "        model3, replaced_params = sample_and_replace(model1, model2, model3, k_percent)\n",
    "        acc_, asr_  = model_eval(model3, main_dataloader, attack)\n",
    "        delta, cos_dist = get_delta_cos(model1, model3, model0_sd)\n",
    "        results[i] = (acc_, asr_, cos_dist)\n",
    "        replaced_params_list.append({asr_:  replaced_params})\n",
    "    return results, replaced_params_list, model3\n",
    "\n",
    "\n",
    "def replaced_params_count(replaced_params_list):\n",
    "    \"\"\"\n",
    "    Counts occurrences of values per layer across multiple replaced_params dictionaries.\n",
    "\n",
    "    :param replaced_params_list: List of replaced_params dictionaries.\n",
    "    :return: Dictionary where keys are layer names and values are Counters of occurrences.\n",
    "    \"\"\"\n",
    "    layer_counts = {}\n",
    "\n",
    "    for replaced_params in replaced_params_list:\n",
    "        for layer, values in replaced_params.items():\n",
    "            if layer not in layer_counts:\n",
    "                layer_counts[layer] = Counter()\n",
    "            layer_counts[layer].update(values)\n",
    "\n",
    "    return layer_counts\n",
    "\n",
    "\n",
    "def convert_to_state_dict(layer_counts, state_dict):\n",
    "    ind_w = OrderedDict()\n",
    "    \n",
    "    # Iterate over the outer dictionary (float keys)\n",
    "    for weight, layers in layer_counts.items():\n",
    "        for layer_name, indices in layers.items():\n",
    "            print(\"layer_name\", layer_name, indices)\n",
    "            # If the layer is not in state_dict, initialize it with an empty list of zeros\n",
    "            if layer_name not in ind_w:\n",
    "                ind_w[layer_name] = {}\n",
    "            \n",
    "            for index in range(state_dict[layer_name].numel()):  \n",
    "                if index in indices:\n",
    "                    # Add the weight to the corresponding index in the layer\n",
    "                    if index not in ind_w[layer_name]:\n",
    "                        ind_w[layer_name][index] = 0\n",
    "                    ind_w[layer_name][index] += weight\n",
    "                else:\n",
    "                    # other not selected indices\n",
    "                    ind_w[layer_name][index] = 0\n",
    "            \n",
    "    \n",
    "    # print(\"ind_w keys\", ind_w.keys())\n",
    "    # print(\"state_dict keys\", state_dict.keys())\n",
    "    \n",
    "    for name, asr_dict in ind_w.items():\n",
    "        asr_w = torch.tensor([value for key, value in sorted(asr_dict.items())])\n",
    "        print(f\"name:{name}, asr_w:{asr_w.numel()}, state_dict:{state_dict[name].numel()}\")\n",
    "        state_dict[name] = asr_w.view(state_dict[name].shape)\n",
    "    \n",
    "    return state_dict\n",
    "\n",
    "\n",
    "def plot_layer_weights(layer_name, params, title, save_plot=False):\n",
    "    \"\"\"\n",
    "    Plots the weights of a specific layer in a PyTorch model as a heatmap.\n",
    "    \n",
    "    Parameters:\n",
    "        layer (torch.nn.Module): The PyTorch layer (e.g., torch.nn.Linear, torch.nn.Conv2d).\n",
    "        layer_name (str): A text string to label the plot and use in the filename.\n",
    "        save_plot (bool): If True, saves the plot as a PNG file with the layer_name as part of the filename.\n",
    "    \"\"\"\n",
    "    # Check if the layer has weights\n",
    "    # if not hasattr(layer, 'weight'):\n",
    "    #     raise ValueError(f\"The provided layer does not have weights.\")\n",
    "    \n",
    "    # Extract the weights\n",
    "    params = params.reshape(params.size(0), -1)\n",
    "    \n",
    "    weights = params.cpu().numpy()\n",
    "    \n",
    "    # Plot the weights as a heatmap\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(weights, cmap=\"coolwarm\", annot=False, cbar=True)\n",
    "    plt.title(f'Weight Matrix of {layer_name} _ {title}')\n",
    "    plt.xlabel('Neuron Index')\n",
    "    plt.ylabel('Input Index')\n",
    "    \n",
    "    if save_plot:\n",
    "        # Save the plot with the layer_name as part of the filename\n",
    "        filename = f\"{layer_name}_{title}_weights_heatmap.png\"\n",
    "        plt.savefig(filename, bbox_inches='tight', dpi=300)\n",
    "        print(f\"Plot saved as {filename}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split:\n",
      " - Client 0: [57 58 69 45 68 75 60 68 56 39]                         -> sum=595\n",
      " - Client 1: [61 71 49 54 64 68 58 52 59 64]                         -> sum=600\n",
      " - Client 2: [43 51 78 54 53 85 81 54 47 55]                         -> sum=601\n",
      " - Client 3: [76 54 72 52 69 71 33 41 55 76]                         -> sum=599\n",
      " - Client 4: [52 89 66 45 43 64 65 36 56 83]                         -> sum=599\n",
      " - Client 5: [ 33  28  59  88 114  69  34  62  43  71]               -> sum=601\n",
      " - Client 6: [61 72 27 86 50 74 72 66 40 52]                         -> sum=600\n",
      " - Client 7: [40 54 59 36 68 52 55 89 97 50]                         -> sum=600\n",
      " - Client 8: [72 53 25 96 71 60 67 55 55 47]                         -> sum=601\n",
      " - Client 9: [52 69 51 45 79 60 50 78 47 69]                         -> sum=600\n",
      ".  .  .  .  .  .  .  .  .  .  \n",
      ".  .  .  .  .  .  .  .  .  .  \n",
      ".  .  .  .  .  .  .  .  .  .  \n",
      " - Client 91: [39 66 82 85 72 58 45 50 41 63]                         -> sum=601\n",
      " - Client 92: [58 48 37 87 74 44 65 74 36 76]                         -> sum=599\n",
      " - Client 93: [ 32  68  69  38  57  38 106  73  84  35]               -> sum=600\n",
      " - Client 94: [ 96  31  84  67 103  39  46  33  46  56]               -> sum=601\n",
      " - Client 95: [73 52 47 65 74 67 60 40 66 56]                         -> sum=600\n",
      " - Client 96: [95 39 47 74 37 58 49 80 53 68]                         -> sum=600\n",
      " - Client 97: [70 55 75 76 56 44 65 41 49 70]                         -> sum=601\n",
      " - Client 98: [117  45  55  47  59  59  36  50  68  64]               -> sum=600\n",
      " - Client 99: [52 44 70 58 53 64 73 54 50 86]                         -> sum=604\n",
      " - Total:     [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define transformation (convert images to tensors and normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the image with mean and std\n",
    "])\n",
    "\n",
    "# Load the training dataset\n",
    "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "client_loaders, test_loader, client_data_subsets =\\\n",
    "    data.get_loaders(train_data, test_data, n_clients=100,\n",
    "                    alpha=alpha_d, batch_size=32, n_data=None, num_workers=4, seed=4)\n",
    "    \n",
    "model_fn = partial(models.get_model(model_name)[\n",
    "                        0], num_classes=num_classes, dataset=dataset)\n",
    "\n",
    "client_loader = client_loaders[0]\n",
    "\n",
    "# created models\n",
    "model1 = model_fn().to(device)\n",
    "model2 = model_fn().to(device)\n",
    "model3 = model_fn().to(device)\n",
    "\n",
    "model0_sd = {k: v.clone().detach() for k, v in model1.state_dict().items()}\n",
    "\n",
    "optimizer1 = optim.SGD(model1.parameters(), lr=0.001)\n",
    "optimizer2 = optim.SGD(model2.parameters(), lr=0.001)\n",
    "optimizer3 = optim.SGD(model3.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.29, 2.29, 2.29, 2.29, 2.29, 2.29, 2.29, 2.29, 2.29, 2.29, 2.29, 2.29, 2.29, 2.29, 2.28, 2.28, 2.28, 2.28, 2.28, 2.28, 2.28, 2.28, 2.28, 2.28, 2.28, 2.28, 2.28, 2.28, 2.28, 2.28, 2.27, 2.27, 2.27, 2.27, 2.27, 2.27, 2.27, 2.27, 2.27, 2.27, 2.27, 2.27, 2.27]\n",
      "model1 acc:0.1091, asr:0.0, cos dist:0\n",
      "model2 acc:0.1, asr:1.0, cos dist:0.9998775282292627\n",
      "current k 5\n",
      "current k 10\n",
      "current k 15\n",
      "current k 20\n",
      "current k 25\n",
      "current k 30\n",
      "current k 35\n",
      "current k 40\n",
      "current k 45\n",
      "current k 50\n",
      "current k 55\n",
      "current k 60\n",
      "current k 65\n",
      "current k 70\n",
      "current k 75\n",
      "current k 80\n",
      "current k 85\n",
      "current k 90\n",
      "current k 95\n",
      "results:\n",
      " {5: [(0.12478991596638656, 0.014100379596042413), (0.0, 0.0), (0.9924283019034192, 0.00020923111986223916)], 10: [(0.1372268907563025, 0.033794783964460784), (0.01654275092936803, 0.0721081795492788), (0.9944799275370315, 0.00015803352583459234)], 15: [(0.13159663865546217, 0.026134859085187055), (0.05204460966542751, 0.13814048362931422), (0.9954169044271112, 9.354627979076157e-05)], 20: [(0.12478991596638656, 0.022314840846962836), (0.032620817843866175, 0.09517286773537231), (0.9959875620203092, 6.519513378763989e-05)], 25: [(0.12193277310924369, 0.022948870566197925), (0.20678438661710033, 0.2967114961677403), (0.996340685558971, 7.536772941767523e-05)], 30: [(0.12571428571428572, 0.017177424367934433), (0.18633828996282525, 0.29511313154384183), (0.9965738208149559, 4.239466953040799e-05)], 35: [(0.11899159663865547, 0.026893907378402672), (0.44507434944237917, 0.39638106482226554), (0.9967893622000702, 3.42743421535208e-05)], 40: [(0.1081512605042017, 0.022247651183737966), (0.4556691449814127, 0.3764476417860262), (0.9969261811696924, 3.772825876277045e-05)], 45: [(0.12672268907563028, 0.03402437886957866), (0.6076208178438662, 0.3874499090748663), (0.9970657083555124, 3.0214266895681932e-05)], 50: [(0.11016806722689076, 0.02388964932688452), (0.6073420074349443, 0.34527535778142426), (0.9971554923802615, 3.052218904373276e-05)], 55: [(0.10521008403361347, 0.021453437541472917), (0.7024163568773233, 0.3169316133132021), (0.9972353188204579, 2.881582727106107e-05)], 60: [(0.10655462184873954, 0.02495897346873932), (0.8660780669144981, 0.24933714518252734), (0.9972996862488799, 2.265118451630385e-05)], 65: [(0.10142857142857147, 0.016976245881481417), (0.9312267657992563, 0.1551326548493249), (0.997364021348767, 1.7922955884530003e-05)], 70: [(0.10159663865546223, 0.021242228169590077), (0.9753717472118961, 0.07153085576819455), (0.9974137812037952, 1.4411149987399878e-05)], 75: [(0.09605042016806728, 0.0008016295810226408), (0.9986059479553904, 0.0044716028712711575), (0.9974695124896243, 1.4420501905784282e-05)], 80: [(0.09579831932773114, 4.163336342344337e-17), (1.0, 0.0), (0.9975001738057472, 1.4000521749099035e-05)], 85: [(0.09579831932773114, 4.163336342344337e-17), (0.999907063197026, 0.00040510213229930835), (0.9975371235515922, 1.2099775708812121e-05)], 90: [(0.09579831932773114, 4.163336342344337e-17), (1.0, 0.0), (0.9975646218634211, 8.618916472434861e-06)], 95: [(0.09579831932773114, 4.163336342344337e-17), (1.0, 0.0), (0.9975917974021286, 8.080647926202764e-06)]}\n"
     ]
    }
   ],
   "source": [
    "# model1 train benign\n",
    "train_op(model1, client_loader, optimizer1, epochs=local_ep, print_train_loss=True)\n",
    "\n",
    "model_1_sd = {key: value.clone() for key, value in model1.state_dict().items()}\n",
    "\n",
    "# model2 train from model1\n",
    "model2.load_state_dict(model_1_sd)\n",
    "if attack == \"tlp\":\n",
    "    train_op_tr_flip(model2, client_loader, optimizer2, epochs=mali_local_ep, class_num=10, print_train_loss=True)\n",
    "elif attack == \"backdoor\":\n",
    "    train_op_backdoor(model2, client_loader, optimizer2, epochs=local_ep)\n",
    "\n",
    "acc1, asr1 = model_eval(model1, test_loader, attack)\n",
    "acc2, asr2 = model_eval(model2, test_loader, attack)\n",
    "\n",
    "# delta, org_cos\n",
    "delta0, org_cos2 = get_delta_cos(model1, model2, model0_sd)\n",
    "print(f\"model1 acc:{acc1}, asr:{asr1}, cos dist:{0}\")\n",
    "print(f\"model2 acc:{acc2}, asr:{asr2}, cos dist:{org_cos2}\")\n",
    "\n",
    "# random average the attack results and main task performance\n",
    "random_exp={}\n",
    "for k in np.arange(5, 100, 5, dtype=int):\n",
    "    print(\"current k\", k)\n",
    "    results, replaced_params_list, model3 = sampling_experiment(model1, model2, model3, model0_sd, client_loader, device, k_percent=k, p=20)\n",
    "    \n",
    "    values = np.array(list(results.values()))\n",
    "    means = values.mean(axis=0)\n",
    "    stds = values.std(axis=0)\n",
    "    random_exp[k] = list(zip(means, stds))\n",
    "    \n",
    "print(\"results:\\n\", random_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: [(0.12478991596638656, 0.014100379596042413),\n",
       "  (0.0, 0.0),\n",
       "  (0.9924283019034192, 0.00020923111986223916)],\n",
       " 10: [(0.1372268907563025, 0.033794783964460784),\n",
       "  (0.01654275092936803, 0.0721081795492788),\n",
       "  (0.9944799275370315, 0.00015803352583459234)],\n",
       " 15: [(0.13159663865546217, 0.026134859085187055),\n",
       "  (0.05204460966542751, 0.13814048362931422),\n",
       "  (0.9954169044271112, 9.354627979076157e-05)],\n",
       " 20: [(0.12478991596638656, 0.022314840846962836),\n",
       "  (0.032620817843866175, 0.09517286773537231),\n",
       "  (0.9959875620203092, 6.519513378763989e-05)],\n",
       " 25: [(0.12193277310924369, 0.022948870566197925),\n",
       "  (0.20678438661710033, 0.2967114961677403),\n",
       "  (0.996340685558971, 7.536772941767523e-05)],\n",
       " 30: [(0.12571428571428572, 0.017177424367934433),\n",
       "  (0.18633828996282525, 0.29511313154384183),\n",
       "  (0.9965738208149559, 4.239466953040799e-05)],\n",
       " 35: [(0.11899159663865547, 0.026893907378402672),\n",
       "  (0.44507434944237917, 0.39638106482226554),\n",
       "  (0.9967893622000702, 3.42743421535208e-05)],\n",
       " 40: [(0.1081512605042017, 0.022247651183737966),\n",
       "  (0.4556691449814127, 0.3764476417860262),\n",
       "  (0.9969261811696924, 3.772825876277045e-05)],\n",
       " 45: [(0.12672268907563028, 0.03402437886957866),\n",
       "  (0.6076208178438662, 0.3874499090748663),\n",
       "  (0.9970657083555124, 3.0214266895681932e-05)],\n",
       " 50: [(0.11016806722689076, 0.02388964932688452),\n",
       "  (0.6073420074349443, 0.34527535778142426),\n",
       "  (0.9971554923802615, 3.052218904373276e-05)],\n",
       " 55: [(0.10521008403361347, 0.021453437541472917),\n",
       "  (0.7024163568773233, 0.3169316133132021),\n",
       "  (0.9972353188204579, 2.881582727106107e-05)],\n",
       " 60: [(0.10655462184873954, 0.02495897346873932),\n",
       "  (0.8660780669144981, 0.24933714518252734),\n",
       "  (0.9972996862488799, 2.265118451630385e-05)],\n",
       " 65: [(0.10142857142857147, 0.016976245881481417),\n",
       "  (0.9312267657992563, 0.1551326548493249),\n",
       "  (0.997364021348767, 1.7922955884530003e-05)],\n",
       " 70: [(0.10159663865546223, 0.021242228169590077),\n",
       "  (0.9753717472118961, 0.07153085576819455),\n",
       "  (0.9974137812037952, 1.4411149987399878e-05)],\n",
       " 75: [(0.09605042016806728, 0.0008016295810226408),\n",
       "  (0.9986059479553904, 0.0044716028712711575),\n",
       "  (0.9974695124896243, 1.4420501905784282e-05)],\n",
       " 80: [(0.09579831932773114, 4.163336342344337e-17),\n",
       "  (1.0, 0.0),\n",
       "  (0.9975001738057472, 1.4000521749099035e-05)],\n",
       " 85: [(0.09579831932773114, 4.163336342344337e-17),\n",
       "  (0.999907063197026, 0.00040510213229930835),\n",
       "  (0.9975371235515922, 1.2099775708812121e-05)],\n",
       " 90: [(0.09579831932773114, 4.163336342344337e-17),\n",
       "  (1.0, 0.0),\n",
       "  (0.9975646218634211, 8.618916472434861e-06)],\n",
       " 95: [(0.09579831932773114, 4.163336342344337e-17),\n",
       "  (1.0, 0.0),\n",
       "  (0.9975917974021286, 8.080647926202764e-06)]}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert the award for experiments to a model state dict to save \n",
    "# results, replaced_params_list, model3 = sampling_experiment(model1, model2, model3, model0_sd, client_loader, device, k_percent=50, p=20)\n",
    "\n",
    "# # Take long time\n",
    "# layer_counts = replaced_params_count(replaced_params_list)\n",
    "# print(\"layer_counts\", layer_counts)\n",
    "\n",
    "# state_dict = convert_to_state_dict(layer_counts, model3.state_dict())\n",
    "# model3.load_state_dict(state_dict)\n",
    "# torch.save(model3.state_dict(), 'model3_sd.pth')\n",
    "\n",
    "\n",
    "# for name, params in state_dict.items():\n",
    "#     plot_layer_weights(name, state_dict[name], title=\"k50\", save_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0.0957983193277311, 1.0, 0.9975994608830661),\n",
       " 1: (0.0957983193277311, 1.0, 0.9975759075023234),\n",
       " 2: (0.0957983193277311, 1.0, 0.9975880386773497),\n",
       " 3: (0.0957983193277311, 1.0, 0.9975948047358543),\n",
       " 4: (0.0957983193277311, 1.0, 0.9975846805609763),\n",
       " 5: (0.0957983193277311, 1.0, 0.9976033759303391),\n",
       " 6: (0.0957983193277311, 1.0, 0.9975934950634837),\n",
       " 7: (0.0957983193277311, 1.0, 0.9975917611736804),\n",
       " 8: (0.0957983193277311, 1.0, 0.997599811758846),\n",
       " 9: (0.0957983193277311, 1.0, 0.9976017780136317),\n",
       " 10: (0.0957983193277311, 1.0, 0.9975874363444746),\n",
       " 11: (0.0957983193277311, 1.0, 0.9975867567118257),\n",
       " 12: (0.0957983193277311, 1.0, 0.9975916817784309),\n",
       " 13: (0.0957983193277311, 1.0, 0.9975778355728835),\n",
       " 14: (0.0957983193277311, 1.0, 0.9975984443444759),\n",
       " 15: (0.0957983193277311, 1.0, 0.997605849057436),\n",
       " 16: (0.0957983193277311, 1.0, 0.9975960054434836),\n",
       " 17: (0.0957983193277311, 1.0, 0.9975901450961828),\n",
       " 18: (0.0957983193277311, 1.0, 0.9975862675346434),\n",
       " 19: (0.0957983193277311, 1.0, 0.9975824118591845)}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace based on the critial parameters from analysis, if can save more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for resnet8:\n\tMissing key(s) in state_dict: \"f.0.weight\", \"f.1.weight\", \"f.1.bias\", \"f.1.running_mean\", \"f.1.running_var\", \"f.3.0.conv1.weight\", \"f.3.0.bn1.weight\", \"f.3.0.bn1.bias\", \"f.3.0.bn1.running_mean\", \"f.3.0.bn1.running_var\", \"f.3.0.conv2.weight\", \"f.3.0.bn2.weight\", \"f.3.0.bn2.bias\", \"f.3.0.bn2.running_mean\", \"f.3.0.bn2.running_var\", \"f.4.0.conv1.weight\", \"f.4.0.bn1.weight\", \"f.4.0.bn1.bias\", \"f.4.0.bn1.running_mean\", \"f.4.0.bn1.running_var\", \"f.4.0.conv2.weight\", \"f.4.0.bn2.weight\", \"f.4.0.bn2.bias\", \"f.4.0.bn2.running_mean\", \"f.4.0.bn2.running_var\", \"f.4.0.downsample.0.weight\", \"f.4.0.downsample.1.weight\", \"f.4.0.downsample.1.bias\", \"f.4.0.downsample.1.running_mean\", \"f.4.0.downsample.1.running_var\", \"f.5.0.conv1.weight\", \"f.5.0.bn1.weight\", \"f.5.0.bn1.bias\", \"f.5.0.bn1.running_mean\", \"f.5.0.bn1.running_var\", \"f.5.0.conv2.weight\", \"f.5.0.bn2.weight\", \"f.5.0.bn2.bias\", \"f.5.0.bn2.running_mean\", \"f.5.0.bn2.running_var\", \"f.5.0.downsample.0.weight\", \"f.5.0.downsample.1.weight\", \"f.5.0.downsample.1.bias\", \"f.5.0.downsample.1.running_mean\", \"f.5.0.downsample.1.running_var\", \"f.6.0.conv1.weight\", \"f.6.0.bn1.weight\", \"f.6.0.bn1.bias\", \"f.6.0.bn1.running_mean\", \"f.6.0.bn1.running_var\", \"f.6.0.conv2.weight\", \"f.6.0.bn2.weight\", \"f.6.0.bn2.bias\", \"f.6.0.bn2.running_mean\", \"f.6.0.bn2.running_var\", \"f.6.0.downsample.0.weight\", \"f.6.0.downsample.1.weight\", \"f.6.0.downsample.1.bias\", \"f.6.0.downsample.1.running_mean\", \"f.6.0.downsample.1.running_var\", \"classification_layer.weight\", \"classification_layer.bias\". \n\tUnexpected key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.1.weight\", \"features.1.bias\", \"features.4.weight\", \"features.4.bias\", \"features.5.weight\", \"features.5.bias\", \"features.8.weight\", \"features.8.bias\", \"features.9.weight\", \"features.9.bias\", \"classifier.weight\", \"classifier.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m delta_model \u001b[38;5;241m=\u001b[39m model_fn()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdelta_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel3_60_sd.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fl39/lib/python3.9/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for resnet8:\n\tMissing key(s) in state_dict: \"f.0.weight\", \"f.1.weight\", \"f.1.bias\", \"f.1.running_mean\", \"f.1.running_var\", \"f.3.0.conv1.weight\", \"f.3.0.bn1.weight\", \"f.3.0.bn1.bias\", \"f.3.0.bn1.running_mean\", \"f.3.0.bn1.running_var\", \"f.3.0.conv2.weight\", \"f.3.0.bn2.weight\", \"f.3.0.bn2.bias\", \"f.3.0.bn2.running_mean\", \"f.3.0.bn2.running_var\", \"f.4.0.conv1.weight\", \"f.4.0.bn1.weight\", \"f.4.0.bn1.bias\", \"f.4.0.bn1.running_mean\", \"f.4.0.bn1.running_var\", \"f.4.0.conv2.weight\", \"f.4.0.bn2.weight\", \"f.4.0.bn2.bias\", \"f.4.0.bn2.running_mean\", \"f.4.0.bn2.running_var\", \"f.4.0.downsample.0.weight\", \"f.4.0.downsample.1.weight\", \"f.4.0.downsample.1.bias\", \"f.4.0.downsample.1.running_mean\", \"f.4.0.downsample.1.running_var\", \"f.5.0.conv1.weight\", \"f.5.0.bn1.weight\", \"f.5.0.bn1.bias\", \"f.5.0.bn1.running_mean\", \"f.5.0.bn1.running_var\", \"f.5.0.conv2.weight\", \"f.5.0.bn2.weight\", \"f.5.0.bn2.bias\", \"f.5.0.bn2.running_mean\", \"f.5.0.bn2.running_var\", \"f.5.0.downsample.0.weight\", \"f.5.0.downsample.1.weight\", \"f.5.0.downsample.1.bias\", \"f.5.0.downsample.1.running_mean\", \"f.5.0.downsample.1.running_var\", \"f.6.0.conv1.weight\", \"f.6.0.bn1.weight\", \"f.6.0.bn1.bias\", \"f.6.0.bn1.running_mean\", \"f.6.0.bn1.running_var\", \"f.6.0.conv2.weight\", \"f.6.0.bn2.weight\", \"f.6.0.bn2.bias\", \"f.6.0.bn2.running_mean\", \"f.6.0.bn2.running_var\", \"f.6.0.downsample.0.weight\", \"f.6.0.downsample.1.weight\", \"f.6.0.downsample.1.bias\", \"f.6.0.downsample.1.running_mean\", \"f.6.0.downsample.1.running_var\", \"classification_layer.weight\", \"classification_layer.bias\". \n\tUnexpected key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.1.weight\", \"features.1.bias\", \"features.4.weight\", \"features.4.bias\", \"features.5.weight\", \"features.5.bias\", \"features.8.weight\", \"features.8.bias\", \"features.9.weight\", \"features.9.bias\", \"classifier.weight\", \"classifier.bias\". "
     ]
    }
   ],
   "source": [
    "delta_model = model_fn().to(device)\n",
    "delta_model.load_state_dict(torch.load(\"model3_60_sd.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_top_r_percent(a, b, delta, k):\n",
    "    n = delta.numel()\n",
    "    top_k = max(1, int(n * (k / 100)))  # Ensure at least one element is selected\n",
    "    threshold = torch.topk(delta, top_k, sorted=True).values[-1]  # Get the r%-th largest value\n",
    "\n",
    "    mask = delta >= threshold  # Mask for top r% values\n",
    "    result = torch.where(mask, b, a)  # Replace selected positions in a with c\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_flat_to_state_dict(flat_grad, model_dict):\n",
    "    state_dict = {}\n",
    "    start = 0\n",
    "    for name, param in model_dict.items():\n",
    "        num_elements = param.numel()\n",
    "        state_dict[name] = flat_grad[start:start + num_elements].view(param.shape)\n",
    "        start += num_elements\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 0, acc: 0.1978, asr: 0.0, cos: 0.002549290657043457\n",
      "k: 2, acc: 0.1981, asr: 0.0, cos: 0.01845616102218628\n",
      "k: 4, acc: 0.1982, asr: 0.0, cos: 0.031197071075439453\n",
      "k: 6, acc: 0.1982, asr: 0.0, cos: 0.037589848041534424\n",
      "k: 8, acc: 0.1984, asr: 0.0, cos: 0.05892503261566162\n",
      "k: 10, acc: 0.1984, asr: 0.0, cos: 0.05892503261566162\n",
      "k: 12, acc: 0.1997, asr: 0.0, cos: 0.09739971160888672\n",
      "k: 14, acc: 0.1997, asr: 0.0, cos: 0.09739971160888672\n",
      "k: 16, acc: 0.1997, asr: 0.0, cos: 0.09739971160888672\n",
      "k: 18, acc: 0.1997, asr: 0.0, cos: 0.09739971160888672\n",
      "k: 20, acc: 0.2122, asr: 0.001, cos: 0.14976048469543457\n",
      "k: 22, acc: 0.2122, asr: 0.001, cos: 0.14976048469543457\n",
      "k: 24, acc: 0.2122, asr: 0.001, cos: 0.14976048469543457\n",
      "k: 26, acc: 0.2122, asr: 0.001, cos: 0.14976048469543457\n",
      "k: 28, acc: 0.2122, asr: 0.001, cos: 0.14976048469543457\n",
      "k: 30, acc: 0.2122, asr: 0.001, cos: 0.14976048469543457\n",
      "k: 32, acc: 0.274, asr: 0.328, cos: 0.2299501895904541\n",
      "k: 34, acc: 0.274, asr: 0.328, cos: 0.2299501895904541\n",
      "k: 36, acc: 0.274, asr: 0.328, cos: 0.2299501895904541\n",
      "k: 38, acc: 0.274, asr: 0.328, cos: 0.2299501895904541\n",
      "k: 40, acc: 0.274, asr: 0.328, cos: 0.2299501895904541\n",
      "k: 42, acc: 0.274, asr: 0.328, cos: 0.2299501895904541\n",
      "k: 44, acc: 0.274, asr: 0.328, cos: 0.2299501895904541\n",
      "k: 46, acc: 0.274, asr: 0.328, cos: 0.2299501895904541\n",
      "k: 48, acc: 0.274, asr: 0.328, cos: 0.2299501895904541\n",
      "k: 50, acc: 0.274, asr: 0.328, cos: 0.2299501895904541\n",
      "k: 52, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 54, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 56, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 58, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 60, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 62, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 64, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 66, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 68, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 70, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 72, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 74, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 76, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 78, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 80, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 82, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 84, acc: 0.2047, asr: 0.984, cos: 0.33482885360717773\n",
      "k: 86, acc: 0.1981, asr: 0.989, cos: 0.3701061010360718\n",
      "k: 88, acc: 0.1981, asr: 0.989, cos: 0.3701061010360718\n",
      "k: 90, acc: 0.1981, asr: 0.989, cos: 0.3701061010360718\n",
      "k: 92, acc: 0.1981, asr: 0.989, cos: 0.3701061010360718\n",
      "k: 94, acc: 0.1981, asr: 0.989, cos: 0.3701061010360718\n",
      "k: 96, acc: 0.1981, asr: 0.989, cos: 0.3701061010360718\n",
      "k: 98, acc: 0.1981, asr: 0.989, cos: 0.3701061010360718\n",
      "k: 100, acc: 0.1981, asr: 0.989, cos: 0.3701061010360718\n"
     ]
    }
   ],
   "source": [
    "flat_model1 = flat_dict(model1.state_dict())\n",
    "flat_model2 = flat_dict(model2.state_dict())\n",
    "flat_delta = flat_dict(delta_model.state_dict())\n",
    "\n",
    "results = {}\n",
    "for k in range(0, 101, 2):\n",
    "    model3.load_state_dict(model1.state_dict())\n",
    "    crafted_flat = replace_top_r_percent(flat_model1, flat_model2, flat_delta, k)\n",
    "    restored_crafted = restore_flat_to_state_dict(crafted_flat, model3.state_dict())\n",
    "    model3.load_state_dict(restored_crafted)\n",
    "    \n",
    "    acc1, asr1 = model_eval(model3, test_loader, attack)\n",
    "\n",
    "    # delta, org_cos\n",
    "    delta0, org_cos2 = get_delta_cos(model1, model3, model0_sd)\n",
    "    print(f\"k: {k}, acc: {acc1}, asr: {asr1}, cos: {org_cos2}\")\n",
    "    \n",
    "    results[k] = (acc1, asr1, org_cos2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0.1978, 0.0, 0.002549290657043457),\n",
       " 2: (0.1981, 0.0, 0.01845616102218628),\n",
       " 4: (0.1982, 0.0, 0.031197071075439453),\n",
       " 6: (0.1982, 0.0, 0.037589848041534424),\n",
       " 8: (0.1984, 0.0, 0.05892503261566162),\n",
       " 10: (0.1984, 0.0, 0.05892503261566162),\n",
       " 12: (0.1997, 0.0, 0.09739971160888672),\n",
       " 14: (0.1997, 0.0, 0.09739971160888672),\n",
       " 16: (0.1997, 0.0, 0.09739971160888672),\n",
       " 18: (0.1997, 0.0, 0.09739971160888672),\n",
       " 20: (0.2122, 0.001, 0.14976048469543457),\n",
       " 22: (0.2122, 0.001, 0.14976048469543457),\n",
       " 24: (0.2122, 0.001, 0.14976048469543457),\n",
       " 26: (0.2122, 0.001, 0.14976048469543457),\n",
       " 28: (0.2122, 0.001, 0.14976048469543457),\n",
       " 30: (0.2122, 0.001, 0.14976048469543457),\n",
       " 32: (0.274, 0.328, 0.2299501895904541),\n",
       " 34: (0.274, 0.328, 0.2299501895904541),\n",
       " 36: (0.274, 0.328, 0.2299501895904541),\n",
       " 38: (0.274, 0.328, 0.2299501895904541),\n",
       " 40: (0.274, 0.328, 0.2299501895904541),\n",
       " 42: (0.274, 0.328, 0.2299501895904541),\n",
       " 44: (0.274, 0.328, 0.2299501895904541),\n",
       " 46: (0.274, 0.328, 0.2299501895904541),\n",
       " 48: (0.274, 0.328, 0.2299501895904541),\n",
       " 50: (0.274, 0.328, 0.2299501895904541),\n",
       " 52: (0.2047, 0.984, 0.33482885360717773),\n",
       " 54: (0.2047, 0.984, 0.33482885360717773),\n",
       " 56: (0.2047, 0.984, 0.33482885360717773),\n",
       " 58: (0.2047, 0.984, 0.33482885360717773),\n",
       " 60: (0.2047, 0.984, 0.33482885360717773),\n",
       " 62: (0.2047, 0.984, 0.33482885360717773),\n",
       " 64: (0.2047, 0.984, 0.33482885360717773),\n",
       " 66: (0.2047, 0.984, 0.33482885360717773),\n",
       " 68: (0.2047, 0.984, 0.33482885360717773),\n",
       " 70: (0.2047, 0.984, 0.33482885360717773),\n",
       " 72: (0.2047, 0.984, 0.33482885360717773),\n",
       " 74: (0.2047, 0.984, 0.33482885360717773),\n",
       " 76: (0.2047, 0.984, 0.33482885360717773),\n",
       " 78: (0.2047, 0.984, 0.33482885360717773),\n",
       " 80: (0.2047, 0.984, 0.33482885360717773),\n",
       " 82: (0.2047, 0.984, 0.33482885360717773),\n",
       " 84: (0.2047, 0.984, 0.33482885360717773),\n",
       " 86: (0.1981, 0.989, 0.3701061010360718),\n",
       " 88: (0.1981, 0.989, 0.3701061010360718),\n",
       " 90: (0.1981, 0.989, 0.3701061010360718),\n",
       " 92: (0.1981, 0.989, 0.3701061010360718),\n",
       " 94: (0.1981, 0.989, 0.3701061010360718),\n",
       " 96: (0.1981, 0.989, 0.3701061010360718),\n",
       " 98: (0.1981, 0.989, 0.3701061010360718),\n",
       " 100: (0.1981, 0.989, 0.3701061010360718)}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.2754, asr: 0.269, cos: 0.22751080989837646\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
