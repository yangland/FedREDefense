{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fgsm_attack(model, loss_fn, images, labels, epsilon):\n",
    "    \"\"\"\n",
    "    Generates adversarial examples using the Fast Gradient Sign Method (FGSM).\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The target model.\n",
    "        loss_fn (torch.nn.Module): The loss function.\n",
    "        images (torch.Tensor): Input images.\n",
    "        labels (torch.Tensor): Corresponding labels.\n",
    "        epsilon (float): Perturbation magnitude.\n",
    "    \n",
    "    Returns:\n",
    "        perturbed_images (torch.Tensor): Adversarial examples.\n",
    "    \"\"\"\n",
    "    # Ensure the images require gradients\n",
    "    images = images.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    \n",
    "    # Backward pass\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Get sign of gradients\n",
    "    sign_data_grad = images.grad.sign()\n",
    "    \n",
    "    # Create perturbed image\n",
    "    perturbed_images = images + epsilon * sign_data_grad\n",
    "    perturbed_images = torch.clamp(perturbed_images, 0, 1)  # Keep within valid range\n",
    "    \n",
    "    return perturbed_images\n",
    "\n",
    "# Load a sample image\n",
    "def load_image(image_path, transform):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "# Define transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load pre-trained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Load an image\n",
    "image_path = \"sample.jpg\"  # Replace with actual path\n",
    "image = load_image(image_path, transform)\n",
    "\n",
    "# Create a dummy label (e.g., random class index)\n",
    "label = torch.tensor([3])  # Replace with correct label if known\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Perform FGSM attack\n",
    "epsilon = 0.1\n",
    "perturbed_image = fgsm_attack(model, loss_fn, image, label, epsilon)\n",
    "\n",
    "# Convert tensors to numpy for visualization\n",
    "image_np = image.squeeze().permute(1, 2, 0).detach().numpy()\n",
    "perturbed_np = perturbed_image.squeeze().permute(1, 2, 0).detach().numpy()\n",
    "\n",
    "# Plot original and adversarial images\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(image_np)\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(perturbed_np)\n",
    "ax[1].set_title(\"Adversarial Image\")\n",
    "ax[1].axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
