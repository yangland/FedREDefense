{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from utils import *\n",
    "from torch.utils.data import DataLoader\n",
    "from models import *\n",
    "import random\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=0, eps=1e-9)\n",
    "device = \"cuda\"\n",
    "\n",
    "# study 1 model's training with the new loss function with dist limits\n",
    "\n",
    "# adjustable parameters\n",
    "alpha_d = 100 # IID\n",
    "local_ep = 5 \n",
    "n_clients = 50 # dataset size for one client\n",
    "mali_local_ep = 5\n",
    "global attack \n",
    "attack = \"untargeted\" #\"backdoor\", \"tlp\", \"ut\"\n",
    "model_name = \"ConvNet\" # \"resnet8\", \"ConvNet\"\n",
    "num_classes = 10\n",
    "dataset =\"fmnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_trainable_state_dict(model):\n",
    "    \"\"\"\n",
    "    Filters model.state_dict() to retain only parameters that are in model.parameters().\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model whose state_dict needs filtering.\n",
    "\n",
    "    Returns:\n",
    "        dict: Filtered state dictionary containing only trainable parameters.\n",
    "    \"\"\"\n",
    "    param_names = {name for name, _ in model.named_parameters()}\n",
    "    return {k: v for k, v in model.state_dict().items() if k in param_names}\n",
    "\n",
    "# # Example usage\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(10, 5),\n",
    "#     nn.BatchNorm1d(5),  # This has buffers (running_mean, running_var) in state_dict but not in parameters\n",
    "#     nn.Linear(5, 2)\n",
    "# )\n",
    "\n",
    "# filtered_state_dict = filter_trainable_state_dict(model)\n",
    "# print(filtered_state_dict.keys())  # Only includes trainable parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_dist(w1, w2):\n",
    "    \"\"\"Compute cosine similarity between two flattened weight tensors\"\"\"\n",
    "    w1_flat, w2_flat = torch.cat([p.view(-1) for p in w1]), torch.cat([p.view(-1) for p in w2])\n",
    "    return 1 - torch.dot(w1_flat, w2_flat) / (torch.norm(w1_flat) * torch.norm(w2_flat))\n",
    "\n",
    "def get_delta_cos(model1, model2, model0_sd):\n",
    "    flat_model0 = flat_dict(model0_sd)\n",
    "    flat_model1 = flat_dict(model1.state_dict())\n",
    "    flat_model2 = flat_dict(model2.state_dict())\n",
    "    \n",
    "    delta = torch.abs(flat_model1 - flat_model2)\n",
    "    org_cos = cos((flat_model1 - flat_model0), (flat_model2 - flat_model0))\n",
    "    return delta, 1-org_cos.item()\n",
    "\n",
    "def model_eval(model, test_loader, attack):\n",
    "    acc = eval_op_ensemble([model], test_loader)\n",
    "    if attack == \"tlp\":\n",
    "        asr = eval_op_ensemble_tr_lf_attack([model], test_loader)\n",
    "    elif attack == \"backdoor\":\n",
    "        asr = eval_op_ensemble_attack([model], test_loader)\n",
    "    elif attack == \"untargeted\":\n",
    "        asr = None\n",
    "    return list(acc.values())[0], list(asr.values())[0]\n",
    "\n",
    "\n",
    "def filter_trainable_state_dict(model):\n",
    "    \"\"\"\n",
    "    Filters model.state_dict() to retain only parameters that are in model.parameters().\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model whose state_dict needs filtering.\n",
    "\n",
    "    Returns:\n",
    "        dict: Filtered state dictionary containing only trainable parameters.\n",
    "    \"\"\"\n",
    "    param_names = {name for name, _ in model.named_parameters()}\n",
    "    return {k: v for k, v in model.state_dict().items() if k in param_names}\n",
    "\n",
    "\n",
    "def train_rev_w_cos(model, loader, optimizer, scheduler, epochs, model0, model1, beta, budget):    \n",
    "    model.train()\n",
    "    # model.parameters need to use \n",
    "    flat_grad_model0 = flat_dict(filter_trainable_state_dict(model0))\n",
    "    flat_grad_model1 = flat_dict(filter_trainable_state_dict(model1))\n",
    "    grad_ben = (flat_grad_model1 - flat_grad_model0).to(device)\n",
    "    \n",
    "    losses = []\n",
    "    running_loss, samples = 0.0, 0\n",
    "    print(f\"data length {len(loader) * loader.batch_size}: batches {len(loader)}, batch_size {loader.batch_size}\")\n",
    "    # check_point = filter_trainable_state_dict(model0).detach().clone()\n",
    "    for ep in range(epochs):\n",
    "        for it, (x, y) in enumerate(loader):\n",
    "            if it % 2 == 0:\n",
    "                losses.append(round(eval_epoch(model, loader), 2))\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss_ce = nn.CrossEntropyLoss(reduction=\"mean\")(model(x), y)\n",
    "            print(f\"model(x), size{model(x).shape}, {model(x)}\")\n",
    "            print(\"y\", y)\n",
    "            print(\"loss_ce\", loss_ce)\n",
    "            # in the untraining reverse the sign of loss\n",
    "            loss_ce = - loss_ce\n",
    "            running_loss += loss_ce.item() * y.shape[0]\n",
    "            samples += y.shape[0]\n",
    "            \n",
    "            # add cos loss \n",
    "            w = torch.cat([p.view(-1) for p in model.parameters()]).to(device)\n",
    "            grad_mail = w - flat_grad_model0\n",
    "            target = torch.ones(len(w)).to(device)\n",
    "            loss_cos = nn.CosineEmbeddingLoss()(grad_ben.unsqueeze(0), grad_mail.unsqueeze(0), target)\n",
    "            loss_obj = (1-beta) * loss_ce + beta * loss_cos\n",
    "            loss_obj.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if it % 5 == 0:\n",
    "                print(f\"ep{ep}, loss_cs: {loss_ce:6f}, loss_cos: {loss_cos:6f}, loss_obj: {loss_obj:6f}, lr: {optimizer.param_groups[0]['lr']}\")\n",
    "        \n",
    "        # break\n",
    "        cos_d = cos_dist(grad_ben, grad_mail)\n",
    "        print(\"eval losses\", losses)\n",
    "        print(f\"cos_d: {cos_d}, budget: {budget}\")\n",
    "        \n",
    "        if cos_d > budget:\n",
    "            print(f\"budget exceeded, finish training early, ep = {ep}\")\n",
    "            craft_g, k, cos_d2 = weighted_avg_budget_cos(a=grad_mail, \n",
    "                                                        b=grad_ben, \n",
    "                                                        budget=budget)\n",
    "            print(f\"crafted cos: {cos_d2}\")\n",
    "            restored_crafted = restore_dict_grad_flat(craft_g, model0.state_dict(), model.state_dict())\n",
    "            model.load_state_dict(restored_crafted)\n",
    "            break\n",
    "        # else:\n",
    "            # check_point = model.state_dict().detach().clone()\n",
    "        \n",
    "\n",
    "    return {\"loss\": running_loss / samples}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split:\n",
      " - Client 0: [122 121 123 115 115 111 126 139 112 110]               -> sum=1194\n",
      " - Client 1: [127 114 132 112 128 124 111 114 123 115]               -> sum=1200\n",
      " - Client 2: [108 111 114 117 117 141 119 125 127 122]               -> sum=1201\n",
      " - Client 3: [123 110 109 118 124 138 108 115 122 132]               -> sum=1199\n",
      " - Client 4: [116 128 138 104 127 121 114 118 116 120]               -> sum=1202\n",
      " - Client 5: [104 127  99 137 125 128 111 111 127 131]               -> sum=1200\n",
      " - Client 6: [117 129 124 139 114 110 128 117 102 120]               -> sum=1200\n",
      " - Client 7: [107 116 117 112  98 109 138 113 151 138]               -> sum=1199\n",
      " - Client 8: [134 123 121  96 125 137 107 105 123 130]               -> sum=1201\n",
      " - Client 9: [114 110 125 147  91 103 133 118 121 136]               -> sum=1198\n",
      ".  .  .  .  .  .  .  .  .  .  \n",
      ".  .  .  .  .  .  .  .  .  .  \n",
      ".  .  .  .  .  .  .  .  .  .  \n",
      " - Client 41: [122 107 131 121 126 109 118 107 139 120]               -> sum=1200\n",
      " - Client 42: [108 116 126 121 121 132 111 118 116 131]               -> sum=1200\n",
      " - Client 43: [124 101 118 111 130 104 119 136 131 126]               -> sum=1200\n",
      " - Client 44: [105 142 128 123 110 125  97 135 110 126]               -> sum=1201\n",
      " - Client 45: [117 133 121 104 122 142 110 110 119 121]               -> sum=1199\n",
      " - Client 46: [103 133 111 112 114 110 123 126 123 144]               -> sum=1199\n",
      " - Client 47: [148 119 123 105 118 111 104 129 111 132]               -> sum=1200\n",
      " - Client 48: [129 143 125 109 115 121 116 128 112 102]               -> sum=1200\n",
      " - Client 49: [123 119 103 110 157 118 120 129 111 116]               -> sum=1206\n",
      " - Total:     [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]\n",
      "\n",
      "num feat 2048\n",
      "num feat 2048\n",
      "num feat 2048\n",
      "num feat 2048\n"
     ]
    }
   ],
   "source": [
    "# Define transformation (convert images to tensors and normalize)\n",
    "transform_img = T.Compose([\n",
    "    T.ToTensor(),  # Convert image to tensor\n",
    "    T.Normalize((0.5,), (0.5,))  # Normalize the image with mean and std\n",
    "])\n",
    "\n",
    "if dataset == \"fmnist\":\n",
    "    # Load the training dataset\n",
    "    train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform_img)\n",
    "    # Load the test dataset\n",
    "    test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_img)\n",
    "elif dataset == \"cifar10\":\n",
    "    train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_img)\n",
    "    test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_img)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "client_loaders, test_loader, client_data_subsets =\\\n",
    "    data.get_loaders(train_data, test_data, n_clients,\n",
    "                    alpha=alpha_d, batch_size=32, n_data=None, num_workers=4, seed=4)\n",
    "    \n",
    "model_fn = partial(models.get_model(model_name)[\n",
    "                        0], num_classes=num_classes, dataset=dataset)\n",
    "\n",
    "client_loader = client_loaders[0]\n",
    "\n",
    "# created models \n",
    "model0 = model_fn().to(device) # orginal model\n",
    "model1 = model_fn().to(device) # train with clean data\n",
    "model2 = model_fn().to(device) # train with new loss function\n",
    "model3 = model_fn().to(device)\n",
    "\n",
    "model0_sd = {k: v.clone().detach() for k, v in model1.state_dict().items()}\n",
    "\n",
    "optimizer0 = optim.SGD(model0.parameters(), lr=0.001)\n",
    "optimizer1 = optim.SGD(model1.parameters(), lr=0.001)\n",
    "\n",
    "optimizer3 = optim.SGD(model3.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.35, 2.3, 2.26, 2.21, 2.17, 2.12, 2.09, 2.05, 2.01, 1.98, 1.95, 1.92, 1.89, 1.86, 1.83, 1.81, 1.79, 1.77, 1.75, 1.73, 1.71, 1.69, 1.67, 1.65, 1.63, 1.62, 1.6, 1.58, 1.57, 1.55, 1.54, 1.53, 1.51, 1.5, 1.48, 1.47, 1.46, 1.45, 1.44, 1.43, 1.42, 1.41, 1.4, 1.38, 1.37, 1.37, 1.36, 1.35, 1.34, 1.33, 1.32, 1.31, 1.3, 1.29, 1.28, 1.27, 1.27, 1.26, 1.25, 1.24, 1.23, 1.23, 1.22, 1.21, 1.21, 1.2, 1.19, 1.19, 1.18, 1.17, 1.17, 1.16, 1.16, 1.15, 1.15, 1.14, 1.13, 1.13, 1.12, 1.12, 1.11, 1.11, 1.1, 1.1, 1.09, 1.09, 1.08, 1.07, 1.07, 1.07, 1.06, 1.06, 1.05, 1.05, 1.04]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.4477986973134715}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model1 train benign\n",
    "train_op(model1, client_loader, optimizer1, epochs=local_ep, print_train_loss=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1_result {'test_accuracy': 0.727}\n"
     ]
    }
   ],
   "source": [
    "model1_sd = {key: value.clone() for key, value in model1.state_dict().items()}\n",
    "\n",
    "model1_result = eval_op_ensemble([model1], test_loader)\n",
    "print(\"model1_result\", model1_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_dict_grad_dict(grad_dict, server_w, model_dict):\n",
    "    state_dict_keys = set(model_dict.keys())\n",
    "    param_dict_keys = set(server_w.keys())\n",
    "    \n",
    "    missing_keys = state_dict_keys - param_dict_keys    \n",
    "    \n",
    "    print(\"grad_dict\", grad_dict)\n",
    "    print(\"server_w\", server_w)\n",
    "    \n",
    "    restored_w = {}\n",
    "\n",
    "    for name, param in model_dict.items():\n",
    "        if name not in missing_keys:\n",
    "            print(\"name\", name)\n",
    "            print(grad_dict[name].shape, server_w[name].shape)\n",
    "\n",
    "            restored_w[name] = grad_dict[name] + server_w[name]                           \n",
    "\n",
    "        else:\n",
    "            restored_w[name] = model_dict[name]\n",
    "    return restored_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length 1216: batches 38, batch_size 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(x), sizetorch.Size([32, 10]), tensor([[-0.2689, -0.5623, -1.0158, -0.1950, -0.8226,  0.6257, -0.3308,  1.0212,\n",
      "          0.4087,  2.9841],\n",
      "        [ 1.7131,  0.4593,  0.3919,  1.3029,  0.4459, -1.8763,  0.9416, -1.3696,\n",
      "         -0.6200, -0.9170],\n",
      "        [ 0.4353, -1.0402,  0.7381,  0.4667,  0.9534, -1.1479,  0.8689, -1.2461,\n",
      "          0.3501, -1.1417],\n",
      "        [ 0.3523,  2.8817, -0.7536,  1.6360, -0.4029, -0.7863, -0.0979, -0.5565,\n",
      "         -0.8770, -0.4496],\n",
      "        [ 0.9152, -0.6645,  0.7119,  0.4295,  0.9356, -0.9383,  1.1982, -1.4538,\n",
      "          0.2379, -1.5836],\n",
      "        [ 1.2954, -1.1222,  1.0025,  0.4308,  0.5932, -1.6827,  1.2210, -1.1300,\n",
      "          0.2958, -1.5679],\n",
      "        [-0.9734, -0.3402, -0.7521, -0.5735, -0.8771,  1.9052, -0.6352,  2.6940,\n",
      "          0.4252,  0.9151],\n",
      "        [-1.3886, -1.0625, -0.1078, -1.0950, -0.0466,  0.8518, -0.4810,  1.7949,\n",
      "          2.0978,  0.4517],\n",
      "        [ 0.3518, -1.4358,  1.7709, -0.1320,  1.1912, -1.4081,  1.4411, -1.4255,\n",
      "          0.6470, -1.1599],\n",
      "        [ 1.0598,  0.1748,  0.3871,  1.0537,  0.7714, -1.4436,  0.7447, -1.4680,\n",
      "          0.1385, -1.4992],\n",
      "        [ 1.9142, -0.0573,  0.6137,  1.1019,  0.3021, -1.8448,  1.2431, -1.4494,\n",
      "         -0.6159, -1.2979],\n",
      "        [ 0.2153,  1.8542, -0.7788,  1.8925, -0.3980, -0.6827, -0.1029, -0.2189,\n",
      "         -0.4510, -0.3516],\n",
      "        [ 1.5909,  0.5226,  0.5670,  0.8570,  0.2549, -0.9070,  0.9410, -1.5964,\n",
      "         -0.8919, -1.4464],\n",
      "        [ 0.2478, -1.3299,  1.6321, -0.0892,  1.5157, -1.4862,  1.4847, -1.4749,\n",
      "          0.5656, -1.0269],\n",
      "        [ 0.3279, -0.6403,  1.2668, -0.0210,  1.6042, -1.3578,  1.3141, -1.4521,\n",
      "          0.2069, -1.3823],\n",
      "        [ 2.1540, -0.4496,  0.8082,  0.6929,  0.6363, -1.9506,  1.1651, -1.6015,\n",
      "         -0.3181, -1.5430],\n",
      "        [ 0.3581, -0.9985,  1.6418, -0.3138,  1.3473, -1.2609,  1.5322, -1.5245,\n",
      "          0.5578, -1.1484],\n",
      "        [-0.1696, -1.0897, -0.1671,  0.3451, -0.0572,  0.0620,  0.1984, -0.1852,\n",
      "          1.6420,  0.3419],\n",
      "        [ 0.8234,  0.7703, -0.0142,  1.6794,  0.5089, -1.6499,  0.5011, -1.2119,\n",
      "         -0.3787, -1.2888],\n",
      "        [-0.2964, -1.2701,  0.3336, -0.6966,  0.4075, -0.2191,  0.4379,  0.3763,\n",
      "          2.1610,  0.2063],\n",
      "        [-0.4467, -0.1660, -0.4566, -0.5987, -1.0620,  2.4670,  0.1458,  0.3661,\n",
      "          0.0369,  1.0096],\n",
      "        [-1.1405, -0.7318, -0.5372, -0.8517, -0.7892,  1.7648, -0.5332,  3.2446,\n",
      "          0.5802,  0.7846],\n",
      "        [-0.5580, -0.9676,  0.1640, -0.5910,  0.0781,  0.6086,  0.1613,  0.6854,\n",
      "          2.1062,  0.2067],\n",
      "        [-1.0212, -1.0090, -0.6988, -1.0855, -0.6403,  1.3643, -0.5315,  2.8569,\n",
      "          0.2733,  1.7633],\n",
      "        [ 0.7387, -0.9622,  0.9018,  0.4826,  1.3834, -1.5089,  0.9984, -1.5310,\n",
      "          0.4988, -1.2167],\n",
      "        [-1.3303, -0.7556, -0.2905, -0.6340, -0.5161,  1.0734, -0.6127,  3.0320,\n",
      "          1.0888,  0.4563],\n",
      "        [ 0.1388, -0.4313,  1.3854, -0.6961,  0.4078,  0.1079,  1.1659, -0.4300,\n",
      "          0.0422, -1.0891],\n",
      "        [-0.9710, -0.9633, -0.3540, -1.1178, -0.4562,  2.6056, -0.3831,  2.3325,\n",
      "          0.4296,  1.0116],\n",
      "        [ 1.3183,  0.0438,  0.5385,  0.0770,  0.2314, -0.5322,  1.3053, -1.0806,\n",
      "         -0.2507, -1.2034],\n",
      "        [-0.1076,  0.2078, -0.2042, -0.1917, -0.7104,  1.9726,  0.2741,  0.0850,\n",
      "         -0.1850,  0.4626],\n",
      "        [ 1.4530, -0.3374,  0.1173, -0.0243, -0.0360,  0.2946,  0.9181, -0.6629,\n",
      "         -0.4846, -0.9142],\n",
      "        [ 0.4511, -0.4071,  1.7540,  0.0387,  1.3450, -1.4750,  1.1016, -1.2276,\n",
      "         -0.1133, -1.1771]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y tensor([9, 6, 3, 1, 4, 3, 7, 8, 6, 4, 0, 3, 3, 6, 4, 0, 2, 8, 3, 8, 5, 7, 8, 7,\n",
      "        4, 7, 6, 5, 6, 5, 0, 2], device='cuda:0')\n",
      "loss_ce tensor(1.1398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "ep0, loss_cs: -1.139809, loss_cos: 0.504929, loss_obj: -0.317440, lr: 0.05\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-5.6382e-01, -7.0546e-02, -1.1706e-03, -1.0681e+00, -7.6836e-01,\n",
      "          2.0172e+00, -4.3204e-01,  2.2844e+00,  7.9578e-02,  2.0007e-01],\n",
      "        [-6.1790e-01, -3.1484e-01,  1.4629e-01, -1.5734e+00, -9.5331e-01,\n",
      "          2.2494e+00, -7.3817e-01,  2.7084e+00,  4.9555e-03,  1.1547e+00],\n",
      "        [ 9.8469e-01, -1.2376e-01,  1.9403e+00, -1.0123e+00,  5.1385e-01,\n",
      "         -1.2705e+00,  6.2482e-01, -1.3349e+00, -2.9934e-02, -7.4757e-01],\n",
      "        [-9.7900e-01, -2.5556e-01,  4.0376e-02, -1.5465e+00, -8.4740e-01,\n",
      "          2.0148e+00, -7.8759e-01,  2.5610e+00,  8.1090e-02,  9.8247e-01],\n",
      "        [-5.6847e-01, -5.1449e-01,  4.7021e-02, -1.7073e+00, -8.3330e-01,\n",
      "          1.6125e+00, -8.9405e-01,  2.2818e+00,  1.2120e-01,  2.5341e+00],\n",
      "        [-1.0207e+00, -3.6026e-01,  2.1683e-01, -1.5735e+00, -7.2764e-01,\n",
      "          1.7067e+00, -7.6514e-01,  2.4637e+00,  3.5935e-01,  1.0063e+00],\n",
      "        [ 1.2990e+00,  1.0048e+00,  8.4493e-01, -7.0415e-01, -1.5980e-01,\n",
      "          2.3378e-01,  6.4496e-01, -8.6013e-01, -8.1547e-01, -7.2996e-01],\n",
      "        [ 1.0620e+00, -4.7175e-01,  2.7562e+00, -1.3561e+00,  8.1798e-01,\n",
      "         -1.3672e+00,  8.5537e-01, -1.2766e+00,  2.3595e-01, -7.5986e-01],\n",
      "        [ 1.3044e+00,  1.5074e+00,  5.5369e-01,  3.8662e-01, -7.3266e-01,\n",
      "         -1.1288e+00,  5.1098e-02, -1.0609e+00, -7.4153e-02, -5.0864e-01],\n",
      "        [ 1.5074e+00,  1.5064e+00,  5.6107e-01,  4.4008e-01, -7.1994e-01,\n",
      "         -1.0713e+00,  1.0951e-01, -1.1687e+00, -2.1838e-01, -4.9556e-01],\n",
      "        [ 1.6014e+00,  1.6004e-01,  1.2537e+00, -5.0852e-01, -5.2146e-02,\n",
      "         -1.2312e+00,  4.4204e-01, -1.3241e+00,  4.3293e-02, -8.0598e-01],\n",
      "        [ 1.3464e+00,  1.0554e+00,  6.7310e-01,  2.3213e-01, -5.9147e-01,\n",
      "         -1.0319e+00,  3.8315e-02, -1.1509e+00,  2.7651e-01, -5.0063e-01],\n",
      "        [ 6.2524e-01,  6.6745e-02,  4.2640e-02, -5.7063e-02, -1.0900e+00,\n",
      "          2.1728e-02, -1.0073e-01, -3.6784e-01,  7.3566e-01,  1.7067e-01],\n",
      "        [ 2.4245e+00, -2.9918e-01,  1.4149e+00, -5.9931e-01, -6.6278e-01,\n",
      "         -6.8542e-01,  1.0139e+00, -1.3831e+00, -3.7340e-01, -1.1606e+00],\n",
      "        [ 8.2421e-01,  1.5706e+00,  3.1403e-01,  4.0724e-01, -7.5578e-01,\n",
      "         -8.7219e-01, -2.8652e-01, -6.8222e-01,  1.8391e-01, -1.2967e-01],\n",
      "        [ 1.7718e+00,  7.4994e-02,  1.7626e+00, -1.0935e+00, -2.4312e-01,\n",
      "         -5.4935e-01,  8.8059e-01, -1.2169e+00, -5.8577e-01, -1.1184e+00],\n",
      "        [ 7.6053e-01, -4.3436e-01,  2.4813e+00, -1.4456e+00,  1.1403e+00,\n",
      "         -1.3634e+00,  6.1334e-01, -1.1859e+00,  4.7027e-01, -5.8419e-01],\n",
      "        [ 4.4399e-01,  3.8438e+00, -2.3032e-02,  1.9029e-01, -9.7926e-01,\n",
      "         -3.2042e-01, -2.0547e-01, -4.7395e-01, -6.6150e-01, -5.4545e-01],\n",
      "        [-9.3392e-01, -3.8839e-01,  2.4103e-01, -1.6384e+00, -8.6223e-01,\n",
      "          1.8680e+00, -8.4277e-01,  2.6283e+00,  2.6800e-01,  1.3804e+00],\n",
      "        [ 7.6395e-01,  3.8616e+00,  3.9504e-01, -2.3229e-01, -7.5351e-01,\n",
      "         -3.2736e-01, -1.0860e-01, -4.2910e-01, -8.8493e-01, -6.6340e-01],\n",
      "        [-7.5103e-01, -5.0060e-01,  1.8494e-01, -1.6187e+00, -8.3072e-01,\n",
      "          1.9207e+00, -8.2104e-01,  2.8470e+00,  3.2827e-01,  1.2423e+00],\n",
      "        [ 6.5289e-01, -6.3357e-01,  1.6210e+00, -1.2871e+00,  6.3938e-01,\n",
      "         -9.5988e-01,  3.4758e-01, -1.0025e+00,  8.7490e-01, -2.1723e-01],\n",
      "        [ 6.4894e-01,  6.0287e-03,  6.5283e-01, -1.1429e+00, -3.3767e-01,\n",
      "         -4.4357e-01, -8.1290e-02, -6.1608e-01, -2.5028e-01,  2.0609e+00],\n",
      "        [ 1.3946e+00,  5.0279e-01,  1.0067e+00, -6.6154e-01, -4.0671e-01,\n",
      "         -4.1600e-01,  5.5568e-01, -1.4590e+00, -3.5148e-01, -7.4900e-01],\n",
      "        [ 5.3199e-01,  5.1698e-01,  2.4757e+00, -1.6772e+00,  9.0994e-01,\n",
      "         -8.3717e-01,  3.3781e-01, -6.9846e-01, -1.0535e-01, -7.2578e-01],\n",
      "        [ 6.7669e-01, -8.2241e-01,  2.8024e+00, -1.7122e+00,  7.8725e-01,\n",
      "         -1.0996e+00,  6.1164e-01, -9.7660e-01,  5.8822e-01, -4.0645e-01],\n",
      "        [ 4.7124e-01,  3.8296e+00,  3.2142e-01, -5.3955e-02, -6.0994e-01,\n",
      "         -3.7813e-01, -1.2248e-01, -4.9360e-01, -6.4498e-01, -5.3005e-01],\n",
      "        [ 9.4560e-01, -3.2141e-01,  2.8946e+00, -1.4101e+00,  7.3116e-01,\n",
      "         -1.4198e+00,  7.5560e-01, -1.3134e+00,  2.6225e-01, -9.4728e-01],\n",
      "        [-7.7860e-01, -4.4501e-01,  3.0126e-01, -1.5289e+00, -7.5923e-01,\n",
      "          1.7117e+00, -8.3907e-01,  2.5699e+00,  5.3796e-01,  1.1359e+00],\n",
      "        [ 7.1705e-01,  3.7199e+00, -2.3566e-01,  1.8939e-01, -1.0189e+00,\n",
      "         -3.0651e-01, -2.6829e-01, -5.5705e-01, -1.1004e+00, -9.5448e-02],\n",
      "        [-5.4972e-01,  5.3545e-03,  1.2635e-01, -9.6909e-01, -9.1191e-01,\n",
      "          2.2100e+00, -5.2047e-01,  1.8284e+00,  2.3492e-01,  1.8681e-01],\n",
      "        [ 4.8780e-01,  2.7818e-01,  4.5657e-01, -9.7623e-01, -5.6008e-01,\n",
      "          5.3227e-01,  3.9622e-01, -3.8050e-01, -1.7827e-01, -7.8058e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y tensor([7, 7, 6, 7, 7, 7, 4, 2, 3, 3, 8, 0, 8, 0, 3, 0, 4, 1, 7, 1, 7, 4, 9, 3,\n",
      "        4, 2, 1, 2, 7, 1, 5, 6], device='cuda:0')\n",
      "loss_ce tensor(1.2770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[ 1.2392,  0.6003,  3.4920, -2.9794, -1.1768,  0.3036,  0.8393, -2.2179,\n",
      "          0.1644,  0.6695],\n",
      "        [ 0.1580,  0.7213,  1.1971, -2.4719, -1.6338,  3.0114, -0.2866, -0.8915,\n",
      "         -0.1695,  2.1268],\n",
      "        [ 1.0009,  0.4155,  3.9037, -3.1000, -0.5926, -0.2146,  0.9425, -2.2278,\n",
      "          0.3842,  0.1123],\n",
      "        [ 0.9619, -0.5101,  3.4630, -2.8571, -0.9655, -0.1076,  1.0170, -2.0102,\n",
      "          0.8155,  0.1942],\n",
      "        [-0.3860,  0.4093,  1.7937, -3.2312, -1.3629,  2.9422, -0.5478, -0.9932,\n",
      "          0.6131,  2.0255],\n",
      "        [ 0.2549,  0.3204,  1.5929, -2.8982, -1.6187,  2.6947, -0.6829, -1.3265,\n",
      "          0.4144,  3.1142],\n",
      "        [ 0.8691,  1.1325,  1.7262, -2.1006, -2.1492,  1.0100,  0.2449, -1.8920,\n",
      "          0.1602,  1.0426],\n",
      "        [ 0.4058,  0.4524,  1.1179, -2.7537, -1.4969,  2.1382, -0.0527, -1.3126,\n",
      "         -0.0419,  2.7026],\n",
      "        [ 1.3822,  1.2519,  4.0667, -2.9279, -1.1390,  0.0599,  0.5428, -2.1016,\n",
      "         -0.4079, -0.3459],\n",
      "        [ 1.2673,  0.6204,  3.0840, -2.6373, -0.9749,  0.7580,  0.9738, -1.8822,\n",
      "         -0.5891,  0.3392],\n",
      "        [ 1.6493,  0.4611,  2.6665, -2.1845, -1.9320,  1.0697,  0.5578, -2.1739,\n",
      "         -0.2532,  0.3753],\n",
      "        [ 1.8225,  1.1750,  3.8457, -3.0435, -1.3071, -0.0407,  0.6921, -2.4440,\n",
      "         -0.2109, -0.3310],\n",
      "        [ 1.5884,  0.5165,  3.8643, -2.7708, -0.9302,  0.0395,  1.1948, -2.1656,\n",
      "         -0.3655, -0.4111],\n",
      "        [ 0.8012,  0.4553,  1.5374, -2.7514, -1.6370,  1.6025, -0.1829, -1.6931,\n",
      "          0.0922,  3.1043],\n",
      "        [ 1.1867,  0.1434,  4.0284, -3.0869, -1.0309,  0.6143,  0.8811, -1.9155,\n",
      "         -0.0911,  0.1683],\n",
      "        [ 0.1501,  0.9209,  0.8583, -1.9347, -1.8025,  2.6992, -0.0743, -1.0485,\n",
      "         -0.3470,  1.9186],\n",
      "        [ 0.6411,  0.4685,  1.8093, -2.6607, -1.4665,  1.3784,  0.0082, -1.7983,\n",
      "         -0.0787,  2.7414],\n",
      "        [ 0.3369,  0.4639,  1.3716, -2.7201, -1.5926,  1.9533, -0.3995, -1.6600,\n",
      "         -0.0894,  3.3969],\n",
      "        [-0.0682,  0.7192,  1.4274, -2.2710, -1.6191,  3.2526, -0.4561, -1.0476,\n",
      "         -0.0517,  1.2105],\n",
      "        [ 2.5393,  1.0562,  3.6078, -2.6567, -1.3361, -0.3476,  0.8377, -2.3221,\n",
      "         -0.6192, -0.3999],\n",
      "        [ 1.4984,  0.7783,  4.3315, -3.1684, -0.8323, -0.1464,  0.8543, -2.2486,\n",
      "         -0.1493, -0.1512],\n",
      "        [ 1.0753,  0.6173,  4.0914, -3.0005, -0.7834, -0.1093,  0.7484, -2.0794,\n",
      "          0.0671, -0.0233],\n",
      "        [ 2.0014,  1.2887,  2.4493, -2.0743, -1.7638,  0.6168,  0.9167, -2.1543,\n",
      "         -0.8949, -0.0131],\n",
      "        [ 1.7678,  1.0797,  3.8851, -3.0781, -1.2568, -0.0449,  0.6711, -2.4023,\n",
      "         -0.1186, -0.3536],\n",
      "        [ 1.1973,  0.8325,  4.1487, -3.1723, -0.6009, -0.1438,  0.7666, -2.1217,\n",
      "          0.1807,  0.0559],\n",
      "        [ 0.0856,  0.3398,  1.4121, -2.5717, -1.4908,  3.2978, -0.1760, -0.9096,\n",
      "          0.1574,  1.2448],\n",
      "        [ 0.0885,  0.2727,  1.7001, -2.9973, -1.4817,  2.0704, -0.4480, -1.4679,\n",
      "          0.5432,  3.0783],\n",
      "        [ 0.5274,  0.3292,  1.7425, -2.6368, -1.5046,  1.0327, -0.0935, -1.9172,\n",
      "          0.0434,  2.9550],\n",
      "        [ 1.5122,  1.2143,  2.7102, -2.6865, -1.7904,  0.4041,  0.3552, -2.2609,\n",
      "          0.2619,  0.5645],\n",
      "        [ 1.2186,  0.7815,  4.2252, -3.1561, -0.6837, -0.1423,  0.7960, -2.1337,\n",
      "          0.1404,  0.0630],\n",
      "        [ 1.4905,  0.5148,  4.0768, -3.0931, -0.8735, -0.2337,  1.0414, -2.1696,\n",
      "          0.1453, -0.2362],\n",
      "        [ 1.3646,  3.7349,  2.3231, -1.9479, -1.6572,  0.5259,  0.4811, -1.9395,\n",
      "         -1.0927, -0.0060]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y tensor([8, 5, 4, 4, 7, 9, 8, 9, 2, 6, 6, 4, 2, 9, 2, 5, 9, 9, 5, 0, 2, 6, 3, 4,\n",
      "        4, 7, 9, 9, 0, 4, 4, 1], device='cuda:0')\n",
      "loss_ce tensor(2.3720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[ 1.1082e+00,  3.9764e+00,  7.4477e+00, -2.5870e+00, -4.6465e+00,\n",
      "          1.4500e+00, -4.3149e-01, -2.3097e+00, -1.4096e+00, -4.3107e-01],\n",
      "        [ 1.1168e+00,  3.5349e+00,  7.6756e+00, -2.7790e+00, -5.0150e+00,\n",
      "          1.4373e+00, -4.3111e-01, -2.4836e+00, -1.4905e+00, -5.3543e-01],\n",
      "        [ 9.2681e-01,  4.5503e-01,  8.5161e+00, -2.8410e+00, -4.9446e+00,\n",
      "          1.1954e+00,  1.5055e-01, -2.4457e+00, -7.6404e-02, -5.0086e-01],\n",
      "        [ 9.1749e-01,  1.5079e+00,  9.2632e+00, -3.2738e+00, -4.7956e+00,\n",
      "          1.3856e+00, -2.2488e-01, -2.6342e+00, -3.8975e-01, -4.6061e-01],\n",
      "        [ 1.0911e+00,  1.9616e+00,  8.8395e+00, -2.9526e+00, -4.7636e+00,\n",
      "          1.1978e+00, -3.5446e-02, -2.6780e+00, -6.3965e-01, -7.4731e-01],\n",
      "        [ 1.4960e+00,  2.6391e+00,  8.5765e+00, -2.7873e+00, -5.3137e+00,\n",
      "          1.1631e+00, -3.7222e-01, -2.6227e+00, -1.4370e+00, -5.8026e-01],\n",
      "        [ 2.5880e-01,  1.0576e+00,  6.9843e+00, -3.0310e+00, -4.3745e+00,\n",
      "          3.4206e+00, -8.0637e-01, -2.4520e+00, -2.0010e-01,  9.5695e-01],\n",
      "        [ 1.2078e+00,  9.9235e-01,  9.6072e+00, -3.1346e+00, -5.2890e+00,\n",
      "          8.6615e-01,  2.6778e-02, -2.6092e+00, -3.3775e-01, -7.5198e-01],\n",
      "        [ 1.4343e+00,  1.1128e+00,  9.9003e+00, -3.3614e+00, -5.4905e+00,\n",
      "          1.2886e+00,  3.1553e-01, -2.9160e+00, -7.1996e-01, -7.5931e-01],\n",
      "        [ 1.1359e+00,  2.5895e+00,  8.2846e+00, -2.9137e+00, -5.1088e+00,\n",
      "          1.5235e+00, -4.7422e-01, -2.5619e+00, -1.1723e+00, -4.1979e-01],\n",
      "        [ 7.6797e-01,  1.5098e+00,  7.2005e+00, -2.9787e+00, -4.8988e+00,\n",
      "          2.2464e+00, -5.7549e-01, -2.5603e+00, -7.2383e-01,  1.5694e-02],\n",
      "        [ 1.1483e+00,  9.6274e-01,  8.9103e+00, -3.0874e+00, -4.8132e+00,\n",
      "          1.2019e+00,  3.4310e-01, -2.5778e+00, -6.4419e-01, -7.1692e-01],\n",
      "        [ 2.1110e-01,  9.6755e-01,  6.5201e+00, -2.8992e+00, -4.2748e+00,\n",
      "          3.5787e+00, -8.6967e-01, -2.3098e+00, -2.3052e-01,  1.0176e+00],\n",
      "        [ 1.8045e+00,  9.0265e-01,  7.5282e+00, -2.7174e+00, -4.6824e+00,\n",
      "          1.1410e+00,  2.6725e-01, -2.3815e+00, -5.1762e-01, -4.9419e-01],\n",
      "        [-8.9738e-02,  9.0030e-01,  6.1302e+00, -3.1199e+00, -3.6608e+00,\n",
      "          4.2845e+00, -8.9829e-01, -2.2678e+00, -2.2186e-01,  7.5069e-01],\n",
      "        [ 9.8425e-01,  1.3989e+00,  8.2224e+00, -2.8141e+00, -4.3615e+00,\n",
      "          1.1301e+00,  9.7908e-02, -2.3009e+00, -6.5945e-01, -4.8355e-01],\n",
      "        [ 1.1132e-01,  1.1026e+00,  4.9583e+00, -2.8924e+00, -2.9889e+00,\n",
      "          3.8908e+00, -9.7089e-01, -2.0539e+00, -4.4914e-01,  6.5083e-01],\n",
      "        [ 8.5469e-01,  9.8784e-01,  8.1069e+00, -3.0723e+00, -4.3444e+00,\n",
      "          1.8722e+00,  6.5466e-04, -2.5731e+00, -6.3524e-01, -1.7726e-01],\n",
      "        [ 1.1239e+00,  1.4228e+00,  9.9739e+00, -3.2446e+00, -5.4535e+00,\n",
      "          8.9546e-01,  1.2100e-01, -2.7753e+00, -7.1832e-01, -8.1616e-01],\n",
      "        [ 1.0517e+00,  3.8911e+00,  7.3209e+00, -2.5411e+00, -4.7820e+00,\n",
      "          1.5010e+00, -5.9955e-01, -2.2481e+00, -1.6366e+00, -3.1870e-01],\n",
      "        [ 1.2651e+00,  1.6381e+00,  8.5315e+00, -3.2718e+00, -5.0942e+00,\n",
      "          1.8554e+00, -7.5068e-02, -2.7328e+00, -1.0019e+00, -2.7248e-01],\n",
      "        [-1.0779e-01,  1.0731e+00,  6.3255e+00, -3.1567e+00, -3.8035e+00,\n",
      "          3.9945e+00, -9.4114e-01, -2.1930e+00, -3.6713e-01,  5.7663e-01],\n",
      "        [ 5.6388e-01,  1.2899e+00,  7.2780e+00, -2.8562e+00, -5.0168e+00,\n",
      "          2.2418e+00, -4.4897e-01, -2.3279e+00, -2.2611e-01,  1.7875e-01],\n",
      "        [ 1.2506e+00,  1.2738e+00,  9.9450e+00, -3.2276e+00, -5.5676e+00,\n",
      "          1.0593e+00,  1.5140e-01, -2.8543e+00, -8.2391e-01, -9.5419e-01],\n",
      "        [ 2.1928e+00,  1.5492e+00,  8.7322e+00, -2.9108e+00, -4.8241e+00,\n",
      "          5.4798e-01,  2.5502e-01, -2.7199e+00, -1.2252e+00, -8.8605e-01],\n",
      "        [ 8.0407e-01,  1.2987e+00,  6.5888e+00, -3.0209e+00, -3.8534e+00,\n",
      "          2.4816e+00, -4.9015e-01, -2.2950e+00, -8.6156e-02,  3.4916e-02],\n",
      "        [ 1.8363e-02,  1.0030e+00,  6.0210e+00, -3.0472e+00, -3.6036e+00,\n",
      "          3.6934e+00, -8.2459e-01, -2.1681e+00, -3.2894e-01,  6.5083e-01],\n",
      "        [ 1.2735e-01,  1.1070e+00,  6.8734e+00, -3.0860e+00, -4.3287e+00,\n",
      "          3.4213e+00, -8.6952e-01, -2.4125e+00, -1.3083e-01,  9.8414e-01],\n",
      "        [ 9.7758e-02,  8.6343e-01,  6.0055e+00, -3.0229e+00, -3.4408e+00,\n",
      "          3.8135e+00, -8.5715e-01, -2.2255e+00, -2.4252e-01,  5.9286e-01],\n",
      "        [ 2.8106e-01,  2.2045e+00,  6.5052e+00, -2.9412e+00, -3.6508e+00,\n",
      "          2.9603e+00, -6.4520e-01, -2.2729e+00, -9.5209e-01,  2.6068e-02],\n",
      "        [-4.6510e-02,  1.0726e+00,  6.1409e+00, -3.0624e+00, -3.6365e+00,\n",
      "          4.0114e+00, -9.1499e-01, -2.1632e+00, -4.3575e-01,  7.4872e-01],\n",
      "        [ 8.5116e-01,  5.2775e-01,  7.8317e+00, -2.6493e+00, -4.5501e+00,\n",
      "          8.6249e-01, -8.0453e-02, -2.0948e+00,  7.1778e-02, -1.4830e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y tensor([1, 1, 2, 4, 1, 3, 9, 2, 6, 3, 8, 2, 9, 6, 7, 4, 5, 4, 2, 1, 6, 7, 8, 2,\n",
      "        0, 0, 7, 9, 7, 2, 7, 2], device='cuda:0')\n",
      "loss_ce tensor(6.0698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[ 0.3272, -0.6640, 17.6948, -3.9537, -6.0516,  1.1980, -1.4445, -4.3912,\n",
      "         -0.8405, -1.5230],\n",
      "        [ 0.1885, -0.7577, 20.4796, -4.4488, -6.7794,  0.9770, -1.5205, -4.6695,\n",
      "         -1.3079, -1.9973],\n",
      "        [-0.6470, -0.5122, 18.3950, -3.8792, -5.4935,  2.6122, -1.7499, -5.5755,\n",
      "         -1.1146, -1.4581],\n",
      "        [ 0.3504, -0.6996, 20.5156, -4.4046, -6.7384,  0.9289, -1.5107, -4.6283,\n",
      "         -1.5423, -2.0032],\n",
      "        [ 0.7080, -0.7299, 20.4627, -4.5935, -6.6674,  0.9536, -1.6108, -4.6453,\n",
      "         -1.9224, -2.0745],\n",
      "        [-0.6288, -0.5546, 17.9231, -3.8841, -5.2958,  2.7424, -1.5757, -5.4118,\n",
      "         -1.0099, -1.4590],\n",
      "        [ 0.4689, -0.7463, 18.9745, -4.2477, -6.0589,  1.6393, -1.6928, -4.7439,\n",
      "         -1.7652, -1.7746],\n",
      "        [ 0.6760, -0.6173, 20.4172, -4.6346, -6.7509,  1.0891, -1.7434, -4.6480,\n",
      "         -2.1397, -1.8356],\n",
      "        [-0.8084, -0.3712, 16.5520, -3.6421, -5.0131,  2.8166, -1.6553, -5.0625,\n",
      "         -0.7995, -1.1827],\n",
      "        [ 0.1896, -0.5255, 19.4256, -4.1931, -6.2894,  0.9658, -1.4001, -4.3402,\n",
      "         -1.2271, -1.8780],\n",
      "        [ 0.7637, -0.7761, 20.3440, -4.5504, -6.7904,  0.9644, -1.5894, -4.6520,\n",
      "         -1.8780, -2.1685],\n",
      "        [ 0.8882, -0.7641, 19.3188, -4.2929, -6.4361,  1.0235, -1.5494, -4.4591,\n",
      "         -1.5762, -2.0443],\n",
      "        [ 0.3033, -0.5163, 17.5362, -3.6393, -5.8883,  1.1526, -1.4376, -4.1507,\n",
      "         -0.7610, -1.5891],\n",
      "        [-0.5492, -0.4979, 18.0504, -3.8280, -5.4276,  2.7482, -1.5754, -5.5416,\n",
      "         -1.0016, -1.3706],\n",
      "        [ 0.0864, -0.8800, 17.8306, -3.7727, -5.1892,  1.9239, -1.4335, -4.5736,\n",
      "         -1.5735, -1.4555],\n",
      "        [-0.4505, -0.5362, 18.1652, -3.8303, -5.8457,  2.3011, -1.7374, -5.2529,\n",
      "         -0.9610, -1.7699],\n",
      "        [-0.6112, -0.6368, 18.5103, -3.8899, -5.5122,  2.7143, -1.7126, -5.2899,\n",
      "         -1.2050, -1.7610],\n",
      "        [ 0.4481, -0.6421, 20.6733, -4.5147, -6.6708,  0.9894, -1.7530, -4.6990,\n",
      "         -1.6750, -1.8737],\n",
      "        [-0.6724, -0.3247, 16.6132, -3.5128, -4.7879,  3.0371, -1.5824, -5.1923,\n",
      "         -1.0700, -1.2630],\n",
      "        [ 0.4114, -0.9271, 20.7865, -4.7063, -6.9558,  1.1953, -1.6469, -4.9134,\n",
      "         -1.5902, -2.0433],\n",
      "        [ 0.2484, -0.1039, 19.6507, -4.2435, -6.2755,  1.5277, -1.5559, -4.7870,\n",
      "         -1.5930, -1.8923],\n",
      "        [ 0.3693, -0.3430, 20.3166, -4.4360, -6.4759,  1.3286, -1.7795, -4.7702,\n",
      "         -1.8981, -1.7809],\n",
      "        [ 0.1932, -0.5404, 18.2824, -3.9282, -5.7785,  1.6505, -1.6205, -4.6246,\n",
      "         -1.5517, -2.2411],\n",
      "        [-0.2632, -0.5515, 17.0323, -3.7250, -5.6582,  1.7518, -1.5622, -4.7714,\n",
      "         -0.5037, -1.1716],\n",
      "        [ 0.3774, -0.6119, 20.7582, -4.6978, -6.7167,  1.3415, -1.8350, -4.8912,\n",
      "         -1.8690, -1.8296],\n",
      "        [ 0.1421, -0.9287, 16.9774, -3.5114, -5.7890,  1.6581, -1.3535, -4.2180,\n",
      "         -1.3012, -1.4659],\n",
      "        [ 0.5061, -0.6786, 20.0365, -4.5965, -6.5144,  1.3625, -1.8145, -4.7125,\n",
      "         -2.0207, -1.8217],\n",
      "        [-0.2937, -0.4361, 18.0698, -3.9870, -5.9518,  1.9064, -1.6398, -5.0494,\n",
      "         -0.6768, -1.4950],\n",
      "        [ 0.3962, -0.5991, 20.2027, -4.4511, -6.5310,  0.9176, -1.5812, -4.5536,\n",
      "         -1.3111, -1.8083],\n",
      "        [ 0.0888, -1.0042, 18.9738, -4.3083, -6.4021,  1.4626, -1.5756, -4.5125,\n",
      "         -1.2225, -1.6520],\n",
      "        [ 0.4515, -0.8146, 19.9905, -4.3982, -6.4416,  1.4402, -1.6485, -4.9248,\n",
      "         -1.8237, -1.9452],\n",
      "        [-0.2462, -0.5220, 18.0140, -3.8637, -5.7695,  2.0341, -1.6359, -4.9392,\n",
      "         -1.2149, -1.8934]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y tensor([8, 2, 7, 2, 0, 7, 3, 3, 5, 4, 0, 0, 6, 7, 2, 9, 7, 2, 5, 3, 1, 1, 9, 8,\n",
      "        2, 6, 3, 8, 2, 8, 0, 9], device='cuda:0')\n",
      "loss_ce tensor(16.7665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-2.3057, -1.6347, 35.9909, -7.5902, -7.7140,  0.4332, -2.8128, -7.1584,\n",
      "         -3.8956, -3.4314],\n",
      "        [-2.3285, -1.4045, 34.1377, -6.8811, -7.2706,  0.4837, -2.6817, -6.6718,\n",
      "         -3.5378, -3.1691],\n",
      "        [-2.4421, -1.2521, 31.8050, -5.6212, -6.1872,  1.7417, -2.5473, -8.3603,\n",
      "         -3.5699, -2.9606],\n",
      "        [-2.2745, -1.4142, 31.0663, -5.5293, -5.7336,  1.8039, -2.3551, -8.2917,\n",
      "         -3.2729, -2.8662],\n",
      "        [-2.0321, -1.5287, 33.8228, -7.1969, -7.0675,  0.5316, -2.8201, -6.6685,\n",
      "         -3.7989, -3.1190],\n",
      "        [-2.3897, -1.4945, 35.2742, -7.1212, -7.4428,  0.5589, -2.7014, -6.9181,\n",
      "         -3.5838, -3.3277],\n",
      "        [-2.0621, -1.1828, 32.5099, -6.3957, -6.8665,  1.2849, -2.5037, -7.3870,\n",
      "         -3.5864, -3.4483],\n",
      "        [-1.7861, -1.0657, 30.3560, -5.6887, -6.3755,  1.4054, -2.3779, -7.0878,\n",
      "         -3.0882, -3.7495],\n",
      "        [-2.3169, -1.6038, 35.6213, -7.4814, -7.4815,  0.5981, -2.8846, -7.2178,\n",
      "         -4.0226, -3.2765],\n",
      "        [-1.4819, -1.6731, 29.9516, -6.3631, -6.2238,  0.8062, -2.4704, -6.1043,\n",
      "         -3.1349, -2.8392],\n",
      "        [-1.9028, -1.2291, 26.8754, -4.7449, -5.2821,  1.8123, -2.3265, -7.1640,\n",
      "         -2.7652, -2.5568],\n",
      "        [-2.3106, -1.5703, 35.8160, -7.4954, -7.6766,  0.5274, -2.8608, -7.1656,\n",
      "         -4.1393, -3.3306],\n",
      "        [-1.8845, -1.3195, 32.8230, -6.8069, -6.7366,  0.6211, -2.7329, -6.7741,\n",
      "         -3.8968, -3.0071],\n",
      "        [-1.3479, -1.7458, 27.7206, -5.7109, -5.9483,  0.8027, -1.9345, -5.5390,\n",
      "         -3.1268, -2.4509],\n",
      "        [-2.4047, -1.4081, 32.1246, -5.6743, -6.1884,  1.7625, -2.6289, -8.4090,\n",
      "         -3.5232, -3.0183],\n",
      "        [-2.1219, -1.3765, 32.2684, -6.1546, -6.9744,  1.0769, -2.8642, -7.3236,\n",
      "         -3.5306, -2.9849],\n",
      "        [-2.4126, -1.3463, 31.4046, -5.6777, -5.7502,  1.7813, -2.4492, -8.3287,\n",
      "         -3.3461, -3.0933],\n",
      "        [-2.4665, -1.3421, 31.5443, -5.7407, -6.0451,  1.5064, -2.5499, -8.1684,\n",
      "         -3.4229, -2.9535],\n",
      "        [-1.8352, -1.6484, 32.7303, -6.9426, -6.7656,  0.6122, -2.6623, -6.6477,\n",
      "         -3.6529, -3.0030],\n",
      "        [-1.7434, -1.3761, 26.3300, -4.8384, -5.1503,  1.9037, -2.1937, -6.8897,\n",
      "         -2.9641, -2.4163],\n",
      "        [-1.7049, -1.1346, 30.1113, -5.6637, -6.1954,  1.4281, -2.4007, -7.1265,\n",
      "         -3.0432, -3.4712],\n",
      "        [-2.1405, -1.4648, 31.8213, -5.6576, -6.1999,  1.7806, -2.5537, -8.1874,\n",
      "         -3.2635, -3.2864],\n",
      "        [-1.8392, -1.1068, 31.7400, -6.4945, -6.4172,  0.5069, -2.5926, -6.4474,\n",
      "         -3.6292, -2.8992],\n",
      "        [-1.8980, -1.5592, 33.2248, -7.1172, -7.0945,  0.6845, -2.6833, -6.6154,\n",
      "         -3.8368, -3.1230],\n",
      "        [-1.7863, -1.0226, 27.8522, -4.7274, -5.7683,  1.5715, -2.5140, -6.9906,\n",
      "         -2.8328, -2.4332],\n",
      "        [-1.9136, -1.0583, 31.8901, -6.5234, -6.4484,  0.5601, -2.5169, -6.3554,\n",
      "         -3.4054, -2.8764],\n",
      "        [-1.7975, -1.6542, 31.3083, -6.3139, -6.4871,  0.8902, -2.2842, -6.3777,\n",
      "         -3.2469, -2.8530],\n",
      "        [-2.1071, -1.3125, 29.6953, -5.2929, -5.6690,  1.9892, -2.3760, -7.9982,\n",
      "         -2.9203, -2.7728],\n",
      "        [-2.0720, -1.4735, 34.2816, -7.3254, -7.2680,  0.5657, -2.7228, -6.7278,\n",
      "         -4.0056, -3.1999],\n",
      "        [-1.8675, -1.5321, 31.6052, -6.6866, -7.1049,  0.3705, -2.4951, -6.2455,\n",
      "         -3.5540, -2.9228],\n",
      "        [-2.0651, -1.0232, 31.5955, -6.3961, -6.3425,  0.6972, -2.5264, -6.4795,\n",
      "         -3.4581, -2.8786],\n",
      "        [-2.2667, -1.4711, 32.6075, -5.9422, -6.3076,  1.6401, -2.5722, -8.1403,\n",
      "         -3.3573, -3.4078]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y tensor([4, 4, 7, 7, 3, 4, 9, 9, 3, 0, 5, 4, 1, 0, 7, 8, 7, 7, 3, 5, 9, 9, 1, 3,\n",
      "        8, 1, 6, 5, 3, 6, 1, 7], device='cuda:0')\n",
      "loss_ce tensor(36.2657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "ep0, loss_cs: -36.265720, loss_cos: 0.506385, loss_obj: -17.879667, lr: 0.05\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-2.8461e+00, -3.3053e+00,  4.8698e+01, -8.8295e+00, -8.6236e+00,\n",
      "         -2.9198e-01, -3.7080e+00, -1.0683e+01, -4.1316e+00, -6.4945e+00],\n",
      "        [-3.2017e+00, -4.7582e+00,  5.3196e+01, -1.0473e+01, -9.9855e+00,\n",
      "         -6.4425e-01, -3.8129e+00, -1.0162e+01, -4.7459e+00, -5.1498e+00],\n",
      "        [-2.4264e+00, -3.5484e+00,  4.5989e+01, -9.3540e+00, -8.8975e+00,\n",
      "         -4.9025e-01, -3.6167e+00, -8.7119e+00, -4.3589e+00, -5.1371e+00],\n",
      "        [-2.7276e+00, -4.0723e+00,  4.9046e+01, -9.7963e+00, -9.6750e+00,\n",
      "         -5.6191e-01, -3.4614e+00, -9.3252e+00, -4.7166e+00, -4.8241e+00],\n",
      "        [-3.0118e+00, -4.1637e+00,  5.1129e+01, -9.9337e+00, -9.7183e+00,\n",
      "         -4.5150e-01, -3.7630e+00, -9.8507e+00, -4.8184e+00, -5.0795e+00],\n",
      "        [-3.0825e+00, -4.4206e+00,  5.2488e+01, -1.0824e+01, -1.0010e+01,\n",
      "         -5.0945e-01, -3.8042e+00, -9.9310e+00, -4.9193e+00, -5.1291e+00],\n",
      "        [-2.8916e+00, -3.9943e+00,  5.0133e+01, -9.6836e+00, -9.6568e+00,\n",
      "         -4.1648e-01, -3.6158e+00, -9.6722e+00, -4.6939e+00, -5.1792e+00],\n",
      "        [-2.7763e+00, -3.8916e+00,  4.8377e+01, -9.3536e+00, -9.4874e+00,\n",
      "         -6.3781e-01, -3.5273e+00, -9.2682e+00, -4.5015e+00, -5.0207e+00],\n",
      "        [-3.1757e+00, -4.6049e+00,  5.2630e+01, -1.0539e+01, -9.9727e+00,\n",
      "         -6.0063e-01, -3.7860e+00, -1.0055e+01, -4.7412e+00, -5.0077e+00],\n",
      "        [-2.9317e+00, -3.2531e+00,  4.8152e+01, -8.4043e+00, -8.3400e+00,\n",
      "         -1.2336e-01, -3.3622e+00, -1.1686e+01, -4.2213e+00, -5.1465e+00],\n",
      "        [-2.9852e+00, -4.1376e+00,  5.1198e+01, -1.0184e+01, -9.8269e+00,\n",
      "         -5.3774e-01, -3.6867e+00, -9.7363e+00, -4.8232e+00, -5.2233e+00],\n",
      "        [-2.5146e+00, -3.8550e+00,  4.6492e+01, -9.0619e+00, -9.1642e+00,\n",
      "         -5.3531e-01, -3.5102e+00, -8.8062e+00, -4.4959e+00, -4.8467e+00],\n",
      "        [-2.9936e+00, -4.4045e+00,  5.3014e+01, -1.0790e+01, -9.8785e+00,\n",
      "         -6.6034e-01, -3.8499e+00, -1.0264e+01, -5.1005e+00, -5.3723e+00],\n",
      "        [-2.9862e+00, -3.3405e+00,  4.9989e+01, -8.7631e+00, -8.6526e+00,\n",
      "         -2.7462e-01, -3.4412e+00, -1.1690e+01, -4.5008e+00, -5.5892e+00],\n",
      "        [-3.1710e+00, -4.5959e+00,  5.2160e+01, -1.0306e+01, -9.8689e+00,\n",
      "         -6.3048e-01, -3.6560e+00, -9.9067e+00, -4.5469e+00, -5.0545e+00],\n",
      "        [-3.1784e+00, -4.6277e+00,  5.2244e+01, -1.0516e+01, -9.9343e+00,\n",
      "         -6.1282e-01, -3.7890e+00, -9.9318e+00, -4.6862e+00, -4.9262e+00],\n",
      "        [-2.8668e+00, -3.3456e+00,  4.8801e+01, -8.5109e+00, -8.4206e+00,\n",
      "         -3.3891e-01, -3.3767e+00, -1.1417e+01, -4.2681e+00, -5.4340e+00],\n",
      "        [-2.8295e+00, -3.0775e+00,  4.7839e+01, -8.5404e+00, -8.7090e+00,\n",
      "         -5.5193e-01, -3.7322e+00, -1.0472e+01, -4.2448e+00, -6.4740e+00],\n",
      "        [-2.5978e+00, -3.1841e+00,  4.7245e+01, -8.5933e+00, -8.9062e+00,\n",
      "         -5.2085e-01, -3.5146e+00, -1.0197e+01, -4.7777e+00, -5.3719e+00],\n",
      "        [-2.9451e+00, -3.3342e+00,  4.9502e+01, -8.8523e+00, -8.9533e+00,\n",
      "         -3.2716e-01, -3.7974e+00, -1.0810e+01, -4.3886e+00, -6.7738e+00],\n",
      "        [-2.5727e+00, -3.6163e+00,  4.6528e+01, -8.9328e+00, -9.3558e+00,\n",
      "         -6.5264e-01, -3.3800e+00, -8.7506e+00, -4.3170e+00, -5.0692e+00],\n",
      "        [-3.0252e+00, -3.5118e+00,  5.0366e+01, -8.6216e+00, -8.7456e+00,\n",
      "         -3.3131e-02, -3.4505e+00, -1.1819e+01, -4.6701e+00, -5.5956e+00],\n",
      "        [-2.9099e+00, -3.9627e+00,  5.0453e+01, -9.7543e+00, -9.7462e+00,\n",
      "         -5.4856e-01, -3.6454e+00, -9.7378e+00, -4.9033e+00, -5.2204e+00],\n",
      "        [-3.1859e+00, -4.5147e+00,  5.2336e+01, -9.8854e+00, -9.8341e+00,\n",
      "         -5.2246e-01, -3.6176e+00, -1.0429e+01, -4.6673e+00, -5.3370e+00],\n",
      "        [-2.8492e+00, -3.9666e+00,  4.9724e+01, -9.5042e+00, -9.6978e+00,\n",
      "         -5.0836e-01, -3.5823e+00, -9.4873e+00, -4.6387e+00, -5.3361e+00],\n",
      "        [-2.9566e+00, -4.1351e+00,  5.1628e+01, -1.0197e+01, -9.8571e+00,\n",
      "         -5.9983e-01, -3.6606e+00, -9.7942e+00, -4.7996e+00, -5.3990e+00],\n",
      "        [-2.4586e+00, -3.3754e+00,  4.4709e+01, -9.0311e+00, -8.7043e+00,\n",
      "         -3.2000e-01, -3.5345e+00, -8.5140e+00, -4.1123e+00, -4.9634e+00],\n",
      "        [-2.9000e+00, -4.3201e+00,  5.0560e+01, -1.0136e+01, -9.7274e+00,\n",
      "         -4.1855e-01, -3.4987e+00, -9.4819e+00, -4.6162e+00, -5.2487e+00],\n",
      "        [-2.2407e+00, -2.8794e+00,  4.3206e+01, -7.3568e+00, -8.0519e+00,\n",
      "         -4.7152e-01, -3.0599e+00, -9.6859e+00, -4.0104e+00, -4.4812e+00],\n",
      "        [-3.0930e+00, -3.4058e+00,  5.0099e+01, -8.7462e+00, -8.8044e+00,\n",
      "         -1.0823e-01, -3.5320e+00, -1.1487e+01, -4.5462e+00, -5.7630e+00],\n",
      "        [-3.0851e+00, -4.3952e+00,  5.2840e+01, -1.0739e+01, -1.0124e+01,\n",
      "         -5.7208e-01, -3.7246e+00, -1.0042e+01, -4.8661e+00, -5.3341e+00],\n",
      "        [-2.7760e+00, -4.1706e+00,  4.9351e+01, -1.0103e+01, -9.5478e+00,\n",
      "         -4.6206e-01, -3.5051e+00, -9.1963e+00, -4.6185e+00, -4.8921e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y tensor([7, 1, 8, 0, 2, 0, 2, 4, 1, 7, 4, 2, 3, 7, 1, 1, 7, 9, 8, 9, 6, 7, 4, 8,\n",
      "        2, 4, 8, 0, 6, 9, 3, 0], device='cuda:0')\n",
      "loss_ce tensor(49.4945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-5.7553e+00, -6.5319e+00,  7.1807e+01, -1.1407e+01, -1.2507e+01,\n",
      "         -5.6599e-01, -5.0727e+00, -1.4695e+01, -7.3274e+00, -7.7555e+00],\n",
      "        [-4.7577e+00, -6.2273e+00,  6.0113e+01, -9.8071e+00, -1.0350e+01,\n",
      "         -4.7920e-01, -4.2109e+00, -1.1274e+01, -6.0573e+00, -5.9245e+00],\n",
      "        [-5.0873e+00, -5.7307e+00,  6.7324e+01, -9.9976e+00, -1.1250e+01,\n",
      "         -7.1402e-02, -4.7524e+00, -1.5145e+01, -6.5207e+00, -8.3825e+00],\n",
      "        [-5.0762e+00, -6.6067e+00,  6.3929e+01, -1.0088e+01, -1.1187e+01,\n",
      "         -6.2546e-01, -4.2905e+00, -1.2354e+01, -6.1779e+00, -6.8266e+00],\n",
      "        [-5.7641e+00, -7.7000e+00,  7.2626e+01, -1.2216e+01, -1.2850e+01,\n",
      "         -7.8441e-01, -4.8933e+00, -1.3502e+01, -7.3041e+00, -7.3284e+00],\n",
      "        [-4.7177e+00, -5.1292e+00,  6.1504e+01, -9.1359e+00, -1.0077e+01,\n",
      "          3.0224e-02, -4.4004e+00, -1.4416e+01, -5.8014e+00, -7.3829e+00],\n",
      "        [-5.1258e+00, -5.8461e+00,  6.2613e+01, -1.0189e+01, -1.0817e+01,\n",
      "         -3.6890e-01, -4.4987e+00, -1.2670e+01, -6.5218e+00, -6.4417e+00],\n",
      "        [-5.2277e+00, -5.9140e+00,  6.8415e+01, -1.0193e+01, -1.1263e+01,\n",
      "         -6.8389e-02, -4.6554e+00, -1.5445e+01, -6.6370e+00, -8.3352e+00],\n",
      "        [-5.9847e+00, -7.4007e+00,  7.4334e+01, -1.2895e+01, -1.3330e+01,\n",
      "         -6.8684e-01, -5.1019e+00, -1.3825e+01, -7.7314e+00, -7.6203e+00],\n",
      "        [-5.7445e+00, -6.8195e+00,  7.1079e+01, -1.2160e+01, -1.2768e+01,\n",
      "         -6.4348e-01, -4.9331e+00, -1.2837e+01, -7.3996e+00, -7.5341e+00],\n",
      "        [-5.8921e+00, -7.5041e+00,  7.3965e+01, -1.2884e+01, -1.3295e+01,\n",
      "         -6.9187e-01, -5.0871e+00, -1.3722e+01, -7.6788e+00, -7.5490e+00],\n",
      "        [-6.0738e+00, -7.2327e+00,  7.3043e+01, -1.2477e+01, -1.3223e+01,\n",
      "         -6.2781e-01, -4.9959e+00, -1.3186e+01, -7.2144e+00, -7.6877e+00],\n",
      "        [-5.2748e+00, -5.8340e+00,  6.7209e+01, -1.0631e+01, -1.1936e+01,\n",
      "         -4.4927e-01, -4.9694e+00, -1.3680e+01, -7.2088e+00, -7.4013e+00],\n",
      "        [-5.5170e+00, -7.1771e+00,  7.0197e+01, -1.1654e+01, -1.2639e+01,\n",
      "         -7.2157e-01, -4.9297e+00, -1.2791e+01, -6.9259e+00, -7.1555e+00],\n",
      "        [-5.7985e+00, -7.2620e+00,  7.2293e+01, -1.2203e+01, -1.2953e+01,\n",
      "         -8.0946e-01, -4.9097e+00, -1.3105e+01, -7.3417e+00, -7.4915e+00],\n",
      "        [-5.9756e+00, -7.4048e+00,  7.4526e+01, -1.2400e+01, -1.3453e+01,\n",
      "         -8.4190e-01, -4.9910e+00, -1.3909e+01, -7.4973e+00, -7.8657e+00],\n",
      "        [-5.9787e+00, -7.1436e+00,  7.4549e+01, -1.2320e+01, -1.3322e+01,\n",
      "         -7.3810e-01, -5.1045e+00, -1.4127e+01, -7.4803e+00, -8.0959e+00],\n",
      "        [-5.1750e+00, -5.6961e+00,  6.8206e+01, -1.0111e+01, -1.1397e+01,\n",
      "         -1.9941e-01, -4.9276e+00, -1.5406e+01, -6.6610e+00, -8.3958e+00],\n",
      "        [-5.6060e+00, -6.4060e+00,  6.9898e+01, -1.0630e+01, -1.1378e+01,\n",
      "         -3.6620e-01, -4.7542e+00, -1.5685e+01, -6.9441e+00, -7.7626e+00],\n",
      "        [-3.9778e+00, -5.6611e+00,  5.2492e+01, -8.2761e+00, -9.0659e+00,\n",
      "         -3.2236e-01, -3.5795e+00, -9.9524e+00, -5.4250e+00, -5.0770e+00],\n",
      "        [-5.0307e+00, -5.7761e+00,  6.6237e+01, -9.8304e+00, -1.0801e+01,\n",
      "         -3.9144e-02, -4.5339e+00, -1.5044e+01, -6.3151e+00, -8.1631e+00],\n",
      "        [-5.5506e+00, -7.5535e+00,  7.1658e+01, -1.2043e+01, -1.2602e+01,\n",
      "         -7.2983e-01, -4.8736e+00, -1.3249e+01, -7.2118e+00, -7.2178e+00],\n",
      "        [-5.9086e+00, -7.4528e+00,  7.2710e+01, -1.2643e+01, -1.2921e+01,\n",
      "         -6.3076e-01, -4.9805e+00, -1.3419e+01, -7.4876e+00, -7.4283e+00],\n",
      "        [-5.7624e+00, -7.0983e+00,  7.2457e+01, -1.2188e+01, -1.3064e+01,\n",
      "         -6.6785e-01, -4.9705e+00, -1.3124e+01, -7.5205e+00, -7.5897e+00],\n",
      "        [-6.0497e+00, -7.6827e+00,  7.5677e+01, -1.2910e+01, -1.3526e+01,\n",
      "         -8.0982e-01, -5.1233e+00, -1.4025e+01, -7.7160e+00, -7.8809e+00],\n",
      "        [-5.5132e+00, -6.1116e+00,  6.9743e+01, -1.0540e+01, -1.1365e+01,\n",
      "         -1.6061e-01, -4.8162e+00, -1.5871e+01, -6.9110e+00, -7.7710e+00],\n",
      "        [-5.8048e+00, -7.0210e+00,  7.2512e+01, -1.1873e+01, -1.2954e+01,\n",
      "         -8.4117e-01, -5.0149e+00, -1.3705e+01, -7.1277e+00, -7.8254e+00],\n",
      "        [-5.9408e+00, -7.0822e+00,  7.3327e+01, -1.2200e+01, -1.3256e+01,\n",
      "         -7.7224e-01, -5.1074e+00, -1.3801e+01, -7.3009e+00, -7.9118e+00],\n",
      "        [-6.0918e+00, -7.3998e+00,  7.4622e+01, -1.2712e+01, -1.3509e+01,\n",
      "         -7.4054e-01, -5.0993e+00, -1.3515e+01, -7.5204e+00, -7.9018e+00],\n",
      "        [-5.4885e+00, -6.2118e+00,  6.9253e+01, -1.0363e+01, -1.1168e+01,\n",
      "         -2.0544e-01, -4.6881e+00, -1.5675e+01, -6.8308e+00, -7.7797e+00],\n",
      "        [-5.8560e+00, -6.8688e+00,  7.2236e+01, -1.1900e+01, -1.3110e+01,\n",
      "         -7.3459e-01, -5.0373e+00, -1.3664e+01, -7.1838e+00, -7.8282e+00],\n",
      "        [-5.9084e+00, -6.8750e+00,  7.2792e+01, -1.2094e+01, -1.3147e+01,\n",
      "         -6.7007e-01, -5.2530e+00, -1.3967e+01, -7.1381e+00, -7.9301e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "y tensor([6, 2, 9, 6, 1, 5, 4, 7, 3, 6, 3, 6, 8, 4, 0, 6, 2, 5, 7, 6, 7, 1, 3, 2,\n",
      "        3, 5, 4, 6, 6, 7, 4, 6], device='cuda:0')\n",
      "loss_ce tensor(70.9132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[ -6.9579,  -9.1037,  93.8224, -16.1663, -15.8644,  -2.6237, -11.4535,\n",
      "         -16.0333,  -8.2925,  -7.7609],\n",
      "        [ -6.4786,  -7.7762,  83.1137, -14.5117, -14.3583,  -2.1325, -10.3852,\n",
      "         -13.6664,  -7.3064,  -6.9053],\n",
      "        [ -6.6181,  -8.1695,  90.1632, -15.4601, -14.8825,  -2.5663, -10.8998,\n",
      "         -15.7211,  -8.2908,  -7.8081],\n",
      "        [ -6.9475,  -8.3354,  91.6037, -15.3223, -15.9008,  -2.5992, -11.2392,\n",
      "         -15.6524,  -7.9707,  -7.8388],\n",
      "        [ -6.8379,  -9.3869,  91.7415, -15.5599, -15.5581,  -2.6142, -11.2934,\n",
      "         -15.3416,  -7.7390,  -7.3479],\n",
      "        [ -6.5546,  -8.0244,  94.3027, -14.1279, -15.2788,  -2.6966, -11.0998,\n",
      "         -19.2552,  -8.1255,  -9.0135],\n",
      "        [ -7.0724,  -8.9968,  91.4926, -15.3349, -15.6316,  -2.5278, -11.1513,\n",
      "         -15.8694,  -7.8207,  -7.3899],\n",
      "        [ -6.9731,  -9.1544,  91.8204, -15.5041, -15.6605,  -2.5644, -11.2335,\n",
      "         -15.4992,  -7.7965,  -7.3622],\n",
      "        [ -7.1162,  -9.5709,  94.2222, -15.8689, -15.8997,  -2.6697, -11.4561,\n",
      "         -16.1590,  -7.9636,  -7.5674],\n",
      "        [ -5.7488,  -7.2366,  86.6158, -14.1617, -14.5293,  -2.2696, -10.9658,\n",
      "         -15.3781,  -8.1070,  -8.6986],\n",
      "        [ -5.7241,  -7.0599,  86.3981, -13.5444, -14.5028,  -2.4911, -10.6237,\n",
      "         -16.1667,  -8.1183,  -7.9408],\n",
      "        [ -6.1968,  -7.2976,  83.9679, -13.4837, -14.5781,  -2.2656, -10.4198,\n",
      "         -14.7965,  -7.3402,  -7.2873],\n",
      "        [ -6.5109,  -8.0412,  94.7135, -14.0936, -15.0626,  -2.5723, -10.9350,\n",
      "         -19.9444,  -8.1726,  -8.9660],\n",
      "        [ -6.8042,  -8.3014,  89.8476, -15.2333, -15.2701,  -2.4207, -10.9204,\n",
      "         -15.4058,  -8.0089,  -7.4625],\n",
      "        [ -6.4319,  -8.0439,  93.1963, -14.3418, -15.1181,  -2.6672, -11.1723,\n",
      "         -17.9433,  -7.9238,  -9.6270],\n",
      "        [ -6.2208,  -8.7686,  86.6470, -14.1330, -14.6629,  -2.2664, -10.6981,\n",
      "         -14.7321,  -7.1096,  -7.1890],\n",
      "        [ -6.5784,  -8.0180,  95.6423, -14.3435, -15.2430,  -2.6361, -11.2154,\n",
      "         -19.8385,  -8.4760,  -9.1238],\n",
      "        [ -6.5127,  -8.4312,  84.8503, -14.6845, -14.4701,  -2.4154, -10.5094,\n",
      "         -14.1432,  -7.0721,  -6.8523],\n",
      "        [ -6.9178,  -8.6054,  92.6046, -15.9383, -15.6776,  -2.6215, -11.3198,\n",
      "         -15.9786,  -8.4314,  -7.6915],\n",
      "        [ -5.9905,  -6.9102,  79.7873, -13.1526, -14.2581,  -2.2308,  -9.9835,\n",
      "         -13.5765,  -6.9820,  -7.0925],\n",
      "        [ -6.1535,  -7.4925,  91.3764, -13.8867, -14.7620,  -2.4667, -11.0014,\n",
      "         -17.8753,  -7.8493,  -9.9006],\n",
      "        [ -7.1663,  -9.3524,  93.6286, -15.7714, -15.8730,  -2.6133, -11.4282,\n",
      "         -16.0454,  -7.9226,  -7.5722],\n",
      "        [ -6.2208,  -7.5200,  92.3487, -13.6205, -14.5613,  -2.6898, -10.7671,\n",
      "         -19.5117,  -8.1273,  -9.0835],\n",
      "        [ -5.9826,  -7.3983,  90.2384, -13.0497, -14.2694,  -2.5477, -10.4466,\n",
      "         -18.9129,  -7.8020,  -8.9105],\n",
      "        [ -6.5401,  -7.9268,  87.3594, -14.5296, -15.2613,  -2.4152, -10.8557,\n",
      "         -14.8289,  -7.6127,  -7.5148],\n",
      "        [ -6.7946,  -8.7446,  87.6231, -14.6747, -14.6782,  -2.4404, -10.6197,\n",
      "         -15.6851,  -7.1979,  -7.0706],\n",
      "        [ -6.7587,  -8.5246,  88.3089, -15.3059, -15.1296,  -2.4459, -10.9331,\n",
      "         -14.4825,  -7.6802,  -7.2375],\n",
      "        [ -7.1602,  -8.8693,  92.4865, -15.8323, -15.8421,  -2.4913, -11.2841,\n",
      "         -15.5864,  -7.9793,  -7.5393],\n",
      "        [ -7.0648,  -9.5791,  94.0669, -15.8010, -15.8186,  -2.6568, -11.4288,\n",
      "         -16.1271,  -7.8887,  -7.5351],\n",
      "        [ -6.3833,  -7.7927,  93.4559, -13.7947, -14.8305,  -2.6311, -10.7992,\n",
      "         -19.3799,  -8.1477,  -9.0120],\n",
      "        [ -6.0024,  -7.3224,  90.1308, -13.3983, -14.3782,  -2.7183, -10.5269,\n",
      "         -18.5250,  -7.9920,  -8.5872],\n",
      "        [ -6.1583,  -7.3751,  90.0463, -13.4981, -14.7880,  -2.3979, -10.7693,\n",
      "         -18.1700,  -8.2796,  -8.5297]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([3, 0, 3, 4, 1, 7, 1, 1, 1, 5, 8, 2, 7, 3, 9, 4, 7, 0, 3, 8, 9, 1, 7, 5,\n",
      "        6, 0, 0, 0, 1, 5, 5, 8], device='cuda:0')\n",
      "loss_ce tensor(97.7888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-10.1027, -12.8675, 115.2410, -17.4257, -17.1990,  -5.3284, -12.2678,\n",
      "         -19.8447,  -9.4399, -10.2232],\n",
      "        [ -9.6929, -12.0802, 110.4582, -17.4479, -16.6281,  -4.9251, -11.7750,\n",
      "         -18.1894,  -9.8808,  -9.4463],\n",
      "        [ -9.9352, -12.7839, 113.5502, -17.0836, -16.6768,  -5.3049, -11.9015,\n",
      "         -19.7329,  -9.3823, -10.2822],\n",
      "        [ -8.0480,  -9.3893,  98.0438, -13.6090, -13.6604,  -4.8717, -10.0192,\n",
      "         -19.9633,  -8.3455,  -9.9846],\n",
      "        [-10.4130, -12.8027, 116.1435, -18.5427, -17.5116,  -5.2355, -12.3490,\n",
      "         -19.2804, -10.3096,  -9.7218],\n",
      "        [-10.3093, -12.8917, 115.6594, -18.3114, -17.4463,  -5.1782, -12.3305,\n",
      "         -19.0924, -10.2207,  -9.7858],\n",
      "        [ -7.3814,  -8.5150,  90.4914, -12.3270, -12.4529,  -4.3471,  -9.1562,\n",
      "         -19.1302,  -7.6967,  -9.1706],\n",
      "        [-10.2258, -12.9552, 114.9211, -18.0274, -17.2381,  -5.1816, -12.1731,\n",
      "         -19.1497, -10.0368,  -9.5759],\n",
      "        [-10.2869, -12.8368, 117.4641, -17.8743, -17.4615,  -5.5038, -12.4074,\n",
      "         -20.3686,  -9.7514, -10.6818],\n",
      "        [ -9.5003, -11.1074, 107.0313, -16.8754, -15.9476,  -4.8730, -11.3636,\n",
      "         -18.5370,  -9.9159,  -9.0159],\n",
      "        [ -9.7631, -12.4115, 111.3669, -17.2313, -16.6608,  -5.0543, -11.8302,\n",
      "         -18.7329,  -9.8298,  -9.2612],\n",
      "        [ -9.7532, -11.7978, 112.0842, -16.8264, -16.0088,  -5.3455, -11.6225,\n",
      "         -20.7382,  -9.1663, -10.2039],\n",
      "        [-10.5607, -13.2736, 119.3620, -18.4296, -17.8597,  -5.5243, -12.6371,\n",
      "         -20.2768, -10.0669, -10.5779],\n",
      "        [ -8.6680,  -9.7313, 101.5589, -14.2779, -14.2254,  -4.9583, -10.3751,\n",
      "         -20.5661,  -8.6259,  -9.6436],\n",
      "        [ -9.9492, -12.3151, 112.1043, -17.9254, -17.2097,  -4.9604, -12.0268,\n",
      "         -18.3604, -10.1689,  -9.3229],\n",
      "        [-10.1839, -12.5800, 115.1188, -18.0998, -17.2871,  -5.1829, -12.1549,\n",
      "         -19.0849, -10.3115,  -9.7617],\n",
      "        [ -9.9890, -12.7123, 115.3779, -17.6182, -17.2137,  -5.3364, -12.1337,\n",
      "         -19.7960,  -9.7211, -10.3434],\n",
      "        [ -8.9594, -10.2865, 104.3793, -14.9401, -14.6646,  -5.0051, -10.6281,\n",
      "         -20.8460,  -8.8180,  -9.9035],\n",
      "        [ -7.8703,  -9.2041,  96.6693, -13.7197, -13.6007,  -4.6137,  -9.9502,\n",
      "         -19.0229,  -8.1676,  -9.9986],\n",
      "        [ -8.2350,  -9.4880,  99.3710, -13.9646, -13.8753,  -4.8674, -10.1823,\n",
      "         -20.2237,  -8.5509,  -9.8663],\n",
      "        [-10.1282, -12.7019, 116.1955, -17.5950, -17.1054,  -5.4968, -12.2565,\n",
      "         -20.2956,  -9.4827, -10.7254],\n",
      "        [-10.5405, -13.3878, 119.4516, -18.2450, -17.6675,  -5.6325, -12.5390,\n",
      "         -20.6651,  -9.9667, -10.5564],\n",
      "        [-10.6809, -13.3133, 120.8242, -18.8780, -18.1689,  -5.6024, -12.8176,\n",
      "         -20.5222, -10.3649, -10.5062],\n",
      "        [ -9.5845, -12.4934, 109.3116, -16.6650, -16.2914,  -4.9500, -11.4952,\n",
      "         -18.4954,  -9.4324,  -9.2208],\n",
      "        [ -7.8825,  -9.2299,  95.9960, -13.6576, -13.3715,  -4.5942,  -9.7722,\n",
      "         -18.9933,  -8.0038,  -9.8731],\n",
      "        [ -7.9745,  -9.1016,  95.4388, -13.3326, -13.2522,  -4.6030,  -9.6814,\n",
      "         -19.5014,  -8.0473,  -9.3740],\n",
      "        [ -9.5417, -12.1053, 108.4186, -17.3901, -16.7765,  -4.7014, -11.7417,\n",
      "         -17.2328,  -9.7234,  -9.2169],\n",
      "        [-10.1954, -12.5357, 116.3281, -17.8964, -17.4220,  -5.3365, -12.3043,\n",
      "         -20.0047, -10.0200, -10.3870],\n",
      "        [ -9.1121, -10.5084, 103.7158, -15.0995, -14.5809,  -4.7713, -10.6418,\n",
      "         -20.3201,  -8.6421,  -9.4779],\n",
      "        [-10.7290, -12.7026, 118.3681, -18.9769, -17.8597,  -5.2367, -12.5956,\n",
      "         -20.0135, -10.5129, -10.3419],\n",
      "        [-10.1913, -12.6889, 115.0006, -17.9810, -17.3094,  -5.1614, -12.2309,\n",
      "         -19.1702, -10.1084,  -9.8593],\n",
      "        [ -8.5124,  -9.7513,  99.6631, -14.3240, -14.3000,  -4.7203, -10.3050,\n",
      "         -19.8049,  -8.5895,  -8.9278]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([4, 0, 1, 9, 0, 0, 9, 1, 4, 3, 1, 8, 2, 7, 3, 0, 6, 7, 9, 9, 2, 2, 4, 1,\n",
      "        9, 7, 0, 6, 7, 6, 6, 5], device='cuda:0')\n",
      "loss_ce tensor(110.3685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-13.7980, -16.4405, 139.9534, -18.6718, -19.4443,  -6.1242, -15.0870,\n",
      "         -24.4523, -10.3940, -15.0561],\n",
      "        [-13.4071, -16.8141, 130.9710, -19.2484, -19.3372,  -5.4674, -14.6318,\n",
      "         -20.5102, -10.1409, -11.0741],\n",
      "        [-12.1189, -13.8944, 127.0317, -17.9572, -18.4629,  -6.0485, -13.9332,\n",
      "         -21.2335, -10.9037, -12.1703],\n",
      "        [-12.0573, -14.6904, 117.6666, -16.9721, -17.3463,  -5.0469, -13.4826,\n",
      "         -19.2223,  -9.2063,  -9.8647],\n",
      "        [-12.0809, -14.6063, 120.3821, -17.3594, -18.0121,  -5.3554, -13.6423,\n",
      "         -19.0532,  -9.7016, -10.3191],\n",
      "        [-12.8823, -15.6582, 128.7223, -18.7805, -19.2460,  -5.6934, -14.4785,\n",
      "         -20.3828, -10.5266, -11.0941],\n",
      "        [-14.1664, -15.9449, 144.6819, -19.3105, -19.9659,  -6.6310, -15.4029,\n",
      "         -26.1306, -11.3572, -15.3253],\n",
      "        [-13.0482, -15.2118, 126.7154, -18.6767, -18.8011,  -5.5343, -14.1942,\n",
      "         -20.2662, -10.3038, -10.8391],\n",
      "        [-12.5482, -14.0891, 133.3355, -16.8935, -18.0763,  -6.0724, -14.2505,\n",
      "         -25.1591, -10.3456, -15.3846],\n",
      "        [ -9.7543, -11.4364,  99.3067, -13.4581, -13.7715,  -4.1203, -11.0375,\n",
      "         -16.9103,  -7.3608,  -9.8876],\n",
      "        [-14.0778, -16.5875, 135.4934, -20.4396, -19.9513,  -5.6959, -15.0728,\n",
      "         -21.3213, -10.9655, -11.7263],\n",
      "        [-14.4000, -16.8589, 145.3758, -19.9161, -20.7031,  -6.6874, -15.8538,\n",
      "         -24.7802, -11.5424, -15.0214],\n",
      "        [-13.3118, -15.0867, 136.9550, -18.2945, -18.9369,  -6.3832, -14.5294,\n",
      "         -25.2550, -10.7766, -13.8087],\n",
      "        [-12.9725, -14.3478, 122.3010, -18.6526, -18.0361,  -5.0943, -13.8290,\n",
      "         -19.0136,  -9.9513, -10.5710],\n",
      "        [-13.9724, -17.2804, 135.4924, -20.1569, -19.9014,  -5.6231, -15.0256,\n",
      "         -21.2598, -10.6354, -11.5076],\n",
      "        [-12.9831, -14.3719, 121.3446, -18.2578, -17.9708,  -5.2364, -13.7351,\n",
      "         -19.1104,  -9.6258, -10.3647],\n",
      "        [-12.8994, -15.0093, 125.5526, -18.3200, -18.7284,  -5.5478, -14.1081,\n",
      "         -20.0761, -10.2695, -10.7873],\n",
      "        [-11.6974, -13.3458, 122.4748, -16.1521, -17.5470,  -5.7504, -13.3921,\n",
      "         -21.7878, -10.4407, -12.1011],\n",
      "        [-12.7867, -15.0659, 125.9085, -19.0905, -18.1447,  -5.2314, -13.7771,\n",
      "         -20.1266, -10.3705, -11.2141],\n",
      "        [-13.9655, -16.3733, 143.5035, -19.8819, -20.4826,  -6.6346, -15.7021,\n",
      "         -24.4268, -11.6123, -14.7510],\n",
      "        [-12.4400, -14.0936, 121.5385, -17.7680, -18.3009,  -5.4620, -13.7977,\n",
      "         -19.4442, -10.0642, -10.5469],\n",
      "        [-13.1510, -15.6251, 128.1189, -18.9675, -18.9286,  -5.5395, -14.2710,\n",
      "         -20.3174, -10.3326, -10.8205],\n",
      "        [-12.6626, -14.7362, 126.6564, -17.8750, -18.8180,  -5.9365, -14.3625,\n",
      "         -20.7599, -10.4162, -11.1863],\n",
      "        [-12.5890, -14.4453, 133.3189, -17.4196, -18.2727,  -5.9782, -14.1494,\n",
      "         -24.2742, -10.3164, -15.1881],\n",
      "        [-12.6943, -15.3969, 125.9886, -18.6051, -18.2960,  -5.3914, -13.7380,\n",
      "         -20.4339, -10.3385, -10.9295],\n",
      "        [-12.8070, -14.7133, 133.3291, -17.6335, -18.4226,  -6.3524, -14.2185,\n",
      "         -24.7169, -10.5784, -13.4377],\n",
      "        [-12.0463, -14.3522, 120.0083, -17.5494, -17.8633,  -5.2378, -13.6802,\n",
      "         -18.8566,  -9.7057, -10.3291],\n",
      "        [-13.9078, -17.0513, 134.6602, -19.9700, -19.7131,  -5.5930, -14.8429,\n",
      "         -21.3374, -10.5167, -11.5079],\n",
      "        [-14.0272, -16.0349, 144.9178, -19.4057, -20.1985,  -6.6898, -15.5711,\n",
      "         -25.8175, -11.6541, -15.3883],\n",
      "        [-14.0245, -16.9222, 139.8833, -20.5143, -20.5717,  -6.0185, -15.6626,\n",
      "         -22.4513, -11.4418, -12.4417],\n",
      "        [-14.3859, -16.8845, 145.9637, -19.7119, -20.6000,  -6.6107, -15.8462,\n",
      "         -25.4504, -11.2100, -15.2104],\n",
      "        [-12.3659, -13.8289, 131.2071, -16.7765, -17.8868,  -6.1768, -13.9463,\n",
      "         -24.7169, -10.0806, -14.6387]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([5, 1, 8, 2, 4, 4, 9, 3, 5, 6, 6, 9, 7, 0, 1, 0, 6, 8, 3, 9, 2, 3, 4, 5,\n",
      "        3, 5, 2, 1, 9, 4, 9, 5], device='cuda:0')\n",
      "loss_ce tensor(132.2454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "ep0, loss_cs: -132.245392, loss_cos: 0.528158, loss_obj: -65.858620, lr: 0.0475\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-13.9268, -15.9734, 156.8927, -20.0732, -20.8132, -10.6627, -16.4724,\n",
      "         -27.3818, -11.9879, -19.8818],\n",
      "        [-15.9906, -18.3435, 174.5573, -22.9539, -23.5280, -11.5610, -18.2953,\n",
      "         -29.6536, -13.7390, -20.5479],\n",
      "        [-17.3151, -19.9678, 174.9200, -25.1861, -25.0620, -10.2978, -19.5171,\n",
      "         -25.1915, -13.5859, -19.0972],\n",
      "        [-15.8137, -18.3200, 172.8806, -22.3219, -23.1689, -11.4541, -18.0503,\n",
      "         -29.7209, -13.4539, -20.5737],\n",
      "        [-17.6209, -20.7130, 180.4021, -25.5769, -25.7112, -10.8427, -19.8937,\n",
      "         -26.7118, -13.8480, -19.8867],\n",
      "        [-17.9919, -21.3353, 183.3351, -25.9933, -26.0277, -10.9685, -20.1301,\n",
      "         -27.0933, -14.1136, -20.0370],\n",
      "        [-17.7533, -21.1849, 178.6308, -25.6031, -25.8865, -10.3432, -19.8430,\n",
      "         -25.7396, -13.9053, -18.7152],\n",
      "        [-15.5017, -17.9142, 170.8477, -22.0856, -22.7348, -11.4641, -17.8315,\n",
      "         -29.1899, -13.2229, -21.0832],\n",
      "        [-17.0632, -21.2642, 172.4304, -24.2596, -24.6378, -10.0988, -19.1321,\n",
      "         -24.7074, -13.1511, -18.2195],\n",
      "        [-15.6556, -18.1641, 168.8706, -22.9481, -22.9096, -11.1180, -17.7232,\n",
      "         -27.3331, -13.6489, -19.5845],\n",
      "        [-17.7750, -21.2775, 177.4634, -25.7797, -25.6352, -10.2378, -19.7664,\n",
      "         -25.1118, -13.7672, -18.6838],\n",
      "        [-17.4457, -20.5340, 178.5777, -25.4428, -25.5906, -10.6347, -19.7771,\n",
      "         -26.2373, -13.7432, -19.6043],\n",
      "        [-17.2488, -21.4931, 174.7505, -24.4370, -24.8011, -10.2577, -19.1632,\n",
      "         -25.5374, -13.2538, -18.5714],\n",
      "        [-17.1573, -20.0830, 176.6141, -24.8965, -25.2044, -10.5804, -19.4947,\n",
      "         -26.0622, -13.6593, -19.4339],\n",
      "        [-17.7974, -22.0064, 178.6951, -25.6538, -25.5009, -10.3993, -19.7338,\n",
      "         -25.6087, -13.6901, -18.6693],\n",
      "        [-16.4553, -18.1754, 170.0546, -24.6366, -23.8632, -10.3589, -18.7241,\n",
      "         -25.3245, -13.8399, -18.7536],\n",
      "        [-16.8575, -20.9224, 172.7099, -23.9563, -24.3960, -10.1842, -18.9051,\n",
      "         -25.4776, -13.2481, -18.5535],\n",
      "        [-15.7305, -18.0483, 172.0001, -22.7119, -23.4009, -11.2034, -18.1010,\n",
      "         -28.8322, -13.8122, -19.9026],\n",
      "        [-14.3321, -16.8537, 161.6039, -20.4767, -21.3133, -10.9623, -16.8438,\n",
      "         -27.8534, -12.1984, -20.5852],\n",
      "        [-17.2594, -20.2042, 172.9088, -25.0061, -24.6556, -10.0427, -19.1657,\n",
      "         -24.6888, -13.4883, -18.5037],\n",
      "        [-17.7439, -21.7751, 177.9251, -25.5304, -25.4550, -10.3306, -19.6681,\n",
      "         -25.4399, -13.6939, -18.5281],\n",
      "        [-17.2394, -20.2655, 172.1815, -25.0017, -24.6752,  -9.9171, -19.1595,\n",
      "         -24.3392, -13.4036, -18.3132],\n",
      "        [-17.9294, -21.4570, 179.3682, -25.9726, -25.7073, -10.4887, -19.8427,\n",
      "         -25.7272, -13.9997, -18.7942],\n",
      "        [-17.7422, -20.7465, 177.3648, -26.1025, -25.5591, -10.1918, -19.6782,\n",
      "         -25.4819, -14.0027, -18.5953],\n",
      "        [-17.8551, -20.9420, 178.0170, -26.1673, -25.3670, -10.3553, -19.6529,\n",
      "         -25.5917, -14.1200, -18.7431],\n",
      "        [-17.1588, -20.2274, 175.4693, -24.8485, -25.3236, -10.3238, -19.4322,\n",
      "         -25.5640, -13.5804, -19.0051],\n",
      "        [-17.9107, -21.0703, 179.9307, -26.0863, -25.7444, -10.5531, -19.9529,\n",
      "         -25.9231, -13.9876, -19.1975],\n",
      "        [-15.3758, -17.9695, 168.6687, -21.7133, -22.5610, -11.2792, -17.6046,\n",
      "         -29.3159, -13.0056, -19.8139],\n",
      "        [-17.2048, -20.1968, 175.2966, -25.2049, -25.3193, -10.2811, -19.5662,\n",
      "         -25.2442, -13.6158, -18.9428],\n",
      "        [-17.4561, -20.4851, 174.1472, -25.4017, -24.9694, -10.0980, -19.3612,\n",
      "         -24.7137, -13.6959, -18.3129],\n",
      "        [-16.6305, -19.4218, 177.4880, -23.7254, -23.9394, -11.3897, -18.7566,\n",
      "         -28.8815, -13.5183, -21.2100],\n",
      "        [-17.0443, -19.4893, 174.6094, -24.7891, -25.0538, -10.5110, -19.3005,\n",
      "         -25.5559, -13.7299, -18.9500]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([5, 7, 6, 7, 4, 4, 2, 9, 6, 5, 0, 6, 1, 2, 1, 8, 1, 5, 9, 0, 1, 0, 3, 3,\n",
      "        3, 2, 1, 7, 6, 0, 5, 2], device='cuda:0')\n",
      "loss_ce tensor(170.2448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-21.0822, -25.3489, 212.7920, -27.4368, -27.4203, -16.0897, -23.8122,\n",
      "         -32.1966, -14.9167, -24.7239],\n",
      "        [-23.1842, -29.3065, 217.4406, -30.9289, -29.2010, -14.4074, -24.6423,\n",
      "         -29.4878, -15.3403, -20.7184],\n",
      "        [-21.2031, -24.9924, 204.1024, -28.3021, -27.4447, -14.5440, -23.1257,\n",
      "         -29.1205, -15.1312, -20.4926],\n",
      "        [-20.9579, -24.9340, 213.1364, -27.3678, -27.2300, -16.3684, -23.6878,\n",
      "         -32.7775, -15.0926, -25.0868],\n",
      "        [-19.7834, -23.5925, 200.8453, -26.4380, -26.6487, -14.9770, -22.5967,\n",
      "         -30.0877, -15.4823, -21.6634],\n",
      "        [-21.7634, -25.9885, 218.1476, -28.2538, -28.0149, -16.6109, -23.9044,\n",
      "         -34.1273, -15.6376, -23.9107],\n",
      "        [-22.5354, -27.4078, 215.3961, -30.3364, -29.2509, -14.8340, -24.6421,\n",
      "         -29.6833, -15.7271, -21.4716],\n",
      "        [-21.3747, -26.8036, 202.3362, -28.6797, -27.8338, -13.2945, -23.4777,\n",
      "         -27.0154, -14.5279, -19.4173],\n",
      "        [-20.9047, -25.1599, 208.5175, -27.5647, -27.2133, -15.3377, -23.5616,\n",
      "         -30.7283, -14.6746, -23.7590],\n",
      "        [-20.7342, -24.5737, 211.8931, -27.3754, -27.2108, -16.4702, -23.2452,\n",
      "         -33.1135, -15.6848, -23.4243],\n",
      "        [-21.3729, -25.1743, 217.1702, -27.6447, -27.6259, -16.8506, -23.8376,\n",
      "         -33.9887, -15.5575, -25.1776],\n",
      "        [-17.9818, -22.6481, 175.3718, -23.8025, -23.4504, -11.8755, -20.1931,\n",
      "         -24.2179, -12.5605, -17.2424],\n",
      "        [-22.3431, -27.3325, 212.9281, -30.2097, -29.0594, -14.5038, -24.4321,\n",
      "         -28.9640, -15.5693, -20.9019],\n",
      "        [-22.8910, -27.9463, 212.7934, -30.8883, -28.7222, -14.0090, -24.2635,\n",
      "         -28.8001, -15.3564, -20.2784],\n",
      "        [-22.4054, -28.1830, 212.9516, -29.8780, -28.5210, -14.5133, -24.1091,\n",
      "         -29.8638, -14.8216, -20.6030],\n",
      "        [-18.4488, -22.2941, 191.6679, -23.9785, -24.1127, -14.9997, -21.4650,\n",
      "         -29.9751, -13.0083, -23.2148],\n",
      "        [-20.7954, -25.6306, 204.1247, -28.1944, -27.8078, -14.4510, -23.2644,\n",
      "         -29.1040, -15.1136, -20.4698],\n",
      "        [-21.2648, -24.9487, 210.3533, -27.9651, -27.7980, -15.5859, -23.5675,\n",
      "         -31.5086, -16.0216, -22.1207],\n",
      "        [-18.0838, -23.3741, 175.9272, -23.8291, -23.9043, -11.9192, -20.2730,\n",
      "         -23.8390, -12.4933, -16.6970],\n",
      "        [-21.6141, -25.2275, 211.2241, -29.5972, -28.1673, -15.1891, -23.9907,\n",
      "         -30.0662, -16.1934, -21.8827],\n",
      "        [-18.8038, -23.0389, 193.9601, -25.3146, -25.9387, -14.6137, -21.8288,\n",
      "         -29.1995, -14.7086, -21.0135],\n",
      "        [-22.8919, -27.3841, 210.8283, -30.4202, -28.5063, -13.9431, -24.1141,\n",
      "         -28.5204, -15.1933, -20.3069],\n",
      "        [-21.7022, -25.8013, 218.3240, -28.4104, -28.1991, -16.6563, -24.3113,\n",
      "         -33.0630, -15.7495, -24.9055],\n",
      "        [-19.6327, -23.4857, 189.8283, -26.7146, -26.3723, -13.4736, -21.7081,\n",
      "         -26.3581, -14.2865, -18.6412],\n",
      "        [-22.8054, -27.5577, 214.3819, -30.6006, -29.0465, -14.4969, -24.4849,\n",
      "         -29.3286, -15.6115, -20.9179],\n",
      "        [-18.1849, -22.0284, 178.2780, -24.4848, -24.6565, -12.7514, -20.6329,\n",
      "         -25.0719, -13.1483, -17.2599],\n",
      "        [-22.8482, -27.8317, 214.1868, -30.7957, -28.8984, -14.3387, -24.3711,\n",
      "         -29.3723, -15.5359, -20.6596],\n",
      "        [-21.0689, -24.3425, 208.2592, -28.7798, -27.4456, -15.3056, -23.5759,\n",
      "         -29.9370, -16.0723, -22.2064],\n",
      "        [-21.3098, -25.4176, 215.0052, -27.7081, -27.6843, -16.4422, -23.7176,\n",
      "         -33.4787, -15.4382, -24.0132],\n",
      "        [-23.0102, -29.4274, 216.1127, -30.4817, -29.0107, -14.3638, -24.4845,\n",
      "         -29.4519, -15.0193, -20.5027],\n",
      "        [-22.1969, -25.9854, 205.1586, -29.4483, -27.9269, -13.7960, -23.4319,\n",
      "         -28.0042, -14.9863, -19.9430],\n",
      "        [-18.9663, -22.6725, 187.7007, -24.7446, -25.3296, -13.5646, -21.2637,\n",
      "         -27.4190, -14.2536, -19.7342]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([9, 1, 2, 9, 8, 7, 4, 6, 9, 5, 9, 2, 4, 3, 3, 5, 4, 8, 1, 8, 8, 0, 9, 6,\n",
      "        3, 2, 6, 8, 9, 1, 3, 8], device='cuda:0')\n",
      "loss_ce tensor(209.7149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-25.0674, -31.4232, 260.4282, -35.9268, -33.8767, -18.2411, -29.3055,\n",
      "         -33.6983, -22.3862, -30.4164],\n",
      "        [-20.9940, -26.6344, 235.7508, -30.2420, -28.9621, -17.7981, -25.3318,\n",
      "         -33.8705, -20.9228, -30.9577],\n",
      "        [-24.7427, -32.0332, 257.2176, -35.3027, -33.8186, -17.7059, -29.1032,\n",
      "         -33.1252, -21.7792, -29.5109],\n",
      "        [-24.0420, -29.7565, 247.7130, -35.0425, -32.7194, -17.0788, -28.0644,\n",
      "         -31.3994, -21.9930, -28.0231],\n",
      "        [-23.5482, -31.0441, 243.5896, -34.1478, -32.2020, -16.2335, -27.6933,\n",
      "         -30.8045, -21.4045, -26.9709],\n",
      "        [-22.3180, -29.9975, 234.2502, -32.3870, -31.0598, -15.6703, -26.6809,\n",
      "         -30.0666, -20.5241, -26.0229],\n",
      "        [-25.1589, -32.1465, 260.7340, -36.3546, -34.2162, -17.9579, -29.4347,\n",
      "         -33.3698, -22.5424, -29.7608],\n",
      "        [-25.0161, -31.7635, 256.2367, -35.9855, -33.6004, -17.4176, -28.9371,\n",
      "         -32.3647, -22.2260, -29.0231],\n",
      "        [-21.7747, -27.4907, 238.9662, -31.1572, -29.6304, -17.6489, -25.6436,\n",
      "         -35.2760, -20.4468, -30.0007],\n",
      "        [-22.9462, -28.3886, 249.4496, -33.0650, -31.3755, -18.4351, -27.0001,\n",
      "         -35.6526, -21.9169, -30.5253],\n",
      "        [-25.0487, -31.3958, 256.4001, -36.1815, -33.6174, -17.4073, -28.9622,\n",
      "         -32.6827, -22.4254, -29.0331],\n",
      "        [-20.2477, -25.0630, 224.7294, -29.0131, -27.8221, -16.6549, -24.2052,\n",
      "         -33.7301, -19.5178, -28.6278],\n",
      "        [-21.9814, -28.3314, 225.1949, -31.1534, -30.0724, -14.7734, -26.0692,\n",
      "         -28.1092, -19.2121, -25.2500],\n",
      "        [-24.9988, -30.6477, 256.8996, -35.9306, -33.5405, -17.7331, -28.9346,\n",
      "         -33.1012, -22.4429, -29.7525],\n",
      "        [-24.1524, -31.6160, 249.0607, -34.8211, -32.8355, -16.7071, -28.1567,\n",
      "         -31.8291, -21.6466, -27.7499],\n",
      "        [-23.5124, -30.2336, 239.0166, -33.4691, -31.7479, -15.7533, -27.1228,\n",
      "         -29.4570, -20.5355, -26.7040],\n",
      "        [-25.0886, -31.4608, 255.3676, -36.0738, -33.5376, -17.2515, -28.9889,\n",
      "         -32.1672, -22.3569, -28.8329],\n",
      "        [-23.2632, -29.2262, 251.1008, -33.4593, -31.7651, -18.4041, -27.3929,\n",
      "         -35.2879, -21.8691, -30.3863],\n",
      "        [-22.2504, -28.0536, 224.3708, -32.2868, -30.0464, -14.6014, -26.0815,\n",
      "         -26.8599, -20.3010, -24.3609],\n",
      "        [-23.6970, -29.8281, 254.1575, -34.1516, -32.7203, -18.3717, -28.1252,\n",
      "         -34.8343, -22.2706, -30.2542],\n",
      "        [-24.6485, -30.8871, 257.6299, -35.4620, -33.6075, -18.0823, -29.0652,\n",
      "         -33.6602, -22.1395, -30.2413],\n",
      "        [-24.9226, -32.0082, 260.7637, -35.7692, -34.0040, -18.2127, -29.3542,\n",
      "         -33.7487, -22.2574, -30.2458],\n",
      "        [-22.0137, -26.7343, 223.0455, -32.1956, -30.0408, -14.3939, -26.1704,\n",
      "         -27.6161, -20.2752, -24.5074],\n",
      "        [-20.6895, -25.6951, 216.3899, -29.7601, -28.4504, -14.7533, -24.3779,\n",
      "         -29.4333, -19.0354, -24.7104],\n",
      "        [-24.9515, -31.7477, 254.2959, -35.9305, -33.5351, -17.1151, -28.7345,\n",
      "         -31.9386, -22.1066, -28.4432],\n",
      "        [-25.2951, -31.5461, 259.0665, -36.3190, -33.8002, -17.7888, -29.2826,\n",
      "         -32.8026, -22.5959, -29.7361],\n",
      "        [-23.5922, -31.5625, 243.6531, -33.9666, -32.1868, -16.2874, -27.5929,\n",
      "         -30.9823, -20.9375, -26.9779],\n",
      "        [-23.0686, -30.7801, 240.0768, -33.2767, -31.7193, -16.0907, -27.2203,\n",
      "         -30.6403, -20.9250, -26.7203],\n",
      "        [-24.8421, -31.4487, 258.5446, -35.7949, -33.7371, -17.9818, -29.0810,\n",
      "         -33.3848, -22.3282, -29.7955],\n",
      "        [-20.4922, -26.8396, 232.7675, -29.4122, -28.5837, -17.8851, -24.9949,\n",
      "         -34.0662, -20.1566, -30.5686],\n",
      "        [-20.9144, -26.2882, 233.5076, -29.9957, -28.7781, -17.4938, -24.9194,\n",
      "         -35.1235, -20.1448, -29.8768],\n",
      "        [-24.8293, -30.6045, 257.0827, -35.7612, -33.5133, -17.8852, -29.1089,\n",
      "         -33.1111, -22.4277, -30.0545]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([2, 9, 4, 4, 1, 1, 4, 0, 7, 8, 0, 5, 6, 6, 1, 0, 0, 8, 0, 8, 6, 6, 2, 5,\n",
      "        0, 6, 1, 1, 2, 9, 7, 6], device='cuda:0')\n",
      "loss_ce tensor(247.4458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-31.6479, -36.7604, 283.6821, -35.5779, -36.0974, -18.9161, -34.7721,\n",
      "         -34.2609, -25.1365, -30.0600],\n",
      "        [-32.3998, -37.6874, 287.2870, -36.9341, -37.2111, -18.6819, -36.0503,\n",
      "         -33.7084, -25.4212, -30.2097],\n",
      "        [-29.2644, -34.5234, 267.8356, -33.4546, -35.4955, -17.8876, -33.7727,\n",
      "         -31.6642, -24.1651, -28.7058],\n",
      "        [-32.5700, -38.0785, 311.7470, -36.4237, -38.5444, -22.7768, -37.2560,\n",
      "         -41.0763, -28.4120, -36.6115],\n",
      "        [-32.1990, -37.9527, 294.6580, -36.8552, -38.4679, -19.8536, -36.7907,\n",
      "         -35.1246, -26.8242, -31.7468],\n",
      "        [-33.0506, -38.8223, 298.9527, -38.5438, -38.5271, -19.8280, -37.0864,\n",
      "         -35.5574, -27.1790, -31.6210],\n",
      "        [-30.4668, -35.8980, 280.3557, -35.0690, -36.9099, -18.8198, -35.1438,\n",
      "         -33.5724, -25.6660, -30.1441],\n",
      "        [-32.3920, -38.7068, 297.2247, -37.4548, -38.7424, -19.8902, -37.0522,\n",
      "         -35.4297, -26.9994, -31.7470],\n",
      "        [-31.6485, -36.9253, 304.7345, -35.6899, -37.6494, -22.3690, -36.3458,\n",
      "         -40.4473, -27.8397, -35.9224],\n",
      "        [-31.6004, -35.7330, 279.4394, -35.7784, -36.1227, -18.2548, -34.9158,\n",
      "         -33.2407, -25.1831, -29.4944],\n",
      "        [-31.9515, -36.1298, 289.1726, -37.5516, -37.0519, -19.5023, -36.1464,\n",
      "         -33.7503, -26.8529, -31.3989],\n",
      "        [-28.3337, -34.1835, 268.5560, -32.3212, -35.1513, -18.4538, -33.1641,\n",
      "         -33.1860, -24.6215, -29.5084],\n",
      "        [-32.8668, -40.7059, 298.0041, -37.7791, -38.3728, -19.6708, -36.8486,\n",
      "         -35.1237, -26.0848, -31.0137],\n",
      "        [-32.5648, -37.9872, 289.1226, -37.2251, -37.4366, -18.7909, -36.1887,\n",
      "         -33.9602, -25.6763, -30.3528],\n",
      "        [-32.4636, -37.8215, 292.1094, -37.7131, -37.7592, -19.2639, -36.4204,\n",
      "         -34.8334, -26.4102, -30.9645],\n",
      "        [-31.4376, -37.0986, 286.9578, -36.2895, -37.5472, -19.1386, -35.9359,\n",
      "         -34.1913, -25.9854, -30.6693],\n",
      "        [-32.3161, -37.3983, 300.4021, -36.2550, -37.9880, -20.8654, -36.7145,\n",
      "         -37.6464, -27.5870, -33.7820],\n",
      "        [-32.7436, -36.8527, 295.0353, -37.9102, -37.4480, -19.9995, -36.5539,\n",
      "         -35.2433, -27.3407, -32.1324],\n",
      "        [-32.2855, -40.4859, 291.4959, -37.2053, -37.6750, -18.9168, -36.3044,\n",
      "         -33.7548, -25.2135, -29.8986],\n",
      "        [-33.2704, -39.7440, 303.5984, -37.9307, -39.1294, -20.4617, -37.4702,\n",
      "         -36.7558, -27.2531, -32.3602],\n",
      "        [-27.5522, -31.9812, 255.7159, -31.4345, -33.8145, -17.2927, -32.1779,\n",
      "         -31.1538, -23.3044, -28.1540],\n",
      "        [-32.1542, -37.1365, 281.7151, -36.6537, -36.4350, -18.0515, -35.3121,\n",
      "         -32.6544, -24.8261, -29.1510],\n",
      "        [-28.6645, -33.5838, 278.1888, -32.4403, -34.4104, -20.5944, -33.4071,\n",
      "         -36.3797, -24.9792, -33.0723],\n",
      "        [-30.8243, -35.3112, 289.4006, -35.7510, -37.0416, -20.2793, -35.7349,\n",
      "         -35.5500, -27.3062, -32.3208],\n",
      "        [-32.3477, -38.5189, 298.4531, -36.9050, -38.5468, -20.3381, -36.9315,\n",
      "         -36.3978, -27.0408, -32.2722],\n",
      "        [-30.1712, -35.9415, 279.7711, -34.6593, -36.6325, -19.0629, -34.8898,\n",
      "         -33.5670, -25.3124, -30.7162],\n",
      "        [-31.6291, -36.2340, 277.9874, -36.1295, -36.0429, -17.9885, -34.9381,\n",
      "         -32.7471, -24.7655, -28.9276],\n",
      "        [-31.7984, -37.8020, 292.1567, -36.6889, -38.0783, -19.6122, -36.3982,\n",
      "         -34.9617, -26.5936, -31.2900],\n",
      "        [-29.9833, -35.3595, 293.4818, -33.7111, -36.3732, -21.9749, -35.0087,\n",
      "         -38.5445, -26.8801, -35.6597],\n",
      "        [-31.5445, -35.8431, 279.5431, -35.8281, -36.2704, -18.3300, -35.1638,\n",
      "         -32.8036, -25.1908, -29.5427],\n",
      "        [-27.5890, -32.9118, 270.1371, -31.4780, -33.4129, -19.9487, -32.2618,\n",
      "         -36.0540, -24.8808, -31.0880],\n",
      "        [-31.7651, -37.9343, 294.3702, -36.4682, -38.4180, -19.9524, -36.6059,\n",
      "         -35.5728, -26.9892, -31.7961]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([6, 6, 2, 7, 4, 0, 4, 4, 7, 0, 8, 4, 1, 0, 0, 2, 8, 3, 1, 4, 8, 0, 5, 8,\n",
      "        2, 6, 0, 4, 5, 6, 7, 6], device='cuda:0')\n",
      "loss_ce tensor(291.8678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-41.8682, -43.6200, 352.4097, -39.5072, -48.1037, -24.2162, -45.0985,\n",
      "         -42.7720, -32.8337, -34.8038],\n",
      "        [-38.0245, -38.1803, 336.1961, -36.1353, -44.1001, -24.9783, -41.6312,\n",
      "         -45.6044, -31.7906, -35.7409],\n",
      "        [-35.9229, -36.3183, 318.1413, -33.8917, -41.3180, -23.5144, -39.4899,\n",
      "         -42.0127, -30.1474, -35.4239],\n",
      "        [-40.8550, -42.6627, 341.8265, -38.5138, -46.5898, -23.1723, -43.8268,\n",
      "         -41.3562, -31.9666, -33.5282],\n",
      "        [-41.7405, -42.5108, 355.0182, -39.6782, -48.0406, -24.8953, -45.4553,\n",
      "         -43.7833, -33.3534, -35.7281],\n",
      "        [-40.1772, -39.2294, 331.8540, -38.3329, -45.4696, -22.3393, -42.6901,\n",
      "         -40.1876, -31.9832, -32.3825],\n",
      "        [-35.0335, -35.7268, 284.4787, -33.2026, -40.5948, -17.7654, -37.9271,\n",
      "         -31.8041, -26.5392, -26.0686],\n",
      "        [-33.7828, -34.0951, 309.1296, -32.2284, -39.5117, -23.9768, -37.7651,\n",
      "         -42.9003, -29.3874, -35.6989],\n",
      "        [-38.3145, -41.0095, 320.7265, -35.9900, -44.3258, -21.2906, -41.5665,\n",
      "         -37.5505, -30.0740, -30.5508],\n",
      "        [-38.1126, -38.2126, 335.7285, -36.3405, -44.4104, -24.7705, -41.7941,\n",
      "         -45.0197, -32.0266, -35.1387],\n",
      "        [-42.2843, -43.2173, 355.6621, -40.1106, -48.3027, -24.7391, -45.5334,\n",
      "         -43.5012, -33.0572, -35.4851],\n",
      "        [-38.9794, -39.3214, 341.7421, -37.3126, -45.2217, -25.1136, -42.5700,\n",
      "         -45.3925, -32.4259, -35.6845],\n",
      "        [-42.3611, -42.5163, 354.0989, -40.3017, -48.1122, -24.4217, -45.6449,\n",
      "         -42.8801, -33.2351, -35.2939],\n",
      "        [-42.8364, -43.0888, 356.4940, -40.8600, -48.7557, -24.4001, -46.0115,\n",
      "         -42.9407, -33.6208, -35.0706],\n",
      "        [-39.0162, -36.8825, 326.8224, -37.9895, -44.1213, -22.9184, -42.1092,\n",
      "         -40.1563, -32.0798, -32.3677],\n",
      "        [-42.3716, -42.8913, 353.7690, -40.2475, -48.3505, -24.3920, -45.7193,\n",
      "         -42.6298, -32.8412, -35.0896],\n",
      "        [-39.1877, -39.0208, 343.9910, -37.7280, -45.8046, -25.4811, -43.1906,\n",
      "         -45.0046, -32.9118, -36.3255],\n",
      "        [-42.2152, -43.2690, 355.6925, -39.7870, -48.4123, -24.7025, -45.6942,\n",
      "         -43.2918, -32.9724, -35.5963],\n",
      "        [-41.0303, -40.5978, 337.9371, -39.3397, -46.2276, -22.7872, -43.6452,\n",
      "         -40.4257, -32.5587, -32.8507],\n",
      "        [-41.5340, -42.6562, 346.8726, -39.3461, -47.5780, -23.6219, -44.6016,\n",
      "         -41.8584, -32.6740, -33.9298],\n",
      "        [-41.1648, -42.1105, 342.2661, -38.8687, -47.0496, -23.1481, -44.3562,\n",
      "         -40.3835, -32.2349, -33.3165],\n",
      "        [-40.9503, -41.1734, 344.8577, -38.9240, -47.0158, -24.0203, -44.8184,\n",
      "         -41.7467, -31.9933, -34.6384],\n",
      "        [-42.0206, -42.4168, 354.9595, -39.8528, -47.8544, -24.9234, -45.5097,\n",
      "         -43.8366, -33.1459, -36.0324],\n",
      "        [-36.9362, -36.7731, 331.6704, -35.2635, -43.3298, -25.2616, -40.8204,\n",
      "         -45.5790, -31.8627, -36.1113],\n",
      "        [-36.8519, -37.3162, 327.1375, -34.8902, -42.6750, -24.3117, -40.3468,\n",
      "         -44.5379, -31.0974, -35.5293],\n",
      "        [-42.1582, -43.0763, 349.0286, -39.7807, -47.8762, -23.5964, -45.1067,\n",
      "         -41.1984, -32.6432, -33.9369],\n",
      "        [-39.3736, -42.9205, 332.2090, -36.7987, -45.5767, -22.4823, -42.6563,\n",
      "         -39.6930, -30.4258, -32.2651],\n",
      "        [-40.7991, -42.4467, 341.3458, -38.4755, -46.7697, -23.1948, -43.9200,\n",
      "         -40.9681, -32.0581, -33.3485],\n",
      "        [-40.1296, -40.9361, 351.7596, -38.3341, -46.5489, -25.9332, -44.1410,\n",
      "         -45.9153, -33.1157, -37.0441],\n",
      "        [-40.5870, -41.8415, 335.6799, -38.3253, -46.8893, -22.1322, -43.8390,\n",
      "         -39.1170, -31.3009, -32.1010],\n",
      "        [-35.6161, -36.0732, 321.6492, -33.8049, -41.1947, -24.4947, -39.3644,\n",
      "         -43.7412, -30.6524, -36.5618],\n",
      "        [-34.1396, -34.0829, 307.8722, -32.6782, -39.7902, -23.4621, -38.3299,\n",
      "         -40.9616, -29.8467, -34.9361]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([4, 7, 7, 1, 2, 6, 0, 9, 1, 7, 2, 5, 6, 3, 8, 6, 8, 4, 3, 3, 0, 4, 4, 7,\n",
      "        5, 0, 1, 3, 8, 4, 9, 9], device='cuda:0')\n",
      "loss_ce tensor(353.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "ep0, loss_cs: -353.018494, loss_cos: 0.576040, loss_obj: -176.221222, lr: 0.0475\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-46.6838, -49.8571, 394.0811, -47.3845, -56.1192, -25.6782, -49.9327,\n",
      "         -46.1036, -37.4427, -35.3102],\n",
      "        [-46.7325, -48.8365, 396.5062, -48.0675, -55.9712, -26.0178, -49.8413,\n",
      "         -46.7806, -38.6384, -36.1656],\n",
      "        [-46.4721, -49.3341, 395.4638, -47.7182, -55.6563, -26.0207, -49.5930,\n",
      "         -46.5992, -38.0123, -36.0260],\n",
      "        [-47.5033, -48.3156, 399.0991, -48.5248, -56.5644, -26.2902, -50.4288,\n",
      "         -47.2026, -38.9545, -36.5435],\n",
      "        [-45.7386, -47.9068, 387.9352, -46.7828, -55.4624, -25.4955, -49.1048,\n",
      "         -45.7789, -37.6224, -35.1044],\n",
      "        [-47.9419, -49.3734, 425.7343, -47.5965, -58.4481, -30.7496, -52.3109,\n",
      "         -54.6250, -41.1603, -43.6330],\n",
      "        [-45.1367, -47.1992, 388.8348, -45.7211, -55.7684, -26.1453, -49.2814,\n",
      "         -46.4472, -37.8348, -35.9871],\n",
      "        [-48.6601, -50.3965, 425.4445, -48.3025, -59.3816, -29.9080, -53.0479,\n",
      "         -52.5017, -40.7579, -43.3946],\n",
      "        [-47.7114, -49.8790, 401.5699, -48.6840, -56.6213, -26.2410, -50.6017,\n",
      "         -47.0888, -38.6732, -36.4568],\n",
      "        [-44.8666, -46.2813, 382.5429, -45.2784, -55.2098, -25.3691, -48.8317,\n",
      "         -45.4385, -37.2799, -35.1233],\n",
      "        [-45.5773, -46.3683, 379.9707, -45.8880, -54.1080, -24.8006, -48.3163,\n",
      "         -44.3406, -36.8458, -34.3452],\n",
      "        [-43.2895, -45.2600, 376.2535, -43.6945, -53.1811, -25.9279, -47.7173,\n",
      "         -44.9193, -36.3174, -35.8443],\n",
      "        [-45.7440, -47.2048, 390.0911, -47.2455, -54.8767, -25.9452, -48.8420,\n",
      "         -46.5660, -38.5129, -35.8917],\n",
      "        [-47.8887, -49.7362, 423.0917, -47.6573, -58.5231, -30.2697, -52.2737,\n",
      "         -53.8178, -40.7746, -42.5062],\n",
      "        [-44.3784, -45.8668, 386.0861, -44.4940, -55.2647, -26.4479, -48.9993,\n",
      "         -47.3738, -37.5510, -36.4749],\n",
      "        [-49.5190, -51.2781, 434.5804, -49.2436, -60.2305, -30.7499, -53.9965,\n",
      "         -54.1392, -41.4846, -44.3923],\n",
      "        [-47.0960, -48.2277, 388.9200, -47.1180, -55.1896, -25.0764, -49.7416,\n",
      "         -44.5705, -36.6716, -35.4007],\n",
      "        [-47.6399, -49.4981, 421.1797, -47.4132, -58.0843, -30.1997, -51.9403,\n",
      "         -53.7631, -40.3785, -42.4868],\n",
      "        [-43.8960, -44.9596, 374.1584, -43.9953, -54.1122, -25.0404, -47.9041,\n",
      "         -44.6524, -36.3493, -34.4716],\n",
      "        [-47.0300, -49.8042, 407.1559, -47.4402, -57.9180, -27.8562, -51.2534,\n",
      "         -49.2234, -39.0605, -38.2109],\n",
      "        [-39.4323, -41.4837, 347.1495, -39.9791, -48.0805, -24.2201, -43.5947,\n",
      "         -42.7442, -32.7751, -33.9947],\n",
      "        [-45.4549, -46.4091, 409.2014, -44.8041, -55.4113, -30.2613, -50.1570,\n",
      "         -53.4698, -39.0421, -43.7891],\n",
      "        [-44.8985, -45.6178, 397.0809, -44.3916, -55.1756, -28.1921, -49.1121,\n",
      "         -50.7300, -39.2943, -40.1900],\n",
      "        [-49.4424, -50.9558, 434.1464, -49.3791, -60.1014, -30.6868, -53.9253,\n",
      "         -54.0299, -41.6756, -44.2575],\n",
      "        [-48.0241, -48.5063, 408.6842, -49.1351, -57.3768, -27.5126, -51.2888,\n",
      "         -48.7967, -40.4108, -38.4372],\n",
      "        [-49.8194, -51.1640, 433.6724, -49.3020, -60.1580, -30.3919, -54.0102,\n",
      "         -53.5120, -41.4280, -44.3588],\n",
      "        [-43.7411, -46.9284, 377.7442, -43.9371, -53.8399, -25.1244, -48.1587,\n",
      "         -44.6411, -36.0087, -34.6063],\n",
      "        [-46.3983, -48.2163, 397.6201, -46.3909, -56.3029, -26.8901, -50.3263,\n",
      "         -47.9623, -37.9324, -37.7782],\n",
      "        [-49.4908, -51.8767, 425.4860, -49.4557, -60.0101, -29.0877, -53.3553,\n",
      "         -51.1921, -40.6857, -40.9299],\n",
      "        [-44.6874, -45.7514, 403.7378, -44.0995, -54.9373, -30.0973, -49.5712,\n",
      "         -52.4760, -39.0588, -43.2449],\n",
      "        [-46.2583, -47.8408, 395.3349, -46.5918, -56.6591, -26.7070, -50.2188,\n",
      "         -47.1394, -38.3244, -36.7727],\n",
      "        [-48.5156, -50.1482, 428.1899, -47.7452, -59.1098, -30.7112, -53.0913,\n",
      "         -53.5657, -41.1764, -44.3013]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([1, 3, 1, 0, 6, 5, 4, 9, 3, 2, 6, 6, 3, 7, 6, 9, 6, 7, 2, 2, 6, 5, 8, 9,\n",
      "        8, 9, 4, 2, 9, 5, 2, 5], device='cuda:0')\n",
      "loss_ce tensor(377.9421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-46.0136, -47.8229, 453.6979, -48.8166, -58.0898, -37.9232, -58.1518,\n",
      "         -59.5532, -42.9149, -54.8673],\n",
      "        [-48.1245, -50.3423, 470.2444, -51.2405, -60.4472, -38.9065, -60.4073,\n",
      "         -60.9493, -45.1805, -54.3261],\n",
      "        [-45.4042, -47.2168, 440.3688, -47.4645, -56.1085, -36.3584, -56.5686,\n",
      "         -56.6801, -40.6484, -53.7217],\n",
      "        [-51.5150, -53.8554, 490.5006, -54.4086, -64.1090, -39.2678, -64.0750,\n",
      "         -61.6126, -46.6678, -55.3144],\n",
      "        [-53.2228, -57.0055, 482.4453, -55.9616, -65.1862, -36.0195, -64.8207,\n",
      "         -55.4351, -44.4508, -50.5325],\n",
      "        [-50.1669, -52.2552, 478.2740, -53.0065, -62.1889, -38.3024, -62.4827,\n",
      "         -60.3231, -45.3926, -54.1658],\n",
      "        [-54.2762, -57.2077, 499.2498, -57.0431, -67.0965, -38.3504, -66.7521,\n",
      "         -58.8882, -46.0167, -54.2226],\n",
      "        [-55.5801, -58.7533, 504.0452, -58.7179, -67.9751, -37.8960, -67.8641,\n",
      "         -58.0085, -46.5123, -53.1844],\n",
      "        [-44.4726, -46.1410, 442.4875, -47.0479, -56.0569, -37.4045, -56.2535,\n",
      "         -59.4134, -41.9654, -53.9782],\n",
      "        [-50.9085, -52.0910, 460.8808, -52.8341, -61.4037, -34.7099, -61.8754,\n",
      "         -54.1443, -43.0530, -49.4805],\n",
      "        [-52.7150, -55.2132, 484.5749, -55.0856, -64.9608, -37.0979, -64.8122,\n",
      "         -57.2172, -44.4720, -53.1054],\n",
      "        [-55.1258, -58.3811, 502.8131, -57.6683, -67.6151, -38.1969, -67.2916,\n",
      "         -58.4641, -46.2612, -53.8416],\n",
      "        [-42.0534, -44.0778, 419.6860, -44.1201, -53.0446, -35.6605, -53.5524,\n",
      "         -55.6053, -39.0817, -52.5219],\n",
      "        [-50.5901, -53.4072, 483.6874, -53.6402, -63.3578, -39.0056, -63.3931,\n",
      "         -60.4433, -46.3719, -53.6913],\n",
      "        [-54.4499, -57.0133, 492.0513, -56.8964, -66.2766, -36.8969, -66.0551,\n",
      "         -56.9544, -45.2907, -52.5709],\n",
      "        [-48.4211, -50.5556, 473.9393, -51.5011, -60.9355, -39.2354, -60.7180,\n",
      "         -62.1278, -45.3890, -55.0047],\n",
      "        [-48.7227, -50.4107, 472.9809, -51.7831, -60.5463, -38.9135, -60.6737,\n",
      "         -61.7817, -44.9347, -55.3741],\n",
      "        [-53.6316, -58.4996, 489.0428, -55.5047, -65.2739, -37.1431, -65.0600,\n",
      "         -56.9068, -44.3050, -52.3386],\n",
      "        [-54.3155, -56.0608, 490.0448, -56.8683, -65.3712, -37.0813, -65.5819,\n",
      "         -57.1492, -45.6279, -52.6719],\n",
      "        [-39.2723, -41.8638, 391.3793, -40.8769, -48.9778, -33.4910, -49.6967,\n",
      "         -52.5430, -35.9332, -47.9402],\n",
      "        [-41.9384, -44.7806, 417.2604, -44.5254, -52.8516, -35.1048, -53.1409,\n",
      "         -54.9182, -39.1928, -50.5661],\n",
      "        [-53.3821, -56.4509, 495.4130, -55.5442, -65.6328, -38.6548, -65.4986,\n",
      "         -59.7729, -45.3913, -54.9652],\n",
      "        [-40.8217, -43.3776, 402.3062, -43.6416, -50.9163, -33.3698, -51.4959,\n",
      "         -52.2496, -38.0329, -47.8857],\n",
      "        [-49.8184, -52.1512, 481.5973, -52.4692, -61.7680, -39.6226, -61.7899,\n",
      "         -62.7657, -45.4982, -55.3658],\n",
      "        [-48.7533, -51.0528, 474.2032, -51.3971, -60.7028, -39.2218, -60.7109,\n",
      "         -62.3649, -44.7535, -54.9571],\n",
      "        [-48.5213, -50.6722, 473.6480, -51.1873, -60.5604, -39.3901, -60.6163,\n",
      "         -62.1375, -44.8318, -55.7103],\n",
      "        [-54.9086, -56.4682, 495.3922, -57.4304, -65.8755, -37.6577, -65.9466,\n",
      "         -58.0688, -46.2560, -53.6078],\n",
      "        [-48.1013, -50.1330, 468.6724, -50.7656, -59.8455, -38.8221, -59.8983,\n",
      "         -61.9073, -44.2072, -54.6734],\n",
      "        [-49.4388, -51.9362, 478.2647, -52.8757, -62.2167, -38.9198, -61.7859,\n",
      "         -61.1392, -46.1527, -53.7663],\n",
      "        [-44.7060, -46.6127, 432.0824, -48.4976, -55.3712, -35.1019, -55.9320,\n",
      "         -55.2673, -41.2837, -50.2909],\n",
      "        [-52.1136, -57.2865, 477.3374, -53.5364, -63.6655, -36.5265, -63.2597,\n",
      "         -55.8756, -42.9533, -51.4946],\n",
      "        [-51.7269, -54.2824, 477.8051, -53.8750, -63.8781, -36.7051, -63.8588,\n",
      "         -56.7045, -43.8316, -52.6948]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([9, 5, 9, 8, 2, 8, 6, 6, 9, 6, 6, 4, 9, 8, 2, 7, 7, 1, 0, 6, 5, 4, 5, 7,\n",
      "        7, 5, 3, 7, 7, 5, 1, 2], device='cuda:0')\n",
      "loss_ce tensor(472.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-59.6439, -64.6441, 565.3445, -63.1961, -73.6415, -45.5781, -78.4021,\n",
      "         -68.2178, -53.6074, -58.8557],\n",
      "        [-59.7964, -64.0250, 568.4672, -63.4283, -73.5996, -46.2828, -78.4901,\n",
      "         -69.7521, -54.2689, -59.9053],\n",
      "        [-59.6271, -65.2592, 587.5831, -62.4351, -74.7341, -49.9419, -79.7767,\n",
      "         -75.2352, -55.1923, -65.7486],\n",
      "        [-58.5516, -64.9707, 586.5588, -61.4090, -74.1587, -50.9598, -79.0532,\n",
      "         -76.4009, -55.7344, -65.6908],\n",
      "        [-57.1079, -64.8889, 549.0306, -61.2301, -71.3120, -44.2602, -75.8939,\n",
      "         -66.2191, -51.4228, -56.4665],\n",
      "        [-56.8675, -64.1155, 554.6476, -61.2665, -71.4525, -45.9066, -76.0252,\n",
      "         -68.5004, -52.5287, -57.9757],\n",
      "        [-58.5050, -63.5329, 567.2598, -62.5926, -73.8402, -46.8366, -78.2528,\n",
      "         -69.8948, -54.5864, -59.7203],\n",
      "        [-57.7070, -62.6314, 555.4196, -61.1828, -73.1134, -45.5220, -77.0780,\n",
      "         -67.8358, -53.0833, -58.0997],\n",
      "        [-57.2107, -62.6232, 573.9177, -59.8911, -72.0875, -50.0615, -77.2201,\n",
      "         -76.2257, -54.1554, -64.9691],\n",
      "        [-58.4533, -62.6771, 576.5370, -61.2721, -73.3614, -49.3125, -78.2272,\n",
      "         -74.1384, -56.0794, -63.4143],\n",
      "        [-57.7550, -64.5264, 556.6492, -62.3746, -71.6879, -45.3201, -76.4643,\n",
      "         -68.0743, -52.8301, -57.8030],\n",
      "        [-59.0046, -64.8635, 567.8101, -63.6644, -73.7024, -46.2509, -78.3101,\n",
      "         -69.5251, -54.1837, -58.9149],\n",
      "        [-57.1660, -61.7261, 569.6273, -59.8298, -71.3655, -49.4823, -76.7659,\n",
      "         -75.1826, -54.3469, -64.0227],\n",
      "        [-57.3852, -62.6940, 540.3099, -61.0336, -70.3803, -43.0929, -75.4048,\n",
      "         -64.5529, -50.7598, -55.4887],\n",
      "        [-59.1091, -63.9589, 561.4300, -63.7930, -72.5850, -45.2921, -77.5192,\n",
      "         -68.2854, -53.6951, -58.0664],\n",
      "        [-55.5391, -59.7719, 562.4916, -57.3940, -69.5142, -50.2096, -75.1101,\n",
      "         -76.0697, -52.8285, -66.3101],\n",
      "        [-58.4698, -63.1416, 583.4491, -61.5740, -73.6220, -50.5954, -78.8215,\n",
      "         -75.6717, -56.5992, -65.3623],\n",
      "        [-59.2062, -63.3008, 559.4484, -62.8855, -72.1055, -45.4381, -76.9702,\n",
      "         -69.0111, -52.9584, -58.3949],\n",
      "        [-58.3800, -65.7858, 564.8724, -62.3357, -73.1359, -46.2404, -77.5570,\n",
      "         -69.4644, -53.1629, -58.9346],\n",
      "        [-59.0523, -65.5113, 570.4588, -63.7105, -73.4687, -46.7826, -78.1467,\n",
      "         -70.2348, -54.2893, -59.5856],\n",
      "        [-52.6358, -56.0110, 513.2032, -56.6873, -64.7203, -43.2112, -69.8345,\n",
      "         -64.9104, -49.7968, -55.2098],\n",
      "        [-57.8600, -63.2377, 559.1318, -61.8927, -73.0993, -45.8171, -77.3638,\n",
      "         -68.5329, -53.5089, -58.2764],\n",
      "        [-58.7081, -63.7284, 559.0441, -62.8129, -72.2215, -45.5136, -77.1041,\n",
      "         -68.3071, -53.1905, -58.1735],\n",
      "        [-58.4558, -65.7286, 565.9861, -62.8454, -73.0357, -46.3137, -77.6843,\n",
      "         -69.3671, -53.5981, -59.0035],\n",
      "        [-57.0334, -64.9214, 555.2449, -61.2076, -71.5227, -45.6774, -76.0113,\n",
      "         -68.4244, -52.4079, -58.0252],\n",
      "        [-57.4961, -61.7802, 578.1111, -60.4158, -72.3933, -50.8688, -77.8151,\n",
      "         -76.2339, -55.9583, -65.5055],\n",
      "        [-56.0317, -63.4546, 547.4117, -59.1110, -71.5288, -45.0795, -75.6508,\n",
      "         -67.2158, -51.2298, -58.1474],\n",
      "        [-59.7538, -65.1859, 593.5905, -62.6807, -75.0792, -51.3626, -80.1316,\n",
      "         -76.5937, -56.6396, -66.5627],\n",
      "        [-53.8576, -57.7923, 509.2502, -57.6014, -65.8009, -41.1453, -71.1489,\n",
      "         -61.2268, -48.4812, -52.6617],\n",
      "        [-59.3104, -65.1112, 576.5143, -63.2270, -74.8209, -47.7151, -79.4374,\n",
      "         -71.1226, -55.2374, -61.1768],\n",
      "        [-58.2825, -62.7740, 560.0289, -62.4465, -73.0517, -45.7360, -77.7101,\n",
      "         -68.1970, -53.9465, -58.7812],\n",
      "        [-59.7664, -64.7334, 568.4581, -63.8393, -73.7404, -46.1246, -78.6062,\n",
      "         -69.2200, -54.1087, -59.2309]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([2, 6, 7, 5, 1, 1, 6, 2, 7, 8, 3, 4, 5, 0, 3, 5, 8, 0, 1, 1, 1, 3, 0, 1,\n",
      "        1, 5, 4, 9, 0, 6, 6, 0], device='cuda:0')\n",
      "loss_ce tensor(587.5566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-63.3083, -70.6932, 619.8618, -62.9690, -72.4525, -60.0842, -82.0019,\n",
      "         -81.3590, -58.4445, -69.6080],\n",
      "        [-72.5040, -81.1660, 668.2950, -71.3374, -81.5553, -59.3635, -91.6354,\n",
      "         -80.7610, -61.8034, -68.9918],\n",
      "        [-69.8487, -75.6686, 646.3845, -69.2772, -78.3607, -58.2465, -88.1085,\n",
      "         -79.9671, -60.8328, -67.6708],\n",
      "        [-60.3116, -66.9509, 606.3546, -59.7435, -70.2041, -60.0865, -79.4803,\n",
      "         -82.4021, -56.9095, -71.5385],\n",
      "        [-71.7880, -80.5134, 663.1235, -70.5025, -80.8442, -59.0905, -90.8563,\n",
      "         -80.3823, -61.2247, -68.7456],\n",
      "        [-66.8005, -74.2455, 655.3793, -66.5631, -77.1115, -62.9791, -86.4748,\n",
      "         -87.2647, -62.2047, -72.3740],\n",
      "        [-64.5641, -75.7524, 617.0197, -62.6695, -74.7515, -56.7353, -82.9966,\n",
      "         -77.1603, -56.1900, -65.8548],\n",
      "        [-69.1165, -77.3875, 662.5323, -68.5358, -78.6802, -61.8961, -88.8886,\n",
      "         -85.1715, -62.2219, -71.1810],\n",
      "        [-67.5574, -76.5063, 646.6782, -67.0097, -77.9423, -59.7811, -87.5722,\n",
      "         -81.5276, -60.8371, -69.1401],\n",
      "        [-67.0002, -75.3167, 658.8521, -66.3654, -77.3377, -63.6402, -86.7484,\n",
      "         -88.2307, -61.8179, -73.2178],\n",
      "        [-71.7044, -77.5352, 652.8675, -71.2890, -79.8231, -57.5276, -90.0641,\n",
      "         -78.1250, -61.3922, -66.4604],\n",
      "        [-72.6558, -82.6806, 660.2469, -71.7005, -82.3580, -56.8112, -92.1708,\n",
      "         -76.5774, -60.7429, -65.1688],\n",
      "        [-64.6608, -71.7900, 635.4941, -64.2112, -74.7010, -61.4900, -83.9226,\n",
      "         -85.2216, -59.9415, -70.6970],\n",
      "        [-60.2816, -66.8601, 603.8713, -59.7075, -70.2165, -59.5345, -79.4713,\n",
      "         -81.3199, -57.0177, -70.5988],\n",
      "        [-68.9729, -77.9231, 639.1958, -67.8733, -77.0347, -57.3516, -86.8670,\n",
      "         -78.6283, -58.6850, -65.3949],\n",
      "        [-71.1420, -80.1764, 662.5013, -69.9982, -80.6090, -59.4964, -90.5737,\n",
      "         -81.0588, -61.0208, -69.1466],\n",
      "        [-70.3989, -75.6219, 649.4820, -70.1263, -78.8354, -58.4556, -89.1647,\n",
      "         -78.9587, -61.9342, -67.4046],\n",
      "        [-68.4168, -78.4141, 645.8148, -66.8274, -78.3321, -58.8887, -87.4106,\n",
      "         -80.2344, -59.2040, -68.3596],\n",
      "        [-73.9303, -82.7903, 683.4182, -72.7696, -83.5927, -60.9930, -93.8643,\n",
      "         -82.8502, -62.8088, -70.7278],\n",
      "        [-74.2251, -82.5073, 689.1710, -73.1588, -83.8785, -62.0420, -94.3232,\n",
      "         -84.3900, -63.6414, -71.9058],\n",
      "        [-71.8482, -81.6666, 669.6512, -70.7118, -81.6226, -60.1553, -91.3642,\n",
      "         -81.9048, -61.4818, -69.5437],\n",
      "        [-73.4203, -82.3889, 677.8922, -71.9842, -82.5845, -60.4962, -93.1459,\n",
      "         -81.9450, -62.3631, -70.1828],\n",
      "        [-72.3888, -79.9962, 663.5381, -71.7400, -81.2286, -58.6104, -91.2850,\n",
      "         -80.0056, -61.8152, -67.9010],\n",
      "        [-71.4034, -82.7899, 664.1356, -69.7408, -81.4453, -59.3851, -90.6698,\n",
      "         -80.1666, -60.2307, -68.3876],\n",
      "        [-71.3270, -82.4230, 662.1973, -69.9947, -81.2568, -58.8768, -90.4740,\n",
      "         -80.1477, -60.3525, -67.8646],\n",
      "        [-74.3065, -83.9881, 689.0388, -73.0394, -84.2780, -61.6507, -94.4885,\n",
      "         -83.7358, -62.9562, -71.3797],\n",
      "        [-72.1226, -80.6859, 681.7162, -71.1944, -82.0549, -62.6662, -92.1269,\n",
      "         -86.0649, -64.0876, -71.4313],\n",
      "        [-72.7448, -80.6060, 678.8828, -71.6958, -82.6986, -61.5230, -92.5648,\n",
      "         -83.8031, -62.9714, -71.0697],\n",
      "        [-74.1686, -83.1215, 685.6502, -73.0189, -83.7405, -61.2531, -94.1864,\n",
      "         -83.1422, -62.9992, -70.9360],\n",
      "        [-66.6766, -74.9410, 647.5624, -66.4084, -77.6360, -60.8026, -86.7066,\n",
      "         -84.0745, -61.4494, -69.9397],\n",
      "        [-60.7223, -67.2955, 609.1606, -60.3211, -70.5182, -60.2203, -79.7393,\n",
      "         -83.2433, -57.5209, -70.8143],\n",
      "        [-73.6448, -82.1370, 684.6062, -72.5414, -83.3186, -61.6277, -93.6309,\n",
      "         -83.9863, -63.1375, -71.7257]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([5, 3, 3, 9, 3, 7, 1, 8, 8, 7, 3, 0, 7, 9, 2, 3, 8, 1, 4, 4, 3, 0, 0, 1,\n",
      "        1, 6, 8, 2, 6, 8, 9, 4], device='cuda:0')\n",
      "loss_ce tensor(684.6002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[ -77.1538,  -91.8218,  744.1388,  -82.6818,  -89.1701,  -64.5941,\n",
      "          -96.0363,  -90.8569,  -74.8419,  -77.2484],\n",
      "        [ -80.1753,  -91.5230,  727.6635,  -86.8857,  -89.5008,  -58.8885,\n",
      "          -96.5543,  -84.2107,  -71.9013,  -69.6213],\n",
      "        [ -81.2846,  -92.6436,  737.1923,  -88.0057,  -90.5498,  -59.6967,\n",
      "          -97.7170,  -85.3034,  -72.8778,  -70.6569],\n",
      "        [ -85.1584,  -99.4577,  817.2089,  -91.3357,  -96.6522,  -71.5368,\n",
      "         -104.9691, -100.5810,  -81.3194,  -86.6595],\n",
      "        [ -81.4142,  -91.9234,  741.1714,  -88.4269,  -89.6688,  -60.9182,\n",
      "          -97.5340,  -87.0124,  -74.1038,  -71.9672],\n",
      "        [ -85.6195, -100.0846,  818.1663,  -92.1240,  -97.1292,  -71.1011,\n",
      "         -105.3041, -100.8962,  -82.0563,  -84.4258],\n",
      "        [ -83.3189,  -98.5449,  789.4369,  -89.5788,  -94.9042,  -67.5760,\n",
      "         -102.3594,  -94.8451,  -78.2634,  -80.9815],\n",
      "        [ -84.7368,  -96.5013,  764.4621,  -91.5803,  -92.4587,  -62.1078,\n",
      "         -100.9504,  -88.6128,  -75.4383,  -73.2220],\n",
      "        [ -83.3308,  -94.4755,  758.2452,  -90.7871,  -91.2327,  -62.2201,\n",
      "          -99.6961,  -88.4976,  -75.5276,  -73.5264],\n",
      "        [ -75.5406,  -83.7219,  675.6351,  -81.2550,  -82.5318,  -54.5716,\n",
      "          -89.7927,  -78.5990,  -66.7592,  -64.5029],\n",
      "        [ -85.0317,  -99.2656,  809.2787,  -91.2468,  -95.6502,  -70.4148,\n",
      "         -104.2650,  -98.8319,  -81.1751,  -83.5268],\n",
      "        [ -86.0138, -100.9242,  819.5817,  -92.2422,  -97.6267,  -70.9816,\n",
      "         -105.5318,  -99.9895,  -81.2803,  -85.6018],\n",
      "        [ -80.6409,  -89.7642,  721.7823,  -86.8913,  -87.4431,  -58.4850,\n",
      "          -95.3931,  -83.9094,  -71.3174,  -69.2910],\n",
      "        [ -83.0420,  -94.6940,  777.4031,  -90.1576,  -93.1548,  -66.0878,\n",
      "         -101.3590,  -92.5367,  -78.6257,  -78.2981],\n",
      "        [ -77.8591,  -90.1584,  750.3209,  -83.0937,  -87.8840,  -65.7837,\n",
      "          -96.4388,  -93.3402,  -75.3356,  -79.3354],\n",
      "        [ -85.3154,  -99.8167,  818.8462,  -91.6284,  -96.9346,  -71.5957,\n",
      "         -105.1749, -101.4933,  -82.0628,  -85.3365],\n",
      "        [ -84.1143,  -98.5135,  809.4747,  -90.3867,  -95.8242,  -71.1056,\n",
      "         -103.8369,  -99.7625,  -80.7960,  -85.6553],\n",
      "        [ -79.5571,  -88.4768,  710.3627,  -84.9689,  -86.7422,  -57.1827,\n",
      "          -94.4407,  -81.7702,  -69.8449,  -68.5685],\n",
      "        [ -77.4969,  -89.1072,  719.1621,  -84.0416,  -88.4487,  -59.5258,\n",
      "          -94.9396,  -84.8943,  -71.6654,  -70.4586],\n",
      "        [ -76.7122,  -88.3601,  706.7418,  -82.9577,  -87.5361,  -57.8718,\n",
      "          -93.7295,  -82.5389,  -70.1264,  -68.5823],\n",
      "        [ -84.7476,  -99.1638,  812.2714,  -91.0223,  -96.3958,  -70.8730,\n",
      "         -104.5696, -100.2009,  -81.6867,  -84.1146],\n",
      "        [ -76.5358,  -84.8054,  681.6256,  -82.1055,  -83.4856,  -54.6852,\n",
      "          -90.8078,  -78.6966,  -66.9213,  -65.2531],\n",
      "        [ -79.5413,  -92.1267,  719.1687,  -85.5285,  -87.9016,  -58.0579,\n",
      "          -95.2310,  -83.3944,  -70.0890,  -68.4030],\n",
      "        [ -85.9013, -101.1830,  816.9034,  -92.2567,  -97.8186,  -70.3924,\n",
      "         -105.5009,  -99.2787,  -81.2144,  -84.2059],\n",
      "        [ -80.2969,  -93.3977,  722.9598,  -86.0581,  -88.2753,  -57.8748,\n",
      "          -96.1229,  -82.4971,  -70.2043,  -68.5365],\n",
      "        [ -75.9106,  -87.0208,  696.2722,  -81.9691,  -86.4422,  -56.7077,\n",
      "          -92.6374,  -80.9745,  -68.6135,  -67.5575],\n",
      "        [ -63.6793,  -71.7647,  590.7093,  -68.1896,  -74.1399,  -48.5719,\n",
      "          -79.0458,  -69.2994,  -59.3699,  -58.3646],\n",
      "        [ -85.4645,  -99.3156,  796.3087,  -91.8777,  -95.3108,  -67.6094,\n",
      "         -103.4919,  -95.3599,  -78.8353,  -80.1296],\n",
      "        [ -78.9579,  -89.6456,  715.6866,  -85.8505,  -87.5079,  -58.0153,\n",
      "          -94.7112,  -83.3631,  -70.8118,  -68.5045],\n",
      "        [ -81.8421,  -95.9224,  743.3705,  -88.1998,  -91.0064,  -60.0383,\n",
      "          -98.5193,  -85.7297,  -72.1335,  -70.8166],\n",
      "        [ -80.1727,  -89.9082,  716.9305,  -86.1678,  -87.7783,  -57.5963,\n",
      "          -95.4150,  -82.6357,  -70.6705,  -68.5556],\n",
      "        [ -79.5615,  -92.6020,  733.1584,  -86.1517,  -90.4983,  -59.9788,\n",
      "          -97.0337,  -85.2305,  -72.4052,  -70.9269]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([8, 6, 4, 9, 0, 7, 5, 3, 3, 0, 5, 9, 0, 8, 7, 7, 9, 6, 4, 2, 7, 0, 6, 7,\n",
      "        3, 6, 6, 5, 0, 1, 0, 4], device='cuda:0')\n",
      "loss_ce tensor(810.3784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "ep0, loss_cs: -810.378418, loss_cos: 0.656335, loss_obj: -404.861053, lr: 0.045125\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[ -96.7545,  -97.9662,  882.0212,  -96.7767, -101.2774,  -78.8805,\n",
      "         -113.4544, -116.5535,  -85.4248,  -94.3735],\n",
      "        [ -82.5557,  -81.5377,  737.3693,  -81.1433,  -85.4973,  -64.8761,\n",
      "          -96.1418,  -92.2527,  -70.7086,  -80.5182],\n",
      "        [-105.3100, -105.5311,  906.2318, -104.5932, -108.2378,  -74.8841,\n",
      "         -121.0416, -108.4189,  -86.8032,  -90.6712],\n",
      "        [-106.3998, -109.4066,  941.4374, -106.0871, -111.0263,  -80.5617,\n",
      "         -123.4910, -117.1247,  -90.2411,  -96.5095],\n",
      "        [ -98.9643, -105.4546,  875.3146,  -98.5617, -103.5093,  -74.1015,\n",
      "         -114.6597, -107.8220,  -82.5588,  -88.7924],\n",
      "        [-105.1700, -108.4061,  931.8260, -104.8266, -109.8999,  -79.6615,\n",
      "         -122.0376, -116.4198,  -89.0768,  -95.6549],\n",
      "        [-105.4084, -106.1681,  919.3752, -104.9311, -108.9611,  -77.9700,\n",
      "         -121.9814, -111.5899,  -89.0683,  -93.1890],\n",
      "        [ -91.8367,  -93.3773,  851.1283,  -92.0150,  -97.1898,  -77.3480,\n",
      "         -108.3933, -115.0209,  -82.0998,  -93.4939],\n",
      "        [ -85.5597,  -84.0910,  799.9056,  -86.3290,  -90.1086,  -73.5645,\n",
      "         -100.6164, -109.9007,  -78.1986,  -91.6812],\n",
      "        [ -74.7909,  -74.3071,  684.9322,  -74.7589,  -77.4097,  -62.1923,\n",
      "          -87.7188,  -89.8116,  -65.6404,  -76.0710],\n",
      "        [ -84.3630,  -85.1428,  791.5517,  -84.7620,  -89.0571,  -72.6055,\n",
      "          -99.6236, -108.9842,  -75.8408,  -90.8255],\n",
      "        [-106.2083, -108.8968,  930.2296, -105.6420, -110.1669,  -78.3651,\n",
      "         -122.7089, -113.9448,  -88.7462,  -94.5862],\n",
      "        [ -88.4397,  -88.1986,  823.0107,  -88.8821,  -93.7014,  -75.0552,\n",
      "         -104.3126, -112.1590,  -79.7897,  -92.3217],\n",
      "        [-100.6397,  -98.1176,  878.3154, -101.2764, -103.9795,  -74.1948,\n",
      "         -116.3418, -107.4583,  -86.6621,  -89.7160],\n",
      "        [-104.6576, -107.7349,  929.7150, -104.1730, -109.5750,  -79.8231,\n",
      "         -121.6402, -116.5589,  -89.0871,  -95.7074],\n",
      "        [ -76.4595,  -74.8509,  706.9138,  -75.6817,  -79.4833,  -65.9818,\n",
      "          -89.6464,  -96.1080,  -67.0627,  -81.4356],\n",
      "        [ -92.5479,  -92.5315,  846.1937,  -92.8601,  -96.6723,  -75.8342,\n",
      "         -108.2058, -112.9970,  -81.9910,  -91.8490],\n",
      "        [ -90.0009,  -90.3310,  834.2831,  -90.7533,  -95.0229,  -75.6601,\n",
      "         -106.0386, -113.4610,  -81.1482,  -91.6695],\n",
      "        [-105.5461, -106.6421,  923.9657, -105.7250, -108.9736,  -78.0385,\n",
      "         -121.3724, -114.1123,  -88.9715,  -94.4065],\n",
      "        [-101.9438, -100.9060,  879.9520, -102.9436, -104.2133,  -73.2669,\n",
      "         -116.3784, -106.7603,  -85.8101,  -88.2213],\n",
      "        [ -97.9081,  -99.0355,  890.6451,  -97.9445, -102.6226,  -79.0891,\n",
      "         -114.3050, -117.2210,  -86.4492,  -95.5290],\n",
      "        [-106.8267, -108.9356,  940.7445, -106.3627, -110.8804,  -80.1953,\n",
      "         -123.4389, -116.7675,  -90.3139,  -96.4607],\n",
      "        [-105.4956, -108.2154,  926.5600, -104.9747, -109.1838,  -78.5982,\n",
      "         -121.6817, -114.2401,  -88.5845,  -94.6937],\n",
      "        [-105.2174, -106.4683,  913.9316, -105.4602, -108.5032,  -76.4089,\n",
      "         -120.6802, -111.1960,  -87.9574,  -91.9253],\n",
      "        [-105.4899, -106.5016,  912.6656, -105.6435, -108.2599,  -76.0555,\n",
      "         -120.6317, -110.5108,  -88.0634,  -91.4541],\n",
      "        [-105.2752, -108.1007,  921.9741, -105.1971, -108.9438,  -77.7892,\n",
      "         -121.0646, -113.4867,  -88.1561,  -93.5537],\n",
      "        [-105.7243, -107.6521,  916.0515, -105.2129, -108.5896,  -76.4278,\n",
      "         -121.3426, -110.6167,  -87.6072,  -92.1712],\n",
      "        [ -94.5611,  -95.3135,  869.5743,  -94.9077, -100.7712,  -78.1479,\n",
      "         -111.7433, -115.2932,  -85.4706,  -93.2521],\n",
      "        [-100.6065, -100.7949,  903.1221, -100.5499, -104.9678,  -78.8415,\n",
      "         -117.2673, -115.7245,  -88.1152,  -95.8584],\n",
      "        [-106.9075, -107.9101,  934.1539, -106.7698, -110.4384,  -78.7048,\n",
      "         -123.0536, -114.8006,  -89.9667,  -95.1781],\n",
      "        [ -95.1095,  -96.0645,  868.5316,  -96.0269,  -99.8303,  -77.7569,\n",
      "         -110.8153, -114.5822,  -84.7402,  -93.7037],\n",
      "        [ -99.5195,  -96.3076,  887.7051, -100.6487, -103.1765,  -77.3538,\n",
      "         -115.2958, -113.0986,  -88.6253,  -93.6034]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([8, 9, 0, 4, 1, 0, 6, 7, 9, 5, 7, 3, 7, 4, 4, 5, 8, 7, 4, 3, 8, 2, 6, 4,\n",
      "        3, 4, 0, 8, 8, 3, 5, 8], device='cuda:0')\n",
      "loss_ce tensor(940.6169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-121.7761, -117.2978, 1113.5135, -124.8916, -136.2901,  -99.1836,\n",
      "         -138.1908, -144.0199, -117.8923, -113.5791],\n",
      "        [-118.5049, -113.4970, 1031.3302, -120.6853, -131.1064,  -86.3341,\n",
      "         -132.5080, -124.3957, -105.7659,  -99.2496],\n",
      "        [-118.8261, -110.2208, 1049.9156, -123.2814, -129.1560,  -90.4083,\n",
      "         -132.3205, -129.5548, -112.6121, -103.9553],\n",
      "        [-121.9135, -116.2793, 1068.4264, -124.6972, -135.5816,  -90.1870,\n",
      "         -136.8825, -130.3490, -110.6105, -103.5529],\n",
      "        [-121.0239, -114.2532, 1044.3522, -122.9901, -132.1389,  -87.0600,\n",
      "         -134.4068, -125.5874, -108.0290,  -99.9390],\n",
      "        [-121.7258, -117.6252, 1110.6907, -124.6719, -136.1718,  -98.6708,\n",
      "         -137.9748, -143.4456, -117.3468, -112.8561],\n",
      "        [-120.3881, -112.4981, 1071.5455, -124.4449, -132.8773,  -92.5979,\n",
      "         -135.6402, -132.9815, -114.2486, -106.3392],\n",
      "        [-121.6577, -118.2502, 1114.2217, -124.6410, -136.8942,  -99.1714,\n",
      "         -138.2722, -144.1555, -117.7118, -113.5105],\n",
      "        [-123.4049, -118.8271, 1079.8961, -126.4264, -136.1661,  -91.2644,\n",
      "         -138.1102, -131.2163, -112.6679, -102.9027],\n",
      "        [-121.6914, -116.9156, 1078.5931, -124.4024, -136.5183,  -91.9221,\n",
      "         -137.0913, -132.8510, -112.1059, -105.8290],\n",
      "        [-121.0118, -116.4459, 1061.8345, -123.5538, -134.7629,  -89.6615,\n",
      "         -136.3519, -129.0298, -109.7477, -102.4985],\n",
      "        [-121.1877, -116.0966, 1068.5525, -124.1476, -135.3884,  -90.7082,\n",
      "         -136.5532, -130.7412, -110.9748, -103.9717],\n",
      "        [-121.5634, -116.1872, 1055.9832, -124.0212, -133.3482,  -88.4923,\n",
      "         -135.2003, -128.2763, -108.6850, -101.3905],\n",
      "        [-122.3752, -113.8772, 1061.3369, -126.0011, -132.6660,  -89.3247,\n",
      "         -135.7166, -128.3861, -111.9231, -102.2113],\n",
      "        [-123.0117, -118.9178, 1095.0507, -126.0501, -138.0088,  -93.7808,\n",
      "         -138.8413, -135.4176, -114.1246, -107.1586],\n",
      "        [-122.6292, -116.1778, 1067.3406, -125.4689, -133.8318,  -89.9363,\n",
      "         -135.9013, -129.6610, -111.3882, -102.8985],\n",
      "        [-119.2621, -119.4806, 1064.2474, -121.8487, -132.6000,  -91.4822,\n",
      "         -134.1918, -131.3251, -109.9621, -103.3054],\n",
      "        [-124.6539, -120.0707, 1092.2939, -127.6345, -136.1378,  -92.8626,\n",
      "         -138.7238, -133.4868, -113.8424, -105.5166],\n",
      "        [-124.0469, -119.3626, 1084.7242, -126.8453, -136.5746,  -91.4172,\n",
      "         -138.2660, -132.1844, -112.0656, -104.5380],\n",
      "        [-115.5752, -109.3596, 1010.5495, -118.7286, -128.7271,  -84.5239,\n",
      "         -130.1076, -121.3804, -105.7531,  -96.6138],\n",
      "        [-120.9241, -120.1121, 1068.9237, -123.2757, -133.8085,  -91.0398,\n",
      "         -135.4625, -130.7552, -110.0165, -103.0457],\n",
      "        [-121.2999, -117.2470, 1112.5596, -124.2946, -136.4452,  -99.3059,\n",
      "         -138.1377, -144.1858, -117.7246, -113.7609],\n",
      "        [-122.1272, -116.5889, 1074.7529, -124.9197, -136.2768,  -90.9669,\n",
      "         -137.3279, -131.6066, -111.5642, -104.3633],\n",
      "        [-122.1923, -118.2662, 1111.1519, -125.0416, -136.6684,  -98.1548,\n",
      "         -138.3112, -142.6872, -117.7088, -112.0250],\n",
      "        [-122.8242, -118.9551, 1117.9609, -126.2164, -138.7531,  -98.2963,\n",
      "         -140.2417, -142.1701, -118.1963, -112.9829],\n",
      "        [-122.8316, -117.0014, 1074.8667, -125.4598, -136.1120,  -90.5469,\n",
      "         -137.3832, -130.9230, -111.4158, -103.7746],\n",
      "        [-120.7321, -115.8144, 1104.5570, -123.4597, -134.7868,  -98.8249,\n",
      "         -136.9098, -143.1270, -116.5114, -113.9010],\n",
      "        [-123.9250, -117.8918, 1080.2648, -126.6797, -135.6980,  -91.0322,\n",
      "         -137.7601, -131.5760, -112.0307, -104.4447],\n",
      "        [-119.3086, -114.4753, 1045.9850, -121.8112, -133.3407,  -87.9366,\n",
      "         -134.0110, -126.9875, -107.8641, -100.9600],\n",
      "        [-124.3134, -120.1951, 1128.0591, -127.4967, -139.3623,  -99.3130,\n",
      "         -141.0278, -143.7794, -118.6119, -114.2621],\n",
      "        [-121.9540, -115.0443, 1067.9049, -124.5129, -135.0112,  -90.2851,\n",
      "         -136.4206, -130.6297, -111.0656, -104.4669],\n",
      "        [-120.2353, -116.3255, 1105.8776, -123.0682, -134.9579,  -99.3303,\n",
      "         -137.0643, -143.1046, -116.5625, -114.8118]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([7, 2, 8, 6, 6, 7, 8, 7, 2, 2, 6, 6, 0, 3, 4, 0, 1, 3, 3, 2, 1, 7, 6, 7,\n",
      "        8, 2, 9, 3, 4, 8, 6, 9], device='cuda:0')\n",
      "loss_ce tensor(1022.9107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-133.9946, -128.9997, 1258.7423, -144.8716, -149.8406, -104.0526,\n",
      "         -165.1502, -169.1320, -138.3140, -125.4739],\n",
      "        [-142.2005, -140.4100, 1287.3024, -153.1172, -157.3359, -100.0858,\n",
      "         -172.8598, -162.7843, -137.4965, -121.0376],\n",
      "        [-131.0172, -127.8713, 1256.6658, -142.1023, -147.7465, -105.5076,\n",
      "         -162.4364, -171.6452, -137.8452, -131.3104],\n",
      "        [-138.3665, -133.6802, 1294.2419, -149.4888, -154.1237, -105.9750,\n",
      "         -169.4139, -174.1519, -141.3746, -128.6701],\n",
      "        [-141.1125, -140.5319, 1280.8668, -152.2462, -156.1983,  -99.6168,\n",
      "         -171.3556, -162.2863, -136.6606, -120.6103],\n",
      "        [-138.2169, -132.8167, 1281.2068, -148.8655, -153.3980, -103.1185,\n",
      "         -169.2056, -169.1352, -140.9187, -125.6070],\n",
      "        [-133.9270, -128.9875, 1253.5801, -144.9702, -148.8652, -103.4100,\n",
      "         -164.5872, -167.5590, -136.9680, -125.3344],\n",
      "        [-134.3243, -131.7868, 1278.0157, -145.4784, -151.3289, -106.1191,\n",
      "         -166.1284, -172.8155, -140.0911, -130.7697],\n",
      "        [-143.6756, -140.7495, 1286.8308, -154.9501, -157.7774,  -98.7762,\n",
      "         -173.2254, -161.3228, -137.3163, -119.4688],\n",
      "        [-136.9763, -132.6217, 1286.5017, -148.4240, -152.8905, -105.2582,\n",
      "         -168.7536, -170.7501, -140.5829, -130.8976],\n",
      "        [-138.1663, -133.1100, 1278.9785, -149.2158, -153.3317, -103.6959,\n",
      "         -169.0264, -168.6227, -139.8534, -124.7181],\n",
      "        [-145.6389, -138.5435, 1292.6564, -156.1215, -158.2194,  -98.9900,\n",
      "         -174.7715, -161.5194, -139.1554, -120.4027],\n",
      "        [-135.2620, -132.2574, 1278.6475, -146.0953, -151.4831, -105.7386,\n",
      "         -166.8409, -171.5210, -139.0624, -131.1414],\n",
      "        [-135.6244, -132.4340, 1279.5424, -146.9763, -153.2770, -104.5907,\n",
      "         -167.8661, -171.1333, -141.4411, -126.7000],\n",
      "        [-142.4320, -137.8909, 1297.4120, -153.0495, -158.3858, -101.5494,\n",
      "         -173.8683, -166.0864, -140.1978, -124.1259],\n",
      "        [-141.7119, -133.4889, 1293.8768, -153.8247, -155.5749, -102.7073,\n",
      "         -171.6985, -167.7292, -142.5026, -125.4060],\n",
      "        [-135.8263, -132.5608, 1280.3121, -146.6894, -152.3765, -105.2784,\n",
      "         -167.5727, -172.5756, -140.5744, -127.7796],\n",
      "        [-133.5518, -129.8435, 1271.8071, -144.6983, -149.9135, -105.9926,\n",
      "         -164.8562, -173.1054, -139.3128, -131.1643],\n",
      "        [-136.3156, -133.7100, 1281.7738, -147.2008, -152.3642, -105.4640,\n",
      "         -167.7255, -171.7332, -139.4407, -128.8380],\n",
      "        [-140.0589, -139.7759, 1278.7318, -151.0556, -155.5057, -100.2431,\n",
      "         -170.5962, -163.2195, -136.5703, -121.3769],\n",
      "        [-138.4091, -135.0561, 1285.3043, -149.2409, -153.2351, -104.5516,\n",
      "         -168.9012, -169.5231, -139.2383, -127.8791],\n",
      "        [-137.3918, -133.1845, 1288.2754, -148.7515, -153.8909, -105.3839,\n",
      "         -168.9307, -172.4996, -141.6426, -127.5368],\n",
      "        [-143.5588, -137.8942, 1293.0312, -154.1229, -158.3766, -100.1172,\n",
      "         -174.2996, -162.8481, -139.8463, -122.1644],\n",
      "        [-146.3945, -141.3024, 1327.2251, -157.9793, -161.0734, -104.1013,\n",
      "         -177.4389, -169.4980, -143.6708, -126.4929],\n",
      "        [-139.2171, -135.0537, 1298.9056, -150.5229, -155.1050, -105.9548,\n",
      "         -170.5137, -173.0979, -141.8558, -128.7903],\n",
      "        [-140.0249, -140.0819, 1273.9495, -150.9160, -155.3466,  -99.3000,\n",
      "         -170.4452, -161.5484, -135.7306, -119.9889],\n",
      "        [-142.9675, -135.1303, 1288.3905, -153.2435, -156.2265, -100.6715,\n",
      "         -172.5763, -165.1449, -139.9127, -123.1765],\n",
      "        [-130.2603, -128.1046, 1223.2111, -140.2071, -145.2546, -100.3549,\n",
      "         -160.3810, -163.8018, -131.4695, -122.8786],\n",
      "        [-143.6981, -138.7908, 1310.6477, -154.4658, -159.3347, -103.1635,\n",
      "         -175.0812, -168.6784, -142.0773, -125.6424],\n",
      "        [-136.0283, -134.0486, 1262.7551, -146.3849, -150.7984, -102.4929,\n",
      "         -166.1172, -165.4978, -136.5740, -125.3250],\n",
      "        [-136.3058, -132.9624, 1285.8396, -147.5883, -153.1442, -105.5553,\n",
      "         -167.9068, -173.5810, -141.0567, -128.6219],\n",
      "        [-144.8091, -140.3752, 1288.8451, -155.8510, -157.7897,  -98.6040,\n",
      "         -173.8092, -160.7883, -137.7966, -119.5849]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([5, 1, 9, 7, 1, 8, 5, 9, 1, 9, 5, 0, 9, 8, 4, 8, 7, 9, 7, 1, 9, 5, 3, 6,\n",
      "        5, 1, 6, 0, 2, 9, 7, 3], device='cuda:0')\n",
      "loss_ce tensor(1376.7856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-154.6767, -160.6994, 1467.0990, -165.7796, -167.3355, -126.4192,\n",
      "         -187.7787, -189.1160, -156.8351, -158.4783],\n",
      "        [-151.7065, -156.4579, 1434.1476, -162.2807, -163.9003, -123.6257,\n",
      "         -184.7018, -184.4566, -152.4583, -155.4737],\n",
      "        [-158.1807, -167.2870, 1515.3944, -169.6513, -171.5943, -131.8614,\n",
      "         -192.8696, -196.7655, -163.2637, -164.0881],\n",
      "        [-156.5921, -166.0025, 1508.6222, -167.8330, -170.0095, -132.3308,\n",
      "         -191.7679, -197.0440, -161.7826, -164.9992],\n",
      "        [-155.4505, -162.0978, 1499.8976, -166.3409, -167.2824, -132.8142,\n",
      "         -189.7328, -197.4122, -161.7760, -166.7166],\n",
      "        [-157.9492, -164.8262, 1499.8214, -169.6059, -170.0742, -129.7878,\n",
      "         -191.5152, -193.6167, -160.5227, -162.0936],\n",
      "        [-155.9901, -163.8969, 1510.4625, -167.2334, -168.1326, -133.9380,\n",
      "         -190.6582, -199.2005, -163.4307, -167.4604],\n",
      "        [-157.8448, -165.8684, 1526.7880, -169.4495, -170.0361, -135.2308,\n",
      "         -192.4758, -201.5934, -165.6132, -168.4689],\n",
      "        [-157.7561, -166.0796, 1526.5778, -169.1031, -170.3514, -135.0072,\n",
      "         -192.6086, -201.3172, -165.2919, -168.6260],\n",
      "        [-154.7668, -160.1411, 1464.5652, -165.1283, -164.2824, -127.2284,\n",
      "         -186.6453, -189.8042, -155.7280, -160.5596],\n",
      "        [-149.7867, -152.2278, 1396.8983, -159.1247, -158.8220, -119.6945,\n",
      "         -179.9037, -178.5677, -148.1615, -150.4975],\n",
      "        [-155.4438, -164.1765, 1475.9407, -166.0300, -168.4318, -126.9788,\n",
      "         -189.2836, -189.1379, -158.4235, -158.2090],\n",
      "        [-154.1266, -161.4920, 1494.5592, -164.9566, -166.4128, -132.7417,\n",
      "         -188.7404, -197.1095, -161.0386, -167.0555],\n",
      "        [-157.5457, -165.1692, 1520.8634, -169.0795, -169.6517, -134.2569,\n",
      "         -192.1812, -200.0066, -164.8351, -167.5751],\n",
      "        [-155.5573, -161.5428, 1466.0251, -166.4888, -167.8588, -125.5547,\n",
      "         -188.3040, -187.8289, -156.4006, -156.6701],\n",
      "        [-157.5411, -165.2066, 1521.7267, -169.0243, -169.2401, -134.6719,\n",
      "         -191.9874, -200.6840, -164.7501, -168.0472],\n",
      "        [-149.7470, -155.1677, 1426.9430, -160.5379, -163.0475, -123.6099,\n",
      "         -182.5951, -184.2781, -153.0292, -154.8951],\n",
      "        [-156.6622, -162.5902, 1490.9331, -167.1826, -167.7846, -130.0782,\n",
      "         -189.0263, -194.4616, -159.3350, -163.2002],\n",
      "        [-158.6221, -166.9859, 1531.8303, -169.9381, -170.9752, -135.1369,\n",
      "         -193.2776, -201.8933, -165.7684, -168.7820],\n",
      "        [-153.7680, -162.5069, 1486.8071, -164.9106, -165.4382, -131.7694,\n",
      "         -187.7596, -195.5812, -160.0919, -164.4137],\n",
      "        [-155.4572, -163.4222, 1488.0813, -166.1869, -168.1170, -129.9254,\n",
      "         -189.3315, -194.0913, -159.5537, -162.6413],\n",
      "        [-151.7868, -155.4332, 1425.3993, -161.9220, -161.5827, -122.7342,\n",
      "         -182.8517, -183.2704, -151.3078, -154.4739],\n",
      "        [-150.8430, -156.2871, 1421.3676, -161.6805, -163.1010, -121.6023,\n",
      "         -183.0891, -181.5053, -151.0307, -152.2752],\n",
      "        [-158.2231, -166.1926, 1530.4432, -169.6521, -170.5884, -135.2382,\n",
      "         -192.7375, -202.6615, -166.0441, -168.8850],\n",
      "        [-155.1437, -160.2476, 1458.1266, -165.4323, -165.7419, -125.3911,\n",
      "         -187.2173, -187.4851, -154.4705, -157.0141],\n",
      "        [-154.5273, -160.1143, 1465.1519, -165.9417, -166.6713, -126.4263,\n",
      "         -187.4482, -188.8770, -156.7445, -158.3091],\n",
      "        [-153.9343, -156.7533, 1437.7638, -163.7745, -163.2745, -123.4414,\n",
      "         -185.0797, -184.3270, -152.7108, -154.6922],\n",
      "        [-158.0146, -165.9972, 1525.0580, -169.5682, -170.0305, -134.6363,\n",
      "         -192.4455, -200.7815, -165.5357, -167.5995],\n",
      "        [-154.8651, -158.5513, 1442.0637, -164.9132, -164.6545, -123.1155,\n",
      "         -185.9827, -183.6552, -152.9574, -153.7022],\n",
      "        [-153.0133, -159.3057, 1448.6460, -164.1063, -165.4621, -124.5729,\n",
      "         -185.8544, -185.9474, -154.4673, -155.9008],\n",
      "        [-158.2693, -165.1361, 1498.4156, -169.6076, -170.2438, -129.1609,\n",
      "         -191.5641, -193.0302, -159.9682, -161.6977],\n",
      "        [-157.8335, -163.0035, 1468.9479, -168.7572, -168.9354, -124.2987,\n",
      "         -190.0595, -185.6680, -156.1077, -155.5858]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([4, 6, 8, 8, 9, 6, 9, 7, 7, 3, 0, 2, 9, 7, 2, 9, 2, 6, 5, 9, 2, 3, 2, 7,\n",
      "        3, 2, 0, 5, 0, 4, 6, 0], device='cuda:0')\n",
      "loss_ce tensor(1345.7644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-172.5499, -161.0327, 1656.7185, -180.8056, -178.0166, -150.0176,\n",
      "         -207.6511, -231.8261, -177.2255, -198.4968],\n",
      "        [-183.9722, -170.0224, 1671.4919, -193.5736, -187.4525, -141.2110,\n",
      "         -218.0140, -214.8259, -178.1985, -186.1466],\n",
      "        [-169.4532, -157.4356, 1624.2637, -176.8926, -174.2660, -147.1560,\n",
      "         -203.5076, -227.1118, -172.1849, -197.0766],\n",
      "        [-171.5764, -161.3559, 1639.5426, -179.5771, -176.8119, -147.5683,\n",
      "         -205.9443, -228.5705, -173.7982, -194.7800],\n",
      "        [-182.5741, -174.1738, 1648.6672, -192.0923, -185.0512, -137.4696,\n",
      "         -215.7729, -209.4438, -172.9952, -180.8554],\n",
      "        [-172.3944, -162.2982, 1659.6328, -180.0835, -178.1868, -150.4384,\n",
      "         -207.5831, -231.4631, -175.8610, -202.5515],\n",
      "        [-187.9951, -175.6373, 1735.4454, -196.2254, -192.2554, -149.6353,\n",
      "         -224.3240, -228.8200, -184.4147, -197.3931],\n",
      "        [-174.3480, -163.7996, 1659.6456, -181.4840, -180.4915, -147.6113,\n",
      "         -210.9973, -227.0320, -179.2257, -195.4268],\n",
      "        [-188.1956, -176.9129, 1725.5508, -196.2375, -193.2961, -147.1951,\n",
      "         -224.7101, -224.5714, -182.8238, -193.4811],\n",
      "        [-181.9449, -170.0381, 1612.1504, -187.7188, -183.2287, -132.7418,\n",
      "         -214.0532, -201.3114, -167.2258, -175.2061],\n",
      "        [-173.6900, -163.7243, 1657.2794, -181.6247, -179.0180, -148.8228,\n",
      "         -208.9649, -229.9767, -177.1488, -194.7695],\n",
      "        [-176.1819, -165.0822, 1688.5673, -184.3707, -181.6160, -152.4160,\n",
      "         -211.8046, -233.5584, -179.9249, -205.0798],\n",
      "        [-162.4726, -155.0173, 1444.4283, -167.0375, -165.4468, -118.3193,\n",
      "         -192.7677, -178.1935, -148.1182, -156.3507],\n",
      "        [-188.0681, -179.3810, 1734.4358, -196.2481, -193.8954, -148.4261,\n",
      "         -225.2078, -226.1718, -182.9471, -195.2884],\n",
      "        [-181.9709, -177.0008, 1654.4447, -190.4944, -185.7043, -138.5920,\n",
      "         -215.7807, -211.5299, -172.0417, -182.3467],\n",
      "        [-176.1731, -169.7887, 1609.3027, -185.1971, -178.9606, -136.2178,\n",
      "         -208.5075, -208.4073, -169.0765, -178.5203],\n",
      "        [-170.1745, -160.9104, 1615.6414, -178.1151, -176.1151, -142.4831,\n",
      "         -206.1101, -221.1724, -174.1273, -187.2012],\n",
      "        [-175.5438, -164.8325, 1571.4414, -182.7513, -179.7188, -129.9335,\n",
      "         -208.5269, -195.8563, -164.8876, -170.3582],\n",
      "        [-175.3232, -162.7946, 1677.8274, -183.6525, -180.0376, -151.7072,\n",
      "         -210.6182, -231.4419, -179.0125, -204.8304],\n",
      "        [-165.1756, -154.2579, 1592.1489, -172.3550, -170.1684, -144.9186,\n",
      "         -198.6553, -224.0910, -167.9181, -194.7625],\n",
      "        [-173.0857, -161.3197, 1663.2780, -181.1288, -178.1436, -150.8088,\n",
      "         -208.2523, -230.9732, -176.8842, -203.8142],\n",
      "        [-185.8792, -175.8859, 1696.5442, -192.7504, -191.0358, -143.3520,\n",
      "         -222.4994, -219.1606, -177.4285, -189.5888],\n",
      "        [-178.4969, -171.6607, 1620.8350, -187.2927, -182.1906, -135.9453,\n",
      "         -211.8285, -207.3718, -169.6408, -177.9625],\n",
      "        [-187.1445, -177.5733, 1710.7076, -194.8918, -192.5127, -144.6940,\n",
      "         -223.4790, -221.0270, -179.9988, -190.6328],\n",
      "        [-188.2344, -178.1119, 1694.0531, -195.9325, -190.2573, -141.6457,\n",
      "         -222.0479, -215.7981, -177.0065, -186.7993],\n",
      "        [-178.8050, -176.5162, 1636.5586, -187.0260, -183.1067, -137.6228,\n",
      "         -212.7761, -210.4057, -169.5049, -181.1194],\n",
      "        [-169.3740, -153.8257, 1531.3229, -179.8474, -169.0474, -130.0484,\n",
      "         -198.8083, -196.7067, -164.6794, -171.1801],\n",
      "        [-175.2321, -165.4522, 1678.2596, -183.5969, -181.1260, -150.9884,\n",
      "         -210.5819, -233.3635, -178.3526, -200.7910],\n",
      "        [-166.0118, -159.4624, 1507.2209, -171.1183, -170.6771, -126.6118,\n",
      "         -198.6748, -191.7801, -155.6729, -166.5105],\n",
      "        [-188.2359, -177.5799, 1691.5035, -196.0778, -190.0691, -141.1507,\n",
      "         -222.0461, -214.4964, -177.0679, -186.5023],\n",
      "        [-177.7854, -175.6030, 1624.5323, -186.0315, -182.2288, -136.2545,\n",
      "         -211.8452, -207.8708, -168.1207, -179.0442],\n",
      "        [-177.0033, -166.2812, 1690.5013, -185.1641, -182.4518, -151.7121,\n",
      "         -212.3897, -233.3477, -179.5330, -203.8865]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([7, 4, 9, 7, 3, 7, 2, 8, 2, 0, 7, 9, 2, 4, 1, 3, 8, 2, 9, 7, 9, 2, 1, 2,\n",
      "        0, 1, 8, 7, 2, 0, 1, 9], device='cuda:0')\n",
      "loss_ce tensor(1442.5767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "ep0, loss_cs: -1442.576660, loss_cos: 0.740979, loss_obj: -720.917847, lr: 0.045125\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-222.5425, -220.5751, 2029.8164, -225.9986, -220.0815, -161.8486,\n",
      "         -244.9895, -279.2037, -213.6321, -241.3885],\n",
      "        [-224.4892, -218.0455, 2034.0299, -228.1616, -221.2303, -161.7369,\n",
      "         -246.0021, -279.2616, -216.0615, -240.0733],\n",
      "        [-215.3934, -207.2616, 1972.4238, -217.5241, -215.4839, -158.0667,\n",
      "         -239.1481, -273.9117, -209.9885, -236.5173],\n",
      "        [-222.5896, -214.7443, 2016.4010, -226.2354, -220.1866, -159.9332,\n",
      "         -245.0007, -275.9087, -214.3373, -238.3596],\n",
      "        [-223.4124, -215.1342, 2009.1201, -226.0648, -219.6688, -158.5994,\n",
      "         -244.5415, -273.6417, -212.3391, -236.6589],\n",
      "        [-221.3236, -220.8486, 2018.9987, -224.4883, -219.4388, -160.8259,\n",
      "         -243.9500, -277.0161, -212.0426, -239.2599],\n",
      "        [-218.4698, -211.2541, 1991.5654, -221.0768, -217.6285, -158.7185,\n",
      "         -241.4109, -274.6369, -211.8473, -236.7530],\n",
      "        [-218.0739, -207.3325, 1958.9448, -220.1752, -212.9588, -154.8358,\n",
      "         -238.0293, -267.4105, -207.8221, -232.0862],\n",
      "        [-203.2896, -197.7438, 1945.5264, -206.4980, -203.9388, -164.5826,\n",
      "         -228.5804, -284.7411, -207.8140, -249.2564],\n",
      "        [-202.7084, -194.5312, 1884.7462, -204.8593, -202.9092, -154.5388,\n",
      "         -226.5017, -266.4305, -200.8140, -232.4429],\n",
      "        [-213.0631, -209.1335, 2002.7450, -216.5167, -213.5781, -165.8036,\n",
      "         -237.9038, -287.1769, -214.4113, -246.4692],\n",
      "        [-217.2272, -211.3596, 1986.4810, -219.4873, -217.1279, -158.7635,\n",
      "         -240.5385, -274.6942, -210.8146, -236.6243],\n",
      "        [-224.2960, -216.1542, 2031.1105, -228.4952, -220.3246, -161.5821,\n",
      "         -245.4905, -278.5436, -216.6450, -240.5389],\n",
      "        [-211.3863, -206.6166, 2006.2689, -214.6660, -212.3033, -167.4527,\n",
      "         -236.7462, -290.8400, -213.3879, -254.0976],\n",
      "        [-224.4305, -218.2778, 2025.6084, -228.2646, -220.7750, -160.2412,\n",
      "         -245.8272, -276.1438, -214.5828, -238.2066],\n",
      "        [-221.5328, -212.9797, 1981.4802, -223.4348, -217.0301, -155.7101,\n",
      "         -241.7287, -268.9510, -208.5170, -232.3932],\n",
      "        [-213.7379, -209.1395, 2013.0398, -216.9201, -214.1080, -167.1094,\n",
      "         -238.7459, -289.9139, -214.8678, -249.8547],\n",
      "        [-215.2658, -208.4306, 1964.6116, -217.1529, -214.7780, -156.8907,\n",
      "         -238.0239, -271.6096, -207.9159, -234.7447],\n",
      "        [-223.4555, -216.2635, 2019.0526, -226.6987, -220.3543, -159.8527,\n",
      "         -245.2187, -275.7808, -213.8002, -238.3092],\n",
      "        [-206.2013, -201.3712, 1965.3258, -209.0717, -207.2556, -165.2576,\n",
      "         -231.5565, -287.0336, -210.2709, -248.5734],\n",
      "        [-219.6982, -214.2648, 1982.3441, -223.5281, -217.5236, -156.2015,\n",
      "         -241.6039, -267.0990, -210.7040, -232.5037],\n",
      "        [-213.4020, -209.0358, 2004.2262, -216.5221, -213.3162, -165.7668,\n",
      "         -237.7981, -288.6041, -213.6098, -247.6326],\n",
      "        [-209.7190, -204.2538, 1984.6895, -213.0284, -210.0687, -165.1647,\n",
      "         -234.3862, -288.3334, -212.0663, -249.0896],\n",
      "        [-212.7975, -207.8559, 2002.4149, -215.6411, -213.6448, -165.5736,\n",
      "         -237.9867, -285.9257, -213.2797, -250.6554],\n",
      "        [-221.2763, -212.3190, 1973.0371, -222.5767, -216.0830, -154.9316,\n",
      "         -241.1305, -267.3274, -207.2890, -231.0602],\n",
      "        [-217.2722, -209.3134, 1977.5170, -219.7956, -216.5818, -157.3997,\n",
      "         -240.1079, -272.2121, -210.1221, -235.0253],\n",
      "        [-224.1306, -217.4796, 2025.0850, -227.0562, -220.5682, -160.5761,\n",
      "         -245.7488, -277.0717, -213.6747, -239.8058],\n",
      "        [-223.7671, -215.1205, 2017.1808, -227.7614, -219.5568, -159.7881,\n",
      "         -244.7274, -275.3114, -214.1727, -237.9059],\n",
      "        [-210.7766, -196.8081, 1911.2167, -216.4963, -204.9442, -153.6978,\n",
      "         -229.9837, -262.6057, -207.2445, -229.6800],\n",
      "        [-218.0051, -212.6622, 1992.7812, -220.0454, -217.8503, -158.9763,\n",
      "         -241.4528, -275.4450, -210.7973, -237.8902],\n",
      "        [-222.0828, -220.9394, 2027.3384, -225.5152, -220.2386, -161.6946,\n",
      "         -244.7994, -278.6426, -213.2631, -240.4424],\n",
      "        [-200.5979, -193.5133, 1862.7223, -203.6096, -200.7916, -152.0315,\n",
      "         -223.3943, -258.8684, -201.7091, -227.6853]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([1, 3, 6, 3, 0, 1, 4, 0, 5, 4, 7, 4, 3, 7, 3, 0, 5, 2, 3, 5, 6, 7, 7, 9,\n",
      "        6, 6, 3, 3, 8, 2, 1, 8], device='cuda:0')\n",
      "loss_ce tensor(2077.8025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-248.2196, -243.2206, 2349.0642, -278.4158, -249.3856, -197.8401,\n",
      "         -280.3979, -336.7455, -242.3349, -272.4754],\n",
      "        [-252.4953, -239.0914, 2319.4248, -283.0506, -250.9211, -189.5498,\n",
      "         -282.8608, -318.6758, -241.2556, -262.6194],\n",
      "        [-246.4691, -240.4992, 2313.5063, -276.2990, -246.9467, -193.8140,\n",
      "         -278.0373, -327.3961, -239.3714, -264.7733],\n",
      "        [-244.9794, -238.8780, 2308.5222, -272.8448, -245.2366, -194.0940,\n",
      "         -276.0549, -329.9596, -236.7934, -268.6528],\n",
      "        [-245.8052, -243.6504, 2277.0459, -276.7574, -244.4274, -186.3345,\n",
      "         -274.7352, -315.5261, -233.7667, -256.7996],\n",
      "        [-235.8495, -228.4503, 2241.6902, -263.3641, -235.7533, -191.8050,\n",
      "         -267.2361, -322.2174, -231.6226, -265.0266],\n",
      "        [-250.9963, -245.8129, 2307.9675, -282.7520, -247.8921, -187.7608,\n",
      "         -279.4929, -317.8412, -237.5680, -259.1169],\n",
      "        [-255.6596, -248.2651, 2368.3379, -286.9095, -254.2117, -194.8058,\n",
      "         -286.8828, -329.0580, -244.6037, -268.8283],\n",
      "        [-248.3416, -243.5505, 2352.4402, -277.8013, -249.6353, -198.3118,\n",
      "         -280.6699, -337.3172, -242.2415, -273.9574],\n",
      "        [-256.8045, -248.9318, 2376.1765, -286.8730, -256.1749, -195.3597,\n",
      "         -288.7241, -330.1225, -244.5587, -269.4776],\n",
      "        [-259.6051, -254.5390, 2370.7219, -290.6795, -256.8550, -191.3713,\n",
      "         -289.9847, -322.1684, -242.4908, -264.0286],\n",
      "        [-246.1623, -240.2109, 2333.8992, -275.3982, -246.8904, -197.1914,\n",
      "         -278.4171, -333.9002, -241.2627, -273.9500],\n",
      "        [-255.3723, -248.8459, 2358.6572, -285.2532, -254.2776, -192.8334,\n",
      "         -286.7268, -326.7364, -242.7689, -266.4720],\n",
      "        [-245.1855, -239.5935, 2324.6758, -274.0594, -246.4666, -196.0632,\n",
      "         -277.0185, -334.9666, -239.5652, -271.1256],\n",
      "        [-260.1294, -251.8331, 2387.0322, -290.9976, -257.4528, -194.3528,\n",
      "         -290.7887, -327.9744, -245.3875, -269.3310],\n",
      "        [-259.4557, -252.0381, 2370.9136, -288.6753, -256.8917, -192.2288,\n",
      "         -290.4650, -323.9951, -242.1613, -266.0345],\n",
      "        [-244.2740, -235.1296, 2290.7607, -273.8076, -243.4748, -192.6601,\n",
      "         -274.8528, -323.7526, -237.2361, -266.2953],\n",
      "        [-254.9182, -246.0671, 2347.2263, -284.7928, -253.8033, -191.6111,\n",
      "         -286.4355, -323.6172, -242.1151, -265.1959],\n",
      "        [-248.1457, -243.2349, 2350.1628, -277.9628, -249.5636, -198.2113,\n",
      "         -280.8270, -336.4558, -243.0209, -272.5543],\n",
      "        [-243.1974, -246.1459, 2266.3501, -272.6590, -243.9954, -185.7465,\n",
      "         -273.4516, -314.0908, -230.3660, -256.7172],\n",
      "        [-250.9642, -244.9500, 2362.6929, -281.8987, -251.3498, -198.0749,\n",
      "         -283.3312, -334.3677, -244.0883, -273.8033],\n",
      "        [-255.1166, -252.8303, 2346.3965, -286.3505, -252.9709, -190.4085,\n",
      "         -285.3345, -321.4815, -239.7885, -263.0384],\n",
      "        [-258.2113, -250.7597, 2359.9565, -287.7473, -254.8096, -191.3602,\n",
      "         -288.3856, -322.5154, -240.9271, -265.6765],\n",
      "        [-258.7077, -250.8327, 2359.2744, -288.7795, -254.9512, -190.8136,\n",
      "         -288.7685, -321.2049, -242.0062, -264.3211],\n",
      "        [-256.4565, -251.0935, 2367.0156, -286.5161, -255.4173, -193.3028,\n",
      "         -287.8750, -327.1684, -243.0393, -266.9706],\n",
      "        [-248.7394, -240.1040, 2330.2139, -277.1134, -249.2540, -194.1359,\n",
      "         -280.2391, -330.2845, -240.9615, -268.3296],\n",
      "        [-247.9395, -240.4563, 2311.5977, -278.1044, -247.6914, -191.5968,\n",
      "         -279.4937, -322.0292, -239.4698, -265.0270],\n",
      "        [-244.5969, -237.7709, 2315.9041, -273.9339, -245.2749, -196.5898,\n",
      "         -276.3160, -331.3712, -240.0510, -270.2886],\n",
      "        [-257.0573, -250.2527, 2369.0476, -287.0789, -254.9696, -193.5790,\n",
      "         -288.0306, -327.6063, -243.2116, -268.3044],\n",
      "        [-248.9741, -252.5626, 2311.4443, -278.7623, -249.4906, -188.9308,\n",
      "         -280.2570, -318.4018, -234.5823, -259.6267],\n",
      "        [-247.9832, -240.6535, 2335.7700, -277.1924, -247.7819, -196.4368,\n",
      "         -280.2306, -331.0417, -240.4737, -273.8495],\n",
      "        [-245.6201, -238.8114, 2327.9443, -275.1044, -246.0985, -196.9219,\n",
      "         -278.0271, -332.3934, -240.7388, -274.0746]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([7, 2, 5, 7, 3, 5, 3, 2, 7, 4, 4, 9, 4, 7, 0, 2, 5, 4, 7, 1, 5, 3, 0, 0,\n",
      "        4, 8, 8, 5, 2, 1, 9, 9], device='cuda:0')\n",
      "loss_ce tensor(2269.7793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-284.2125, -272.0980, 2658.7256, -314.0609, -297.7274, -241.4498,\n",
      "         -295.1060, -383.7805, -267.0662, -305.1397],\n",
      "        [-271.9343, -257.2942, 2518.9106, -298.2574, -284.0857, -226.8500,\n",
      "         -282.4199, -358.0270, -250.9976, -290.7926],\n",
      "        [-282.1759, -271.0377, 2657.4353, -311.1765, -298.0941, -242.3517,\n",
      "         -294.6264, -383.7583, -266.7164, -309.3636],\n",
      "        [-281.2050, -266.6150, 2622.3586, -310.3253, -293.0418, -238.6102,\n",
      "         -290.8898, -376.5163, -264.9754, -301.1601],\n",
      "        [-283.7359, -270.4325, 2663.0376, -313.1141, -297.1585, -243.2535,\n",
      "         -295.0602, -385.7427, -267.6166, -308.7563],\n",
      "        [-285.0407, -271.7189, 2607.3645, -312.9155, -300.1959, -228.2167,\n",
      "         -295.9932, -363.8426, -258.8974, -289.2999],\n",
      "        [-284.9336, -261.9917, 2539.7476, -311.2924, -290.6679, -219.6012,\n",
      "         -290.1522, -349.1516, -251.9358, -279.1169],\n",
      "        [-285.9108, -263.1324, 2621.7090, -316.8378, -297.5065, -232.2666,\n",
      "         -295.5263, -368.7010, -267.7953, -295.9055],\n",
      "        [-288.9886, -274.1089, 2647.7834, -317.8058, -302.9077, -233.3775,\n",
      "         -299.4585, -371.1917, -263.2803, -296.9882],\n",
      "        [-287.7262, -270.4196, 2581.2705, -316.3561, -296.6728, -223.2573,\n",
      "         -295.0695, -354.6201, -256.1078, -281.3270],\n",
      "        [-290.9706, -274.0177, 2627.9563, -320.8813, -299.8690, -229.9246,\n",
      "         -299.1322, -363.1469, -261.2144, -289.6949],\n",
      "        [-278.1348, -264.5180, 2552.9763, -305.0884, -294.3230, -224.0264,\n",
      "         -290.1899, -357.2132, -253.5683, -285.0057],\n",
      "        [-284.4362, -263.4094, 2530.2039, -309.7815, -289.8863, -218.4965,\n",
      "         -289.7316, -346.9282, -249.1398, -277.4274],\n",
      "        [-279.3103, -266.2546, 2621.6736, -308.8448, -292.7938, -239.7154,\n",
      "         -290.9197, -378.7363, -265.0491, -301.8895],\n",
      "        [-261.9264, -245.3702, 2384.7622, -285.5327, -276.8875, -207.6232,\n",
      "         -273.0807, -331.8084, -236.8112, -264.7370],\n",
      "        [-283.9250, -270.6761, 2653.4412, -313.7866, -297.0373, -241.0405,\n",
      "         -294.7065, -382.6050, -267.7285, -303.5535],\n",
      "        [-285.0135, -271.7862, 2661.8240, -315.0953, -297.9457, -241.9631,\n",
      "         -295.6289, -383.6154, -267.9188, -304.4977],\n",
      "        [-274.2448, -257.5514, 2553.8101, -302.7316, -289.6588, -228.5424,\n",
      "         -286.3626, -363.7180, -261.4347, -290.7542],\n",
      "        [-286.8020, -278.1473, 2681.4736, -316.6832, -301.1997, -243.3937,\n",
      "         -298.0804, -384.0300, -267.6664, -307.7733],\n",
      "        [-288.5835, -275.8307, 2713.4246, -318.8901, -303.7316, -247.2166,\n",
      "         -300.4169, -393.4618, -272.8521, -314.4170],\n",
      "        [-284.8878, -272.9636, 2689.1631, -314.8255, -300.0757, -246.1746,\n",
      "         -297.0262, -391.5747, -270.0052, -313.5714],\n",
      "        [-288.5868, -270.3374, 2607.2498, -317.7073, -299.9468, -226.4760,\n",
      "         -297.4482, -360.4388, -259.5307, -287.3398],\n",
      "        [-280.7500, -268.1520, 2644.0737, -309.6974, -297.1418, -240.6803,\n",
      "         -293.7978, -381.7444, -265.1307, -309.0048],\n",
      "        [-278.1603, -259.5652, 2562.1304, -305.1417, -294.5311, -226.8367,\n",
      "         -290.6260, -361.5591, -256.9196, -289.5522],\n",
      "        [-293.7891, -281.1918, 2659.7134, -323.7261, -303.4773, -232.6169,\n",
      "         -301.9213, -368.1414, -263.6091, -291.6864],\n",
      "        [-292.8286, -273.0399, 2645.0432, -323.4525, -302.3184, -231.1821,\n",
      "         -300.7181, -367.3319, -264.8342, -290.8325],\n",
      "        [-290.4643, -273.8806, 2628.9692, -319.5813, -302.1414, -228.5938,\n",
      "         -299.7816, -363.4574, -261.4246, -289.7154],\n",
      "        [-291.8672, -277.3991, 2637.9558, -321.5407, -302.0319, -230.0903,\n",
      "         -300.0969, -364.6268, -261.5478, -288.9462],\n",
      "        [-270.1416, -256.2841, 2469.4734, -295.2224, -286.5221, -215.2995,\n",
      "         -281.6589, -344.1116, -244.9608, -273.9324],\n",
      "        [-290.0734, -276.0681, 2627.5637, -319.6713, -300.1910, -229.9991,\n",
      "         -298.8317, -363.6996, -260.7124, -289.1903],\n",
      "        [-275.5598, -257.6278, 2539.1826, -302.5060, -289.7902, -225.0161,\n",
      "         -286.5167, -359.0786, -257.3255, -286.8641],\n",
      "        [-284.1229, -269.7774, 2604.0637, -312.0339, -299.8761, -228.5554,\n",
      "         -295.8994, -363.9596, -258.9931, -290.3622]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([7, 9, 9, 5, 7, 2, 0, 8, 3, 1, 1, 4, 0, 5, 2, 7, 7, 8, 5, 7, 7, 6, 9, 2,\n",
      "        1, 3, 4, 1, 2, 1, 8, 4], device='cuda:0')\n",
      "loss_ce tensor(2559.7644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-295.1996, -310.8524, 2876.8276, -325.2618, -317.6165, -267.2264,\n",
      "         -300.3028, -435.3157, -286.9423, -335.9388],\n",
      "        [-305.2494, -317.0736, 2975.7871, -339.9673, -330.1308, -275.1263,\n",
      "         -311.1849, -449.0269, -301.5112, -344.3831],\n",
      "        [-301.9864, -313.7520, 2961.3838, -336.0214, -327.3997, -275.8731,\n",
      "         -308.6658, -449.8864, -300.4669, -345.1095],\n",
      "        [-304.0062, -319.6269, 2950.7600, -334.9125, -327.5985, -272.7224,\n",
      "         -308.6396, -445.3252, -293.5674, -341.8729],\n",
      "        [-319.1299, -336.1221, 3011.7373, -353.0851, -341.5384, -268.4980,\n",
      "         -321.6972, -437.6696, -301.2069, -332.8065],\n",
      "        [-287.4372, -309.6771, 2679.8081, -313.6040, -310.2979, -233.9692,\n",
      "         -292.2374, -379.5498, -262.0384, -289.9106],\n",
      "        [-307.3216, -320.7642, 2996.7407, -341.1086, -332.6235, -276.8665,\n",
      "         -312.7438, -454.7601, -302.0695, -345.9124],\n",
      "        [-302.3548, -316.0773, 2964.7368, -335.8326, -328.4939, -274.5775,\n",
      "         -308.4283, -452.6918, -298.8438, -345.5620],\n",
      "        [-326.4454, -338.0916, 3068.9158, -362.7722, -347.7946, -273.3889,\n",
      "         -328.5529, -445.6002, -308.6573, -338.4847],\n",
      "        [-323.9988, -340.2564, 3059.9260, -359.8485, -346.6785, -272.9884,\n",
      "         -326.7263, -446.8382, -306.0180, -337.2001],\n",
      "        [-304.3610, -314.6479, 2866.9558, -333.8649, -326.3110, -256.2825,\n",
      "         -308.7383, -415.5197, -286.3323, -319.6014],\n",
      "        [-312.7519, -325.4023, 3034.7393, -347.6347, -337.6533, -279.1690,\n",
      "         -318.1018, -456.4829, -305.5940, -350.0985],\n",
      "        [-310.0992, -318.3341, 2962.0698, -345.3279, -330.9407, -269.6125,\n",
      "         -313.9482, -436.1382, -300.6151, -335.1389],\n",
      "        [-301.1578, -311.8519, 2918.0850, -335.0477, -326.8550, -266.6128,\n",
      "         -307.5801, -436.1529, -298.6372, -332.4443],\n",
      "        [-308.9741, -322.0466, 3012.0000, -343.8793, -334.6577, -277.5940,\n",
      "         -314.5150, -456.7862, -303.4750, -348.4203],\n",
      "        [-324.8536, -335.8829, 3039.4800, -359.3951, -345.3106, -269.5977,\n",
      "         -326.1922, -440.6334, -305.4688, -333.3701],\n",
      "        [-321.7945, -332.4177, 3021.1536, -356.9455, -341.5009, -269.3673,\n",
      "         -322.6581, -437.8155, -304.3788, -334.8817],\n",
      "        [-323.8956, -332.4630, 3013.1296, -356.0718, -343.7940, -266.2752,\n",
      "         -324.8181, -434.0267, -302.4401, -330.4458],\n",
      "        [-314.5454, -319.4489, 2947.4897, -346.7619, -335.5461, -263.3434,\n",
      "         -318.8114, -425.7669, -296.0522, -327.0473],\n",
      "        [-305.3503, -322.8556, 2956.1921, -340.0431, -330.3648, -270.9199,\n",
      "         -311.1887, -441.2963, -296.5380, -336.5404],\n",
      "        [-319.4052, -323.7180, 2973.9111, -350.9484, -338.3913, -263.9388,\n",
      "         -320.2317, -429.6947, -301.1780, -327.7294],\n",
      "        [-327.8300, -336.3582, 3074.7151, -363.9963, -348.0098, -274.2928,\n",
      "         -329.1798, -446.8789, -309.9643, -339.1498],\n",
      "        [-305.7784, -319.6481, 2985.7407, -339.5277, -332.1118, -275.2148,\n",
      "         -311.4895, -453.8457, -301.4563, -344.1674],\n",
      "        [-304.2366, -318.1763, 2971.7241, -338.9469, -329.5167, -275.7113,\n",
      "         -310.9360, -447.4214, -300.3901, -344.6248],\n",
      "        [-319.0881, -328.8381, 2998.4338, -352.2387, -342.4418, -267.0621,\n",
      "         -323.2754, -435.3606, -301.2417, -330.7844],\n",
      "        [-314.3937, -323.7634, 2976.2051, -347.2686, -338.9207, -266.5055,\n",
      "         -319.7834, -435.5076, -300.4132, -331.0139],\n",
      "        [-316.2997, -337.0111, 2997.6418, -350.3843, -338.9145, -267.8481,\n",
      "         -318.8952, -437.6345, -298.3718, -331.7756],\n",
      "        [-307.0620, -319.3271, 3006.2712, -341.8770, -333.9166, -278.1481,\n",
      "         -313.3441, -458.4300, -305.2027, -347.0973],\n",
      "        [-324.6665, -331.0446, 3029.0537, -359.6216, -344.5924, -268.8333,\n",
      "         -326.5446, -437.1084, -305.3697, -332.8810],\n",
      "        [-322.4677, -339.6871, 3038.1658, -357.4702, -344.8217, -270.1657,\n",
      "         -324.8498, -441.3226, -303.3718, -334.0656],\n",
      "        [-302.8100, -318.6382, 2960.1895, -337.3546, -329.1660, -272.8199,\n",
      "         -309.0357, -448.7137, -298.5081, -340.9149],\n",
      "        [-325.2979, -337.0825, 3040.9343, -360.3273, -345.9108, -269.0850,\n",
      "         -326.5854, -439.0203, -305.4416, -333.1385]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([5, 5, 5, 5, 1, 4, 5, 9, 4, 6, 2, 9, 8, 8, 9, 6, 3, 0, 2, 5, 0, 0, 7, 5,\n",
      "        2, 6, 1, 7, 0, 1, 5, 3], device='cuda:0')\n",
      "loss_ce tensor(2998.6748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-368.1390, -362.3277, 3420.2209, -383.5320, -372.7179, -358.6390,\n",
      "         -362.7129, -486.0408, -342.5283, -383.7914],\n",
      "        [-382.6951, -384.0527, 3490.4575, -395.3553, -384.4297, -359.6668,\n",
      "         -373.9578, -488.7834, -337.0467, -384.8891],\n",
      "        [-381.7958, -382.3979, 3593.9663, -399.2321, -386.6282, -381.8048,\n",
      "         -376.4634, -523.4786, -353.7444, -409.1668],\n",
      "        [-364.9597, -360.2838, 3378.3826, -376.6354, -368.6953, -354.1556,\n",
      "         -358.9161, -480.9276, -327.8608, -386.7486],\n",
      "        [-393.8596, -394.6745, 3618.3533, -410.7170, -395.4552, -375.3503,\n",
      "         -385.3421, -508.2134, -353.6234, -401.1028],\n",
      "        [-393.9446, -398.5554, 3625.8887, -411.2773, -396.9751, -376.6523,\n",
      "         -386.0652, -507.5026, -354.0221, -400.2180],\n",
      "        [-395.3161, -395.2516, 3616.6914, -412.7394, -396.0495, -373.4185,\n",
      "         -385.9614, -504.7906, -354.4081, -398.2582],\n",
      "        [-393.2287, -394.0032, 3620.6589, -409.3048, -400.2033, -374.1011,\n",
      "         -386.8145, -507.6605, -354.3482, -400.6712],\n",
      "        [-398.4958, -392.8430, 3643.3206, -414.8488, -399.6765, -376.2775,\n",
      "         -388.8027, -511.1561, -358.8657, -403.2826],\n",
      "        [-376.3010, -374.8724, 3450.5232, -390.1180, -385.1486, -354.1182,\n",
      "         -371.0053, -480.9037, -338.2630, -379.6335],\n",
      "        [-395.4570, -399.0339, 3629.8281, -412.9949, -397.6939, -375.9177,\n",
      "         -386.9139, -507.3994, -354.3868, -399.2657],\n",
      "        [-382.0219, -380.9804, 3503.8809, -396.0993, -389.0266, -361.2315,\n",
      "         -376.4599, -489.1206, -342.8863, -385.7975],\n",
      "        [-391.4442, -383.9512, 3539.6084, -405.2450, -390.2266, -362.3619,\n",
      "         -380.5088, -491.1248, -346.7438, -388.0334],\n",
      "        [-393.2771, -393.1860, 3617.0864, -409.6154, -399.9596, -373.2601,\n",
      "         -386.7124, -506.1539, -354.7308, -399.5204],\n",
      "        [-374.9713, -372.5418, 3543.7380, -391.4096, -382.1306, -377.8629,\n",
      "         -370.5902, -514.9444, -351.7899, -409.1040],\n",
      "        [-393.7967, -393.6814, 3599.9897, -410.3899, -396.2842, -371.1314,\n",
      "         -385.0568, -502.3395, -351.8281, -394.9610],\n",
      "        [-398.0403, -402.2351, 3668.0840, -415.0639, -403.2086, -379.8527,\n",
      "         -390.8565, -515.0137, -357.6820, -405.8082],\n",
      "        [-383.9248, -373.5657, 3480.9441, -397.7579, -384.0678, -356.3857,\n",
      "         -374.2200, -483.9431, -344.1952, -382.5304],\n",
      "        [-385.7250, -387.5686, 3614.6667, -404.2615, -390.1263, -382.8905,\n",
      "         -380.2383, -521.5899, -357.6473, -405.6254],\n",
      "        [-383.0958, -376.7455, 3539.8032, -398.9155, -388.5665, -368.1120,\n",
      "         -376.1488, -500.8715, -352.1125, -396.2050],\n",
      "        [-391.9095, -384.9255, 3582.1101, -409.9952, -391.7411, -370.1760,\n",
      "         -382.2172, -501.1852, -354.2619, -395.9438],\n",
      "        [-393.9115, -390.7460, 3585.0830, -409.7929, -393.8412, -368.9124,\n",
      "         -383.9652, -498.8878, -350.7235, -394.2954],\n",
      "        [-379.4223, -378.1524, 3415.3464, -391.8356, -378.5782, -347.9014,\n",
      "         -369.8134, -468.1946, -330.8500, -370.7964],\n",
      "        [-373.3942, -372.9099, 3537.1277, -390.0615, -379.2028, -378.7623,\n",
      "         -369.4697, -518.3928, -349.5894, -406.5038],\n",
      "        [-390.4046, -387.7938, 3551.0815, -406.6761, -391.3474, -365.1586,\n",
      "         -381.2676, -492.8808, -347.7483, -388.0777],\n",
      "        [-386.7933, -386.9105, 3626.2715, -403.9718, -391.1660, -384.3304,\n",
      "         -381.2928, -524.4221, -357.0312, -411.3254],\n",
      "        [-378.2935, -377.2870, 3557.8171, -395.2140, -383.3949, -377.5147,\n",
      "         -373.2550, -517.3917, -351.7880, -404.8513],\n",
      "        [-386.1370, -385.6187, 3604.6621, -403.4908, -391.1474, -379.2827,\n",
      "         -379.8626, -517.3979, -355.9714, -406.3829],\n",
      "        [-390.7591, -387.9885, 3556.0989, -405.8004, -391.8750, -365.9612,\n",
      "         -382.0136, -496.1794, -346.8815, -389.5754],\n",
      "        [-379.4167, -379.7165, 3565.1887, -396.1387, -383.7701, -378.7080,\n",
      "         -374.4915, -518.2374, -350.9968, -404.5247],\n",
      "        [-377.0184, -376.3380, 3556.8047, -392.7417, -383.8170, -378.3560,\n",
      "         -372.5942, -516.9883, -350.0927, -410.2875],\n",
      "        [-387.3865, -384.9776, 3535.3489, -401.6337, -392.8251, -362.4487,\n",
      "         -380.1639, -491.7245, -346.0233, -387.8547]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([8, 0, 7, 9, 3, 1, 3, 2, 0, 4, 1, 2, 0, 2, 5, 1, 4, 6, 5, 8, 3, 3, 3, 5,\n",
      "        1, 5, 7, 8, 4, 7, 9, 2], device='cuda:0')\n",
      "loss_ce tensor(3464.4971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "ep0, loss_cs: -3464.497070, loss_cos: 0.814819, loss_obj: -1731.841187, lr: 0.04286875\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-386.1276, -395.8754, 3693.1816, -423.6802, -395.2141, -409.1031,\n",
      "         -366.0947, -539.4730, -366.0821, -415.0608],\n",
      "        [-391.3854, -406.6005, 3794.0264, -432.5232, -403.3944, -422.7086,\n",
      "         -372.9354, -557.5336, -377.1519, -432.1397],\n",
      "        [-394.3314, -401.6554, 3741.5210, -430.3983, -405.6818, -410.1376,\n",
      "         -375.6666, -538.8496, -370.9671, -416.2833],\n",
      "        [-403.9829, -407.9289, 3773.9333, -443.8357, -407.1575, -406.7809,\n",
      "         -379.9325, -531.0554, -378.4079, -415.9956],\n",
      "        [-429.1469, -441.3978, 4023.2834, -468.1100, -435.2646, -435.2520,\n",
      "         -405.9426, -567.7369, -394.8031, -446.8701],\n",
      "        [-425.8820, -440.1787, 3985.0999, -463.6022, -433.1141, -429.4969,\n",
      "         -402.8887, -560.7907, -389.2142, -441.1842],\n",
      "        [-415.8114, -423.7426, 3916.2493, -457.2502, -424.4316, -424.3215,\n",
      "         -394.0075, -553.7960, -392.0703, -431.1567],\n",
      "        [-399.4872, -413.3632, 3848.0681, -439.9023, -410.7849, -426.7001,\n",
      "         -380.0734, -562.8103, -381.2500, -435.6656],\n",
      "        [-406.8194, -418.1689, 3820.1011, -447.5807, -412.7267, -412.2448,\n",
      "         -383.8647, -540.3188, -378.5537, -421.3780],\n",
      "        [-385.7460, -399.0479, 3588.5745, -417.8594, -395.0357, -382.0738,\n",
      "         -365.0862, -498.3756, -349.5401, -397.1688],\n",
      "        [-359.6749, -363.2546, 3426.3533, -393.4913, -363.1508, -381.3299,\n",
      "         -338.9184, -500.7420, -342.6403, -387.5601],\n",
      "        [-400.9562, -414.1272, 3708.2852, -439.2942, -404.0774, -394.6601,\n",
      "         -376.6736, -511.2544, -367.5295, -401.1231],\n",
      "        [-390.2133, -403.1463, 3764.3423, -430.5061, -401.0575, -417.9493,\n",
      "         -371.0526, -552.3530, -373.4638, -427.0046],\n",
      "        [-435.3588, -438.8218, 4051.2207, -474.9030, -437.9713, -436.5778,\n",
      "         -409.9203, -567.3933, -403.4085, -446.8699],\n",
      "        [-389.7004, -401.5167, 3622.7366, -423.3719, -400.1032, -385.9530,\n",
      "         -369.7020, -502.4160, -354.8169, -397.5078],\n",
      "        [-374.2670, -383.6113, 3359.0967, -398.8334, -381.0268, -345.6208,\n",
      "         -352.4197, -445.0084, -324.0915, -354.3988],\n",
      "        [-415.6617, -420.3195, 3841.6472, -453.2477, -417.8384, -410.4464,\n",
      "         -389.6192, -532.1338, -381.9127, -420.8780],\n",
      "        [-420.8952, -436.1571, 3962.1506, -459.8920, -427.6445, -429.4997,\n",
      "         -398.3265, -561.2678, -388.1183, -441.7287],\n",
      "        [-396.8048, -410.5000, 3819.0500, -438.5833, -406.5456, -422.9332,\n",
      "         -376.6880, -554.7507, -381.0336, -433.6362],\n",
      "        [-372.7539, -391.0341, 3518.4949, -406.3808, -384.8041, -379.6118,\n",
      "         -354.8878, -494.6533, -344.6115, -391.8700],\n",
      "        [-384.4111, -398.9185, 3718.4771, -425.3430, -395.5987, -412.8045,\n",
      "         -365.7696, -545.8529, -369.4711, -423.1145],\n",
      "        [-423.4673, -433.4598, 3925.6548, -461.3885, -429.9935, -419.0995,\n",
      "         -400.9847, -544.3127, -385.6885, -429.0538],\n",
      "        [-428.8095, -440.7985, 4022.8833, -466.7230, -436.0779, -435.4771,\n",
      "         -406.4714, -567.9391, -393.6424, -447.7798],\n",
      "        [-419.5589, -432.5099, 3897.6382, -455.2248, -427.9136, -416.1044,\n",
      "         -396.8853, -542.1522, -380.1046, -428.5242],\n",
      "        [-437.9838, -454.8501, 4104.9165, -476.5221, -446.4415, -443.9410,\n",
      "         -414.8112, -576.2830, -402.5964, -452.4683],\n",
      "        [-378.1907, -383.0827, 3560.6428, -416.3087, -382.1221, -389.5474,\n",
      "         -355.2319, -503.9322, -359.9303, -396.7480],\n",
      "        [-429.8472, -442.1570, 4034.0496, -468.9782, -436.5020, -436.6918,\n",
      "         -407.3593, -569.5760, -395.6317, -448.0372],\n",
      "        [-415.9186, -422.5334, 3904.8374, -457.3808, -421.0396, -422.6660,\n",
      "         -392.1106, -552.7236, -390.4272, -430.7072],\n",
      "        [-424.0818, -431.5928, 3910.7947, -457.8411, -430.3615, -415.9261,\n",
      "         -401.1679, -541.9512, -381.2911, -428.2082],\n",
      "        [-374.1515, -383.1164, 3501.3459, -408.6728, -382.1324, -375.5435,\n",
      "         -353.7945, -489.9540, -346.4955, -389.7593],\n",
      "        [-395.5080, -408.0169, 3812.1814, -435.2848, -407.0210, -423.1106,\n",
      "         -376.6064, -558.5891, -377.8876, -432.3628],\n",
      "        [-380.3889, -396.3133, 3557.0259, -414.6704, -390.9475, -380.3006,\n",
      "         -360.7489, -494.1679, -349.6828, -391.6692]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([5, 9, 5, 8, 4, 4, 8, 7, 6, 0, 5, 0, 7, 6, 1, 0, 0, 4, 9, 1, 7, 2, 2, 4,\n",
      "        6, 5, 4, 8, 6, 3, 7, 1], device='cuda:0')\n",
      "loss_ce tensor(3938.7534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-437.4229, -443.0426, 4056.9927, -444.3687, -462.7791, -443.3155,\n",
      "         -420.1600, -568.2064, -401.8986, -431.8470],\n",
      "        [-380.8391, -382.9540, 3444.4106, -387.9070, -395.6735, -372.9594,\n",
      "         -363.3788, -472.9489, -339.0281, -348.3562],\n",
      "        [-436.7144, -436.1575, 3994.0234, -441.3467, -460.7876, -429.2555,\n",
      "         -418.7202, -551.8055, -392.3000, -422.9842],\n",
      "        [-419.6837, -426.7193, 3821.3958, -432.9166, -435.7266, -412.5521,\n",
      "         -398.6383, -525.8911, -378.4635, -388.3366],\n",
      "        [-365.3406, -357.3256, 3274.7781, -369.3971, -376.7837, -353.4114,\n",
      "         -348.2991, -448.6067, -326.5304, -331.2018],\n",
      "        [-379.2247, -377.2066, 3431.9724, -385.1405, -394.4307, -372.3611,\n",
      "         -362.4483, -473.0169, -339.5149, -349.4393],\n",
      "        [-409.5045, -406.7255, 3766.7571, -415.0574, -432.3359, -410.4523,\n",
      "         -394.0378, -526.3440, -372.0501, -397.9665],\n",
      "        [-417.4632, -422.6769, 3781.3948, -430.7966, -431.4182, -406.7140,\n",
      "         -395.3878, -518.3896, -374.8785, -381.7574],\n",
      "        [-380.1771, -380.5970, 3461.9326, -387.4376, -396.5544, -376.7321,\n",
      "         -364.0278, -480.5115, -342.3877, -353.7375],\n",
      "        [-411.8779, -418.0843, 3739.3638, -425.3151, -425.8860, -403.7064,\n",
      "         -390.8838, -513.6824, -371.0415, -377.1179],\n",
      "        [-360.3649, -360.3300, 3264.2644, -367.3116, -371.1133, -356.2806,\n",
      "         -343.0040, -450.7801, -322.8705, -331.4937],\n",
      "        [-383.1312, -377.0565, 3442.2170, -387.5421, -396.1535, -371.9564,\n",
      "         -364.8432, -471.6099, -341.8175, -349.1579],\n",
      "        [-361.0958, -361.4739, 3273.9612, -366.6926, -374.4011, -357.8953,\n",
      "         -344.6906, -452.3078, -322.8560, -333.1149],\n",
      "        [-382.5056, -382.2630, 3472.7712, -389.5995, -398.0256, -377.2111,\n",
      "         -365.6794, -479.0140, -344.6563, -353.1724],\n",
      "        [-406.3553, -411.1941, 3709.6780, -409.4303, -424.9869, -404.0576,\n",
      "         -387.3596, -509.5935, -368.0589, -387.9123],\n",
      "        [-414.5951, -418.1100, 3754.3689, -425.9054, -429.4908, -404.0793,\n",
      "         -393.9886, -515.2977, -371.0664, -380.4219],\n",
      "        [-404.2406, -406.7321, 3645.1187, -415.2567, -416.2743, -391.7112,\n",
      "         -383.0721, -500.0832, -360.0845, -366.8663],\n",
      "        [-407.1485, -398.9083, 3632.0188, -413.7965, -416.0944, -388.2504,\n",
      "         -384.5246, -495.6960, -360.1574, -367.7580],\n",
      "        [-451.6854, -458.1150, 4181.5015, -458.9189, -474.6685, -458.7979,\n",
      "         -432.2701, -585.4318, -415.0266, -444.6128],\n",
      "        [-362.4583, -356.0648, 3271.4648, -363.2161, -371.3486, -357.7602,\n",
      "         -342.3802, -451.6797, -325.5953, -341.1160],\n",
      "        [-373.0368, -366.6829, 3345.0684, -378.2806, -379.6815, -363.7198,\n",
      "         -352.3434, -461.9782, -330.2574, -339.9494],\n",
      "        [-420.0381, -426.1405, 3843.7109, -432.2367, -440.5396, -413.4536,\n",
      "         -401.9649, -531.1331, -378.9403, -395.2797],\n",
      "        [-366.5506, -361.4702, 3314.1526, -369.8354, -383.0562, -357.8781,\n",
      "         -351.8073, -457.7667, -329.0866, -339.2839],\n",
      "        [-401.8605, -403.5798, 3637.9272, -413.0112, -414.0935, -393.3895,\n",
      "         -381.1442, -501.1692, -360.6832, -367.8770],\n",
      "        [-412.2337, -407.5796, 3679.6538, -420.6124, -420.2914, -392.7975,\n",
      "         -387.6657, -501.9509, -365.2134, -370.4764],\n",
      "        [-365.5119, -358.4022, 3272.5955, -368.3980, -375.0288, -353.7901,\n",
      "         -346.9735, -448.4163, -324.2468, -332.2063],\n",
      "        [-380.4604, -372.4110, 3390.4324, -384.1387, -388.4698, -364.8633,\n",
      "         -359.3956, -462.9470, -335.5308, -342.5308],\n",
      "        [-408.7522, -407.2782, 3757.3447, -411.5822, -423.9095, -415.8614,\n",
      "         -388.8183, -528.7950, -369.7001, -401.6144],\n",
      "        [-380.3280, -374.4168, 3400.8567, -385.2922, -388.4993, -367.2211,\n",
      "         -359.6999, -464.1110, -337.2605, -344.0159],\n",
      "        [-372.2758, -368.5175, 3343.1382, -374.9710, -386.4861, -360.7350,\n",
      "         -354.6118, -457.7808, -330.1453, -339.8179],\n",
      "        [-396.7112, -401.2900, 3595.7261, -406.0051, -408.5020, -391.5222,\n",
      "         -376.1949, -496.5595, -353.9466, -364.7693],\n",
      "        [-369.0626, -373.5661, 3396.7715, -379.6721, -384.1697, -373.1978,\n",
      "         -352.3065, -475.8950, -337.6293, -348.7787]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([5, 4, 5, 3, 2, 6, 2, 1, 4, 1, 2, 2, 2, 2, 8, 1, 0, 6, 5, 8, 0, 6, 2, 1,\n",
      "        6, 6, 0, 8, 6, 6, 0, 3], device='cuda:0')\n",
      "loss_ce tensor(3137.5999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-517.9612, -515.4407, 4685.4897, -506.2740, -520.9230, -520.6851,\n",
      "         -519.5988, -628.9277, -468.1199, -487.9669],\n",
      "        [-518.6529, -516.6448, 4685.8242, -507.6234, -522.8799, -518.7996,\n",
      "         -520.3507, -628.0088, -469.1894, -484.2863],\n",
      "        [-407.2796, -397.5112, 3777.2268, -392.1249, -410.0614, -436.1616,\n",
      "         -421.1441, -526.4905, -383.7614, -401.6276],\n",
      "        [-466.4620, -453.1498, 4229.4116, -458.3005, -464.1031, -475.1257,\n",
      "         -474.5867, -570.4091, -436.6405, -432.7434],\n",
      "        [-508.3226, -500.1255, 4624.3711, -493.6104, -517.1812, -517.4590,\n",
      "         -515.8896, -624.1898, -462.1767, -484.6702],\n",
      "        [-525.2452, -529.9833, 4701.2959, -511.2012, -528.8698, -515.1552,\n",
      "         -525.9200, -619.8727, -466.4531, -479.2563],\n",
      "        [-491.9876, -487.1229, 4457.7446, -476.0198, -497.9056, -498.4430,\n",
      "         -497.9220, -597.9160, -441.8138, -467.4143],\n",
      "        [-528.3176, -511.3886, 4747.4053, -519.9042, -528.1299, -524.1504,\n",
      "         -531.4650, -634.8816, -484.8242, -486.0860],\n",
      "        [-496.4419, -505.8523, 4472.8794, -481.7966, -502.8055, -492.2541,\n",
      "         -498.5644, -593.9274, -442.9897, -457.8693],\n",
      "        [-448.1645, -439.9819, 3939.0095, -428.8683, -450.2012, -427.5429,\n",
      "         -450.6221, -502.7992, -392.7134, -397.2726],\n",
      "        [-512.9405, -517.1733, 4572.1855, -498.0259, -516.2233, -499.0169,\n",
      "         -513.4496, -598.6329, -453.5297, -463.5566],\n",
      "        [-454.8313, -452.3040, 4275.4458, -444.9467, -462.6312, -492.9183,\n",
      "         -465.5360, -609.7372, -430.1350, -460.5482],\n",
      "        [-510.2852, -517.2262, 4563.7793, -495.1321, -515.2242, -498.9759,\n",
      "         -511.6851, -601.2498, -450.8461, -463.3058],\n",
      "        [-546.5474, -541.4576, 4948.2642, -535.9493, -549.7188, -549.8707,\n",
      "         -549.2960, -666.1607, -495.3819, -513.7212],\n",
      "        [-533.5137, -529.7854, 4812.7476, -522.4028, -536.1910, -533.7869,\n",
      "         -534.8593, -643.4594, -481.8595, -496.4122],\n",
      "        [-543.2042, -541.6830, 4850.7290, -531.2365, -545.8851, -529.7384,\n",
      "         -543.2233, -640.5154, -484.2428, -492.6544],\n",
      "        [-529.4586, -521.0218, 4681.2754, -514.4737, -530.9417, -508.6964,\n",
      "         -531.0087, -608.7592, -467.3586, -470.6885],\n",
      "        [-397.2762, -390.2652, 3705.6946, -383.0197, -397.8943, -431.8675,\n",
      "         -409.6102, -526.0839, -371.5271, -398.1933],\n",
      "        [-517.7334, -515.0757, 4657.3809, -504.6987, -521.6541, -514.5266,\n",
      "         -519.2357, -619.5445, -465.1663, -480.1743],\n",
      "        [-515.9067, -513.7556, 4630.1919, -501.9018, -518.9147, -511.6361,\n",
      "         -517.2444, -611.7938, -461.3575, -476.8843],\n",
      "        [-471.6258, -463.4510, 4306.4185, -459.4344, -478.7126, -482.0391,\n",
      "         -486.1714, -586.9562, -441.3719, -437.2698],\n",
      "        [-478.1172, -469.9972, 4478.1006, -471.3561, -483.6123, -516.5553,\n",
      "         -486.4153, -629.8337, -458.1812, -485.7134],\n",
      "        [-525.9391, -524.7428, 4752.7666, -514.5639, -529.8002, -526.3486,\n",
      "         -527.3867, -637.5714, -474.8097, -492.2986],\n",
      "        [-525.0923, -518.8499, 4777.0347, -512.5980, -529.9761, -533.4141,\n",
      "         -532.0655, -652.5732, -480.8157, -491.0579],\n",
      "        [-406.8116, -393.5722, 3581.0454, -385.7564, -409.6226, -391.8222,\n",
      "         -412.6821, -460.7519, -357.7999, -363.5739],\n",
      "        [-536.0978, -533.1677, 4899.4092, -524.3954, -543.5974, -549.6723,\n",
      "         -541.5142, -666.6475, -490.0768, -513.8381],\n",
      "        [-546.9211, -543.1520, 4927.9312, -535.1628, -550.1234, -544.9807,\n",
      "         -548.5212, -658.7233, -492.2573, -509.0413],\n",
      "        [-465.4569, -458.2213, 4294.3457, -454.1858, -473.6150, -485.7750,\n",
      "         -476.8239, -593.8785, -435.9782, -449.3417],\n",
      "        [-499.8883, -493.2667, 4387.3130, -483.7195, -497.7170, -474.8076,\n",
      "         -499.3498, -560.4166, -438.1329, -440.6724],\n",
      "        [-549.7906, -549.9749, 4993.9106, -538.2471, -556.3251, -555.6255,\n",
      "         -554.0222, -673.9304, -497.9349, -517.0944],\n",
      "        [-474.5013, -466.8594, 4384.5371, -465.1585, -472.6405, -502.7768,\n",
      "         -480.9135, -611.5439, -442.0307, -468.8963],\n",
      "        [-465.9806, -459.0803, 4373.7559, -458.5572, -472.1158, -505.1485,\n",
      "         -475.8410, -619.2558, -445.9915, -472.8034]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([0, 3, 5, 5, 2, 1, 6, 8, 1, 0, 1, 7, 1, 4, 0, 3, 0, 5, 3, 0, 8, 9, 3, 0,\n",
      "        2, 4, 2, 5, 3, 4, 5, 9], device='cuda:0')\n",
      "loss_ce tensor(4553.0459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-708.7836, -696.6039, 5908.9922, -687.6390, -666.7061, -650.5428,\n",
      "         -645.0989, -719.5654, -574.3918, -560.6574],\n",
      "        [-713.9059, -688.5731, 5965.4932, -690.9860, -671.7023, -660.2703,\n",
      "         -647.7193, -735.4064, -585.8938, -574.0139],\n",
      "        [-681.0872, -661.9354, 5622.1846, -656.4443, -639.2445, -613.2491,\n",
      "         -618.5803, -676.8751, -543.7839, -531.2762],\n",
      "        [-675.0361, -648.4185, 5877.7148, -655.6450, -647.1777, -682.3940,\n",
      "         -617.8704, -765.5021, -582.9154, -604.7957],\n",
      "        [-657.3530, -626.8920, 5763.6592, -637.3921, -629.4172, -679.5225,\n",
      "         -602.5583, -758.2435, -575.5413, -597.6262],\n",
      "        [-674.6375, -646.2134, 5780.9512, -651.8534, -645.1827, -656.9492,\n",
      "         -618.9687, -737.2286, -579.7864, -573.3581],\n",
      "        [-639.9322, -604.3096, 5595.9038, -619.9929, -610.6605, -659.6801,\n",
      "         -584.7213, -735.3481, -556.2143, -585.8406],\n",
      "        [-705.1566, -686.5511, 5872.7451, -683.5917, -664.0660, -645.8517,\n",
      "         -641.9047, -714.6481, -573.8523, -558.6280],\n",
      "        [-696.0072, -672.8253, 5935.8706, -676.4949, -664.8081, -669.9771,\n",
      "         -637.0856, -750.5911, -587.7468, -582.8011],\n",
      "        [-695.5779, -669.7982, 5911.6006, -674.5808, -664.7508, -665.3206,\n",
      "         -637.7281, -742.8084, -585.8401, -577.9559],\n",
      "        [-712.7458, -700.5281, 5986.7114, -693.0502, -674.9556, -662.3171,\n",
      "         -650.0155, -738.0293, -583.6703, -572.4683],\n",
      "        [-701.2142, -695.4916, 5862.5156, -679.7781, -661.3250, -645.9210,\n",
      "         -639.5328, -716.3723, -567.2700, -555.5752],\n",
      "        [-679.6050, -659.1111, 5935.1460, -659.5798, -653.6348, -690.4710,\n",
      "         -624.8036, -778.2047, -586.8053, -604.0860],\n",
      "        [-712.8240, -698.3351, 5962.5479, -693.2071, -672.4778, -656.9676,\n",
      "         -648.2195, -731.1386, -581.0517, -569.4314],\n",
      "        [-680.5548, -662.2303, 5916.0269, -661.8928, -652.0396, -684.4550,\n",
      "         -623.3043, -770.1042, -579.7880, -600.6871],\n",
      "        [-622.4105, -596.1562, 5385.6553, -601.7275, -589.4692, -631.4164,\n",
      "         -568.7333, -686.1880, -533.9474, -550.9575],\n",
      "        [-677.4933, -655.4301, 5867.3359, -659.7797, -647.9532, -678.3566,\n",
      "         -624.4183, -754.1539, -586.1970, -583.8760],\n",
      "        [-704.2235, -670.5209, 5878.9922, -678.4067, -660.9070, -653.1570,\n",
      "         -639.3429, -727.6366, -581.5286, -566.6929],\n",
      "        [-672.7193, -644.4437, 5553.5073, -650.8903, -628.9471, -609.1475,\n",
      "         -610.4789, -666.0698, -542.3697, -528.5743],\n",
      "        [-664.9380, -639.8506, 5750.6748, -643.1639, -638.2552, -659.5419,\n",
      "         -611.6168, -741.2637, -576.4825, -576.9970],\n",
      "        [-715.0202, -693.3925, 5957.7739, -694.1738, -671.8656, -656.2704,\n",
      "         -647.9773, -728.6353, -582.8843, -569.7910],\n",
      "        [-665.2382, -658.7476, 5600.3940, -637.9853, -636.2311, -623.4935,\n",
      "         -608.2599, -686.7578, -541.2410, -540.8967],\n",
      "        [-687.1629, -666.1544, 5967.7798, -669.3428, -660.4870, -687.9089,\n",
      "         -632.5073, -772.8522, -594.2066, -598.4981],\n",
      "        [-706.8945, -676.6331, 5946.6782, -685.9380, -670.2529, -662.9654,\n",
      "         -643.6708, -736.9051, -588.6699, -578.0085],\n",
      "        [-701.0005, -692.5143, 5841.9873, -679.6094, -658.5627, -642.4980,\n",
      "         -638.7104, -710.8255, -566.2496, -552.2798],\n",
      "        [-667.8755, -638.4268, 5788.4971, -649.6421, -641.5812, -668.6279,\n",
      "         -615.1707, -742.2625, -582.1843, -583.7907],\n",
      "        [-678.7870, -653.0382, 5915.2383, -659.2926, -650.6019, -687.7704,\n",
      "         -622.0910, -774.2682, -586.4675, -604.0280],\n",
      "        [-605.0996, -591.1752, 5159.2134, -583.0242, -572.1624, -592.1805,\n",
      "         -558.0657, -641.9253, -508.9587, -502.3476],\n",
      "        [-670.0920, -644.6407, 5851.5337, -651.2045, -643.1964, -681.2256,\n",
      "         -614.9490, -768.8310, -579.6348, -598.6069],\n",
      "        [-688.1656, -653.8044, 5699.2090, -663.3885, -643.1024, -628.9040,\n",
      "         -625.2649, -694.2169, -565.1241, -541.2883],\n",
      "        [-674.6697, -645.6169, 5900.4312, -655.0967, -646.3699, -690.7613,\n",
      "         -617.1917, -776.2993, -585.8725, -609.8428],\n",
      "        [-671.9496, -642.3440, 5787.5762, -650.5911, -641.1362, -662.8502,\n",
      "         -616.4266, -743.7698, -581.1921, -579.3510]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([1, 0, 0, 7, 5, 8, 9, 3, 6, 4, 1, 1, 7, 1, 5, 5, 5, 6, 3, 8, 3, 6, 7, 2,\n",
      "        1, 8, 7, 5, 7, 0, 9, 8], device='cuda:0')\n",
      "loss_ce tensor(6268.4219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[-802.2961, -816.1570, 7067.0693, -780.8118, -738.6205, -838.7103,\n",
      "         -740.4397, -938.2070, -713.6523, -699.4650],\n",
      "        [-821.7421, -836.6470, 7064.7393, -798.0233, -755.4818, -815.6100,\n",
      "         -753.9169, -902.0732, -703.9447, -677.4989],\n",
      "        [-827.2708, -838.2728, 7099.8477, -803.8450, -756.4420, -819.6638,\n",
      "         -756.7100, -908.4099, -707.8176, -682.5484],\n",
      "        [-834.4639, -858.3050, 7152.3340, -814.5531, -758.5114, -823.2296,\n",
      "         -760.5153, -909.2964, -712.0151, -681.7753],\n",
      "        [-788.0322, -786.0380, 6800.8784, -770.1517, -714.5832, -791.7383,\n",
      "         -722.5516, -871.8334, -698.4582, -657.0239],\n",
      "        [-784.2234, -771.9964, 6614.6221, -759.2870, -709.0746, -754.9055,\n",
      "         -715.4689, -825.7503, -666.6823, -630.0023],\n",
      "        [-808.9665, -822.3732, 7119.7900, -787.7808, -744.1997, -845.3498,\n",
      "         -745.8675, -943.3495, -720.1229, -703.1546],\n",
      "        [-784.1190, -790.2640, 6801.0254, -765.0405, -709.8357, -800.7690,\n",
      "         -717.2709, -879.0847, -688.4879, -665.9062],\n",
      "        [-804.3163, -815.5522, 6900.3315, -778.3123, -738.0686, -796.7615,\n",
      "         -738.1940, -880.0416, -685.1771, -664.2385],\n",
      "        [-825.5114, -840.2504, 7098.0249, -801.4501, -757.5180, -820.3464,\n",
      "         -756.7271, -908.4143, -706.9853, -681.5159],\n",
      "        [-804.8489, -816.1139, 7055.5151, -781.5813, -741.3317, -834.9551,\n",
      "         -744.0981, -925.3832, -716.6884, -692.1725],\n",
      "        [-827.2762, -840.6519, 7053.6406, -803.4841, -750.9388, -811.4103,\n",
      "         -753.2418, -894.7999, -699.9600, -672.4427],\n",
      "        [-791.3597, -791.0169, 6826.2534, -772.3865, -719.3580, -793.5408,\n",
      "         -726.3834, -875.1277, -696.8985, -660.1922],\n",
      "        [-794.8243, -806.8456, 6942.3691, -771.3287, -726.1264, -821.0284,\n",
      "         -730.9282, -906.6793, -701.0154, -682.8247],\n",
      "        [-802.4819, -813.3910, 7087.3613, -784.6484, -738.7259, -845.1451,\n",
      "         -738.9864, -938.2459, -718.3443, -709.1227],\n",
      "        [-819.1856, -834.1104, 7028.6548, -795.0497, -751.7430, -809.4509,\n",
      "         -752.0573, -895.4974, -698.4874, -673.6401],\n",
      "        [-833.8602, -857.6252, 7148.7095, -811.0029, -759.2324, -823.7603,\n",
      "         -760.7741, -911.6833, -708.6814, -682.1503],\n",
      "        [-803.3595, -817.9116, 7091.3174, -784.2866, -739.7890, -844.9222,\n",
      "         -739.7092, -939.3677, -713.9268, -710.0554],\n",
      "        [-830.2205, -853.5972, 7083.5674, -805.9648, -753.5589, -813.8049,\n",
      "         -757.8362, -895.7988, -700.3947, -672.5198],\n",
      "        [-813.8931, -822.2873, 7061.5269, -789.8956, -750.3616, -825.8972,\n",
      "         -749.5018, -913.7382, -707.5664, -689.1246],\n",
      "        [-818.2505, -838.5983, 7128.2671, -798.8925, -750.4677, -835.6061,\n",
      "         -753.3162, -927.7279, -719.3978, -687.3688],\n",
      "        [-804.9749, -806.7774, 6934.4009, -783.9749, -732.8391, -805.0271,\n",
      "         -738.6418, -889.0225, -704.7092, -669.9522],\n",
      "        [-822.5112, -835.8718, 7083.8682, -797.8933, -756.7109, -819.9858,\n",
      "         -754.8063, -908.4440, -705.0744, -683.0216],\n",
      "        [-772.1989, -780.6244, 6474.9771, -740.9299, -700.7784, -731.4006,\n",
      "         -704.1733, -799.3666, -636.9594, -608.4567],\n",
      "        [-810.2740, -826.0775, 7129.6807, -789.4543, -745.3655, -846.7274,\n",
      "         -747.4094, -943.4007, -719.9464, -702.3026],\n",
      "        [-820.2094, -821.0720, 6969.7598, -792.4794, -740.2228, -802.0200,\n",
      "         -743.9114, -885.6238, -693.2547, -670.5133],\n",
      "        [-798.5507, -810.4031, 7013.0713, -777.8232, -736.8400, -829.1096,\n",
      "         -740.9974, -918.3233, -715.0699, -687.0636],\n",
      "        [-830.9467, -842.1962, 7128.4966, -813.6438, -752.9720, -822.3036,\n",
      "         -755.9513, -911.1356, -717.4424, -683.0963],\n",
      "        [-810.8907, -819.1945, 6954.3945, -784.6833, -744.2604, -803.2537,\n",
      "         -743.6327, -887.1331, -690.1281, -670.9998],\n",
      "        [-803.8868, -817.3071, 7094.2729, -783.4327, -740.4263, -845.8925,\n",
      "         -742.3907, -939.5089, -718.3758, -704.6490],\n",
      "        [-795.2239, -789.1287, 6779.9741, -763.7505, -721.7679, -785.4443,\n",
      "         -726.0594, -868.4424, -677.5562, -654.8541],\n",
      "        [-807.6128, -822.7864, 7109.2729, -785.3879, -743.6683, -845.0531,\n",
      "         -745.8354, -941.7633, -718.6675, -699.9376]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([7, 2, 2, 1, 8, 2, 7, 5, 4, 2, 8, 1, 8, 5, 9, 4, 1, 9, 1, 2, 5, 8, 2, 6,\n",
      "        5, 0, 8, 3, 2, 9, 6, 7], device='cuda:0')\n",
      "loss_ce tensor(6083.3804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "ep0, loss_cs: -6083.380371, loss_cos: 0.872045, loss_obj: -3041.254150, lr: 0.04286875\n",
      "model(x), sizetorch.Size([32, 10]), tensor([[ -914.2425,  -989.6346,  8090.3071,  -888.9916,  -851.6047,  -944.5980,\n",
      "          -858.0257, -1013.5380,  -858.3444,  -772.4051],\n",
      "        [ -885.6525,  -957.4217,  8099.6411,  -862.0841,  -836.7844,  -981.9385,\n",
      "          -834.1862, -1059.2550,  -864.3544,  -818.8397],\n",
      "        [ -922.4721, -1004.3686,  8213.7090,  -898.1277,  -860.0587,  -965.0720,\n",
      "          -864.4682, -1038.9619,  -869.2537,  -791.1624],\n",
      "        [ -913.7676,  -985.3274,  8112.8091,  -891.2106,  -850.5985,  -952.0259,\n",
      "          -856.6771, -1022.7075,  -862.0175,  -780.0054],\n",
      "        [ -917.8757,  -989.0175,  8126.6309,  -889.8829,  -851.7039,  -952.4376,\n",
      "          -858.2634, -1024.3302,  -863.9255,  -780.4937],\n",
      "        [ -896.7501,  -974.5574,  8185.7163,  -874.2299,  -846.5143,  -986.0292,\n",
      "          -845.4205, -1068.7346,  -881.0522,  -812.5422],\n",
      "        [ -874.0195,  -935.0914,  7594.2588,  -839.0345,  -803.9693,  -875.7059,\n",
      "          -815.3253,  -935.3277,  -798.1233,  -717.0222],\n",
      "        [ -906.3506,  -969.5680,  8127.1772,  -887.7220,  -841.9597,  -968.0120,\n",
      "          -847.0815, -1036.8168,  -875.8077,  -795.3931],\n",
      "        [ -877.9763,  -948.7441,  8083.6309,  -854.1414,  -828.8165,  -988.3209,\n",
      "          -827.1781, -1072.2816,  -865.8215,  -821.0022],\n",
      "        [ -921.2782, -1005.1462,  8209.6152,  -897.1658,  -860.0118,  -964.2938,\n",
      "          -863.6201, -1038.6403,  -870.2795,  -789.8812],\n",
      "        [ -913.7264,  -989.2126,  8185.4697,  -888.5207,  -859.2748,  -966.7005,\n",
      "          -860.7089, -1041.5597,  -872.6904,  -793.7183],\n",
      "        [ -896.0995,  -961.5082,  8074.6143,  -873.8875,  -837.6985,  -965.0376,\n",
      "          -840.6573, -1034.3073,  -871.4894,  -794.1337],\n",
      "        [ -860.2279,  -928.0790,  7711.6777,  -833.5941,  -812.7930,  -910.1628,\n",
      "          -813.1158,  -980.4997,  -824.4401,  -748.5690],\n",
      "        [ -881.4512,  -955.5151,  8116.9741,  -859.0778,  -834.2779,  -989.2971,\n",
      "          -831.4429, -1075.9857,  -868.6063,  -821.8905],\n",
      "        [ -871.8934,  -933.8848,  7974.8789,  -848.4125,  -822.4956,  -970.2077,\n",
      "          -821.1494, -1041.7477,  -855.0013,  -811.4568],\n",
      "        [ -907.7917,  -977.2087,  8106.1338,  -881.6335,  -852.2118,  -955.5158,\n",
      "          -854.4434, -1029.1564,  -864.5894,  -785.0358],\n",
      "        [ -895.1279,  -979.2487,  8057.4473,  -868.8713,  -845.3898,  -953.4702,\n",
      "          -843.4644, -1030.2394,  -856.3129,  -783.9487],\n",
      "        [ -893.9706,  -972.7751,  8205.0957,  -872.7773,  -845.0131,  -995.5129,\n",
      "          -842.9149, -1081.5615,  -880.0230,  -821.0513],\n",
      "        [ -920.3652, -1012.0759,  8219.6533,  -897.6869,  -859.4749,  -966.8502,\n",
      "          -862.4227, -1040.9496,  -867.8765,  -791.8047],\n",
      "        [ -918.1432,  -994.8130,  8138.8203,  -893.6696,  -854.0667,  -952.9464,\n",
      "          -859.8376, -1023.6664,  -862.7761,  -780.1023],\n",
      "        [ -903.1787,  -966.5196,  7917.6709,  -871.6596,  -832.5508,  -921.3416,\n",
      "          -842.4927,  -987.5237,  -840.3155,  -753.3162],\n",
      "        [ -875.5391,  -964.9359,  8002.0674,  -855.6101,  -826.2372,  -968.4230,\n",
      "          -827.7966, -1034.5900,  -855.5097,  -792.3348],\n",
      "        [ -879.8962,  -947.2303,  7768.2822,  -851.5784,  -825.0999,  -902.7476,\n",
      "          -827.7739,  -968.1865,  -824.2271,  -740.8471],\n",
      "        [ -888.1675,  -962.4618,  8102.8223,  -867.0931,  -838.5361,  -978.8707,\n",
      "          -838.9443, -1050.6039,  -875.0032,  -804.2108],\n",
      "        [ -885.0934,  -963.8142,  8123.9111,  -863.7070,  -837.1795,  -984.0480,\n",
      "          -834.9569, -1071.8615,  -870.8773,  -812.4279],\n",
      "        [ -922.4973,  -999.2410,  8211.3145,  -901.0601,  -858.5360,  -964.7751,\n",
      "          -863.2953, -1037.4462,  -874.2781,  -791.3353],\n",
      "        [ -917.7928,  -988.4791,  8133.5884,  -890.0442,  -852.9665,  -953.6031,\n",
      "          -859.6409, -1024.8264,  -866.0446,  -781.0533],\n",
      "        [ -870.5914,  -939.9056,  7976.1123,  -847.2916,  -820.5522,  -968.4374,\n",
      "          -821.7855, -1045.3972,  -866.9073,  -796.4859],\n",
      "        [ -892.7870,  -972.6504,  8196.3379,  -872.2496,  -844.5743,  -993.9192,\n",
      "          -842.9124, -1078.6626,  -881.3965,  -817.7603],\n",
      "        [ -902.1962,  -974.4467,  8067.3447,  -874.4488,  -850.1271,  -950.0568,\n",
      "          -851.3878, -1024.3014,  -860.7416,  -780.6630],\n",
      "        [ -919.9442,  -999.3800,  8203.8994,  -897.4135,  -858.9518,  -964.6817,\n",
      "          -862.8948, -1037.9844,  -873.0153,  -790.7504],\n",
      "        [ -917.3585, -1006.5638,  8154.1665,  -892.7759,  -855.1770,  -955.0222,\n",
      "          -859.5920, -1025.9801,  -859.3417,  -781.9139]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([4, 9, 1, 6, 0, 8, 0, 8, 9, 3, 6, 8, 6, 7, 9, 6, 2, 7, 1, 6, 0, 5, 2, 8,\n",
      "        7, 3, 6, 8, 7, 6, 3, 1], device='cuda:0')\n",
      "loss_ce tensor(8437.0381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "model(x), sizetorch.Size([10, 10]), tensor([[-1007.6146, -1093.7419,  9291.0596,  -986.2066,  -907.7487, -1061.7249,\n",
      "         -1046.2942, -1225.4712, -1039.4800,  -922.6730],\n",
      "        [-1057.0229, -1139.6683,  9526.1123, -1035.4391,  -941.4990, -1062.9753,\n",
      "         -1087.0052, -1214.5530, -1059.3055,  -927.7059],\n",
      "        [-1020.5863, -1106.7211,  9374.2480,  -999.2575,  -916.5767, -1067.3850,\n",
      "         -1055.9849, -1227.8380, -1048.2947,  -929.6694],\n",
      "        [-1011.6788, -1099.3849,  9332.2764,  -990.3509,  -910.4276, -1067.6659,\n",
      "         -1049.8611, -1231.6462, -1039.0941,  -933.7756],\n",
      "        [-1022.4476, -1096.7770,  9137.3730,  -990.7200,  -911.3215, -1016.2007,\n",
      "         -1059.0135, -1151.1799, -1012.9847,  -878.1389],\n",
      "        [-1043.3833, -1134.1576,  9500.3975, -1023.0151,  -938.6503, -1067.8208,\n",
      "         -1078.8794, -1225.6937, -1057.9801,  -929.1453],\n",
      "        [-1053.6188, -1144.5126,  9545.5566, -1036.3083,  -941.7812, -1067.6555,\n",
      "         -1084.4523, -1223.6790, -1063.2997,  -929.2054],\n",
      "        [-1014.0356, -1097.4258,  9378.5020,  -993.1884,  -915.8528, -1074.2913,\n",
      "         -1054.9091, -1234.2502, -1052.4543,  -942.9591],\n",
      "        [ -996.6546, -1085.4563,  9215.5195,  -977.0402,  -902.9321, -1052.4292,\n",
      "         -1040.8668, -1203.9218, -1041.9871,  -912.0121],\n",
      "        [-1051.6274, -1136.4404,  9411.3105, -1023.2383,  -937.1248, -1043.4015,\n",
      "         -1081.1830, -1190.4595, -1037.0065,  -910.3029]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y tensor([7, 0, 8, 5, 0, 4, 3, 9, 8, 0], device='cuda:0')\n",
      "loss_ce tensor(10414.4785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "eval losses [1.04, 2.46, 18.52, 49.68, 91.29, 131.26, 209.2, 295.28, 399.8, 566.95, 753.92, 1082.9, 1470.62, 1981.39, 2608.48, 3533.47, 3753.06, 5803.12, 8083.83]\n",
      "cos_d: 0.8867213726043701, budget: 0.1\n",
      "budget exceeded, finish training early, ep = 0\n",
      "crafted cos: 0.10020971298217773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': -1605.4140338386524}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model2 train with new loss function\n",
    "optimizer2 = optim.SGD(model2.parameters(), lr=0.05) # 0.001\n",
    "scheduler2 = torch.optim.lr_scheduler.StepLR(optimizer2, step_size=10, gamma=0.95)\n",
    "\n",
    "model2.load_state_dict(model1_sd)\n",
    "train_rev_w_cos(model2, client_loader, optimizer2, scheduler2, epochs=8, \n",
    "                                model0 = model0, \n",
    "                                model1 = model1, \n",
    "                                beta = 0.5, \n",
    "                                budget = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    initial_lr: 0.05\n",
       "    lr: 0.04286875\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1_2 cos dist tensor(0.0034, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cos_d_model1_2 = cos_dist(flat_dict(model1.state_dict()) - flat_dict(model0.state_dict()), \n",
    "                          flat_dict(model2.state_dict()) - flat_dict(model0.state_dict()))\n",
    "print(\"model1_2 cos dist\", cos_d_model1_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0035, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_dist(flat_dict(filter_trainable_state_dict(model1)) - flat_dict(filter_trainable_state_dict(model0)),\n",
    "         flat_dict(filter_trainable_state_dict(model2)) - flat_dict(filter_trainable_state_dict(model0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model2_result {'test_accuracy': 0.1}\n"
     ]
    }
   ],
   "source": [
    "model2_result = eval_op_ensemble([model2], test_loader)\n",
    "print(\"model2_result\", model2_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('features.0.weight',\n",
       "              tensor([[[[ 0.0613, -0.0275,  0.2202],\n",
       "                        [ 0.0242,  0.1756, -0.2839],\n",
       "                        [-0.1478,  0.2592, -0.2472]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0114,  0.1287, -0.0115],\n",
       "                        [ 0.3173, -0.2873,  0.1135],\n",
       "                        [-0.1041, -0.3322, -0.2713]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2120,  0.2647,  0.1445],\n",
       "                        [-0.1276, -0.2407,  0.2731],\n",
       "                        [ 0.0399,  0.2029,  0.1159]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1498,  0.2122,  0.1164],\n",
       "                        [ 0.1134,  0.2563,  0.1857],\n",
       "                        [ 0.2865,  0.0301, -0.1244]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2479, -0.3254, -0.1642],\n",
       "                        [-0.3118, -0.1609,  0.1739],\n",
       "                        [ 0.0314, -0.1409, -0.1808]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1134, -0.0464,  0.0009],\n",
       "                        [-0.0213,  0.2542,  0.0792],\n",
       "                        [-0.1534, -0.0224, -0.0377]]]], device='cuda:0')),\n",
       "             ('features.0.bias',\n",
       "              tensor([ 1.6619e-01,  3.1480e-01,  1.5045e-01,  9.3596e-02, -5.2632e-02,\n",
       "                       2.7470e-01,  2.1630e-01, -5.4368e-03, -6.9357e-02,  3.2990e-01,\n",
       "                       2.8357e-01,  6.4498e-02,  5.1811e-02,  4.7338e-02, -2.2028e-01,\n",
       "                      -2.8374e-01, -4.4483e-02, -1.1852e-01,  9.5901e-02, -2.6850e-01,\n",
       "                      -6.3026e-02,  3.0197e-01, -1.9791e-01, -2.3865e-01, -7.6104e-02,\n",
       "                       2.4652e-01,  1.0620e-01, -2.7466e-01,  1.5909e-01, -1.2587e-01,\n",
       "                      -3.5820e-02, -2.5968e-01, -3.9444e-03,  2.0802e-01,  2.7555e-01,\n",
       "                      -1.9404e-01,  7.6920e-02, -4.9082e-02,  1.0156e-01, -1.5361e-01,\n",
       "                      -3.2196e-02, -1.3142e-01, -1.4936e-01, -1.4417e-01,  2.6043e-01,\n",
       "                      -2.7859e-01, -3.2248e-01, -1.2143e-01,  1.9004e-01, -1.7835e-01,\n",
       "                      -1.8372e-02, -1.0502e-01, -2.1223e-02,  2.5922e-01,  2.7973e-01,\n",
       "                      -1.5105e-01, -6.0132e-02, -2.3411e-01,  1.8190e-01, -5.5798e-02,\n",
       "                       6.0746e-02, -1.6921e-02,  3.1873e-01,  2.0362e-01, -2.1285e-01,\n",
       "                      -2.4584e-01,  3.2986e-01,  2.1981e-01, -2.8427e-04, -2.8076e-01,\n",
       "                      -2.6134e-01,  1.5986e-01, -4.0200e-02, -2.4083e-01, -7.1716e-02,\n",
       "                      -3.2910e-01,  1.4323e-01,  2.9484e-02, -6.4839e-02,  2.1537e-01,\n",
       "                      -1.7189e-01, -3.2860e-01,  2.0574e-01,  1.0846e-01,  2.7199e-01,\n",
       "                      -3.0678e-01,  7.1423e-02,  4.2000e-02, -1.6703e-01,  1.1255e-01,\n",
       "                      -2.3575e-01,  2.9845e-01, -2.6796e-01,  2.3310e-01,  1.3739e-01,\n",
       "                      -1.9138e-01, -1.0814e-01,  3.1432e-01,  3.1776e-01,  1.4417e-03,\n",
       "                      -3.0597e-01,  1.5207e-01, -3.2743e-01, -2.3768e-01, -2.4638e-01,\n",
       "                      -7.2031e-02, -2.4475e-01, -8.8500e-02, -2.3791e-01, -2.8474e-01,\n",
       "                      -3.5423e-02, -2.6499e-02,  2.0337e-01, -3.0927e-01, -4.9439e-03,\n",
       "                       1.6595e-01,  3.9739e-02, -2.8078e-01, -3.0390e-01, -3.3211e-01,\n",
       "                       2.6094e-01, -1.6549e-01, -1.1752e-01, -4.6438e-02, -5.4614e-02,\n",
       "                      -1.3497e-02, -1.7369e-01, -2.6499e-01], device='cuda:0')),\n",
       "             ('features.1.weight',\n",
       "              tensor([1.0001, 0.9999, 0.9998, 0.9999, 0.9996, 1.0001, 0.9998, 1.0006, 1.0002,\n",
       "                      0.9998, 1.0002, 1.0004, 0.9997, 1.0005, 0.9996, 0.9998, 1.0000, 1.0008,\n",
       "                      1.0001, 0.9999, 0.9992, 1.0006, 0.9993, 0.9993, 1.0001, 1.0002, 1.0000,\n",
       "                      0.9999, 1.0000, 1.0002, 0.9998, 1.0009, 1.0008, 1.0002, 1.0005, 1.0005,\n",
       "                      0.9997, 0.9999, 0.9997, 0.9999, 0.9997, 0.9993, 0.9999, 0.9999, 0.9999,\n",
       "                      1.0004, 1.0000, 0.9992, 1.0001, 1.0001, 0.9997, 1.0003, 0.9997, 1.0001,\n",
       "                      1.0001, 0.9999, 1.0002, 1.0002, 0.9999, 1.0001, 1.0000, 1.0009, 0.9998,\n",
       "                      1.0000, 0.9992, 1.0008, 0.9994, 0.9999, 0.9999, 1.0005, 0.9999, 1.0003,\n",
       "                      1.0002, 0.9993, 1.0001, 0.9998, 1.0002, 0.9998, 0.9999, 1.0000, 0.9996,\n",
       "                      1.0005, 1.0001, 1.0007, 0.9998, 1.0001, 0.9997, 0.9999, 0.9993, 1.0006,\n",
       "                      0.9998, 0.9994, 1.0000, 0.9996, 0.9997, 1.0008, 1.0007, 0.9997, 0.9997,\n",
       "                      0.9999, 0.9996, 1.0001, 1.0001, 1.0005, 1.0002, 0.9996, 1.0002, 1.0002,\n",
       "                      1.0010, 1.0001, 1.0002, 0.9999, 0.9995, 0.9995, 1.0001, 1.0001, 0.9999,\n",
       "                      1.0000, 1.0004, 1.0001, 0.9995, 0.9999, 0.9998, 1.0002, 1.0000, 0.9995,\n",
       "                      1.0007, 0.9991], device='cuda:0')),\n",
       "             ('features.1.bias',\n",
       "              tensor([ 2.7519e-05, -2.7432e-04,  4.9509e-05,  1.7495e-04, -1.8464e-04,\n",
       "                       1.9212e-04, -8.6226e-05,  2.7293e-04,  1.8443e-04, -1.2652e-04,\n",
       "                       2.0006e-04, -1.1371e-04, -1.0573e-04,  2.2528e-04, -4.6471e-04,\n",
       "                      -4.7174e-05, -4.5854e-05,  5.3363e-04,  2.9407e-04, -2.5685e-04,\n",
       "                      -3.5729e-04,  1.4610e-04, -1.9807e-04, -3.5112e-04,  1.4094e-04,\n",
       "                      -1.3979e-04,  1.0807e-04, -9.2849e-05, -1.1320e-04, -1.1280e-03,\n",
       "                      -1.3164e-04,  6.3198e-04,  2.9774e-04, -1.3843e-04,  2.9130e-04,\n",
       "                       4.1529e-04, -3.4593e-04, -6.8794e-04, -1.8368e-04, -3.8553e-04,\n",
       "                      -1.2952e-04,  2.4597e-04, -4.7445e-04,  4.1350e-04, -2.2804e-04,\n",
       "                      -8.9304e-05, -4.8534e-04, -6.8726e-04,  1.9685e-04,  2.9518e-04,\n",
       "                       5.4466e-05, -9.6144e-05,  6.5809e-06,  1.8319e-04,  1.9882e-04,\n",
       "                       2.0035e-04, -1.5123e-04,  3.9769e-04, -3.2846e-04, -2.6304e-04,\n",
       "                       3.2647e-05,  6.3266e-04,  1.3737e-05,  2.1858e-05, -4.3018e-05,\n",
       "                       6.0842e-04, -2.6604e-04,  5.1248e-05,  3.0738e-04,  1.6821e-04,\n",
       "                       1.6054e-04,  2.1526e-04, -3.3633e-04, -1.2418e-04,  2.3393e-04,\n",
       "                       1.0708e-04,  4.0720e-04,  4.5783e-05,  2.7119e-04,  4.5762e-04,\n",
       "                      -3.5142e-04, -6.5573e-05, -1.5779e-04,  7.3516e-04, -1.4755e-04,\n",
       "                      -3.9244e-04,  1.4614e-04, -3.4980e-04, -3.7340e-04,  3.4953e-04,\n",
       "                      -6.2955e-06, -1.4137e-04,  1.6912e-05, -6.3430e-04, -3.8647e-04,\n",
       "                       5.1160e-04,  2.5783e-04, -6.0856e-04,  1.1117e-04, -1.8744e-05,\n",
       "                      -4.9726e-04,  3.2963e-04,  6.0259e-04,  1.4217e-04,  3.1151e-04,\n",
       "                       3.0396e-04,  5.4647e-06, -2.4712e-04,  5.9737e-04, -2.2011e-04,\n",
       "                       1.6791e-04, -1.4769e-05, -1.6233e-04, -1.7364e-05,  1.8535e-04,\n",
       "                       4.0647e-05, -2.4215e-05,  4.7404e-04,  4.0849e-04,  1.3759e-04,\n",
       "                      -2.9025e-05, -1.1881e-04, -1.1409e-04,  1.1246e-04,  1.6621e-05,\n",
       "                       1.2031e-04,  1.1509e-04, -3.0716e-04], device='cuda:0')),\n",
       "             ('features.4.weight',\n",
       "              tensor([[[[-0.0130,  0.0280, -0.0043],\n",
       "                        [ 0.0027,  0.0021,  0.0213],\n",
       "                        [-0.0204,  0.0297,  0.0263]],\n",
       "              \n",
       "                       [[-0.0234,  0.0090,  0.0059],\n",
       "                        [ 0.0239, -0.0019, -0.0030],\n",
       "                        [-0.0136, -0.0210, -0.0243]],\n",
       "              \n",
       "                       [[-0.0057, -0.0123,  0.0131],\n",
       "                        [ 0.0074,  0.0096, -0.0166],\n",
       "                        [ 0.0276,  0.0155, -0.0183]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0021, -0.0234,  0.0238],\n",
       "                        [ 0.0257, -0.0206, -0.0153],\n",
       "                        [ 0.0162,  0.0218,  0.0083]],\n",
       "              \n",
       "                       [[-0.0177, -0.0255,  0.0003],\n",
       "                        [-0.0150,  0.0191,  0.0268],\n",
       "                        [-0.0288,  0.0159, -0.0173]],\n",
       "              \n",
       "                       [[ 0.0270,  0.0160, -0.0063],\n",
       "                        [-0.0195, -0.0154,  0.0260],\n",
       "                        [-0.0085, -0.0019,  0.0230]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0206, -0.0139, -0.0026],\n",
       "                        [-0.0155, -0.0022,  0.0064],\n",
       "                        [-0.0113, -0.0154,  0.0052]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0071,  0.0041],\n",
       "                        [ 0.0124,  0.0212, -0.0291],\n",
       "                        [ 0.0208, -0.0107,  0.0102]],\n",
       "              \n",
       "                       [[ 0.0140,  0.0072, -0.0152],\n",
       "                        [-0.0237,  0.0145,  0.0064],\n",
       "                        [ 0.0239,  0.0176, -0.0159]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0019,  0.0217, -0.0174],\n",
       "                        [ 0.0098,  0.0183, -0.0225],\n",
       "                        [ 0.0212, -0.0186,  0.0052]],\n",
       "              \n",
       "                       [[-0.0032,  0.0227,  0.0287],\n",
       "                        [-0.0282, -0.0244, -0.0017],\n",
       "                        [ 0.0015,  0.0235,  0.0275]],\n",
       "              \n",
       "                       [[ 0.0187, -0.0267,  0.0224],\n",
       "                        [ 0.0165,  0.0285, -0.0098],\n",
       "                        [-0.0103,  0.0171, -0.0230]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0006, -0.0070,  0.0271],\n",
       "                        [ 0.0054, -0.0022, -0.0040],\n",
       "                        [ 0.0176, -0.0048, -0.0280]],\n",
       "              \n",
       "                       [[-0.0030, -0.0113,  0.0202],\n",
       "                        [-0.0126,  0.0280, -0.0194],\n",
       "                        [ 0.0227,  0.0283, -0.0216]],\n",
       "              \n",
       "                       [[ 0.0279, -0.0182, -0.0180],\n",
       "                        [ 0.0022, -0.0160,  0.0189],\n",
       "                        [ 0.0233, -0.0211, -0.0048]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0296,  0.0160, -0.0123],\n",
       "                        [ 0.0248,  0.0227,  0.0233],\n",
       "                        [-0.0075, -0.0072,  0.0089]],\n",
       "              \n",
       "                       [[-0.0111,  0.0004, -0.0288],\n",
       "                        [-0.0195,  0.0095, -0.0047],\n",
       "                        [ 0.0057,  0.0008, -0.0203]],\n",
       "              \n",
       "                       [[ 0.0221, -0.0126, -0.0192],\n",
       "                        [-0.0057, -0.0257,  0.0140],\n",
       "                        [-0.0276, -0.0261, -0.0237]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0183, -0.0156,  0.0174],\n",
       "                        [-0.0232, -0.0049, -0.0223],\n",
       "                        [-0.0057,  0.0179,  0.0047]],\n",
       "              \n",
       "                       [[ 0.0007,  0.0184,  0.0018],\n",
       "                        [-0.0037,  0.0255,  0.0189],\n",
       "                        [ 0.0009,  0.0148, -0.0152]],\n",
       "              \n",
       "                       [[ 0.0001,  0.0286,  0.0033],\n",
       "                        [ 0.0222,  0.0097,  0.0144],\n",
       "                        [-0.0119,  0.0028,  0.0287]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0278, -0.0057,  0.0239],\n",
       "                        [ 0.0046, -0.0061,  0.0240],\n",
       "                        [-0.0163, -0.0026,  0.0259]],\n",
       "              \n",
       "                       [[ 0.0169, -0.0220, -0.0097],\n",
       "                        [ 0.0287, -0.0066, -0.0008],\n",
       "                        [ 0.0042, -0.0269, -0.0077]],\n",
       "              \n",
       "                       [[-0.0191,  0.0122, -0.0088],\n",
       "                        [ 0.0279, -0.0012,  0.0236],\n",
       "                        [-0.0061, -0.0239, -0.0274]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0087,  0.0019,  0.0141],\n",
       "                        [-0.0166,  0.0243, -0.0090],\n",
       "                        [ 0.0112, -0.0220, -0.0289]],\n",
       "              \n",
       "                       [[-0.0144,  0.0037, -0.0283],\n",
       "                        [ 0.0238, -0.0295, -0.0205],\n",
       "                        [-0.0195,  0.0190,  0.0009]],\n",
       "              \n",
       "                       [[-0.0289, -0.0189, -0.0198],\n",
       "                        [ 0.0185, -0.0270, -0.0204],\n",
       "                        [-0.0233, -0.0038, -0.0152]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0043, -0.0074,  0.0236],\n",
       "                        [ 0.0009, -0.0216,  0.0054],\n",
       "                        [ 0.0225,  0.0194,  0.0119]],\n",
       "              \n",
       "                       [[ 0.0165, -0.0223, -0.0242],\n",
       "                        [ 0.0164, -0.0002,  0.0242],\n",
       "                        [ 0.0266, -0.0081, -0.0232]],\n",
       "              \n",
       "                       [[-0.0062, -0.0197, -0.0150],\n",
       "                        [ 0.0246,  0.0041, -0.0256],\n",
       "                        [-0.0144,  0.0019,  0.0039]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0196, -0.0133,  0.0098],\n",
       "                        [-0.0203, -0.0242,  0.0227],\n",
       "                        [ 0.0102,  0.0145, -0.0268]],\n",
       "              \n",
       "                       [[ 0.0042, -0.0234, -0.0185],\n",
       "                        [-0.0250, -0.0096, -0.0014],\n",
       "                        [ 0.0070,  0.0101,  0.0034]],\n",
       "              \n",
       "                       [[ 0.0139,  0.0126, -0.0197],\n",
       "                        [-0.0183, -0.0034,  0.0261],\n",
       "                        [ 0.0017, -0.0155, -0.0113]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0040, -0.0149, -0.0003],\n",
       "                        [ 0.0102,  0.0179,  0.0230],\n",
       "                        [-0.0210, -0.0084, -0.0203]],\n",
       "              \n",
       "                       [[-0.0044,  0.0134,  0.0053],\n",
       "                        [ 0.0221,  0.0200,  0.0260],\n",
       "                        [-0.0186,  0.0011,  0.0059]],\n",
       "              \n",
       "                       [[ 0.0188, -0.0040,  0.0053],\n",
       "                        [ 0.0193, -0.0272, -0.0220],\n",
       "                        [ 0.0039, -0.0012, -0.0089]]]], device='cuda:0')),\n",
       "             ('features.4.bias',\n",
       "              tensor([ 2.3021e-02, -2.3947e-02,  1.7811e-02,  9.0996e-03,  2.2046e-02,\n",
       "                       1.9105e-02,  6.2528e-03,  1.9683e-02, -2.1021e-02, -2.8148e-02,\n",
       "                      -1.9805e-02, -2.0097e-02,  2.6516e-02,  1.7119e-02,  1.7809e-02,\n",
       "                       1.8103e-02,  9.2364e-03,  9.2168e-03, -2.8026e-02, -1.0518e-02,\n",
       "                       1.7020e-02,  1.2434e-02, -7.2074e-03, -3.7297e-04,  1.5020e-02,\n",
       "                      -2.2341e-02,  1.0105e-02, -1.0883e-02, -7.0123e-03, -1.6797e-02,\n",
       "                       1.0242e-02,  2.5711e-02, -1.2692e-02,  5.1062e-03,  2.3270e-02,\n",
       "                       1.1890e-02,  1.1200e-02,  2.3282e-02, -1.5574e-02, -3.8588e-03,\n",
       "                      -3.6327e-03,  7.3167e-03,  7.8452e-03, -1.7092e-02,  2.9274e-02,\n",
       "                       1.6166e-02, -7.7329e-03,  2.7865e-02, -7.2957e-03,  1.6935e-02,\n",
       "                      -1.8395e-02,  2.0830e-02, -2.1335e-03, -1.6848e-02,  1.5381e-02,\n",
       "                       1.0647e-02,  2.5208e-04, -7.8752e-04,  2.5462e-02, -2.8277e-03,\n",
       "                      -2.9162e-02,  1.9623e-02, -8.9160e-03,  1.7442e-02,  2.1250e-02,\n",
       "                      -1.5074e-02, -2.2466e-02, -1.8481e-03,  1.4185e-02,  6.4966e-04,\n",
       "                      -2.7002e-02, -1.9268e-02,  1.4026e-02, -2.6946e-02, -1.0709e-02,\n",
       "                       2.9037e-03,  1.4864e-02, -5.0268e-03,  5.6771e-03, -1.1824e-02,\n",
       "                       1.4213e-02, -1.2629e-02,  2.5685e-03,  1.8452e-03,  2.2060e-03,\n",
       "                       2.9037e-02, -1.8870e-02, -1.0085e-02,  1.1286e-03,  2.5186e-02,\n",
       "                      -8.1159e-03,  7.4082e-03, -2.7970e-02,  2.1473e-02, -2.0352e-02,\n",
       "                       2.5042e-02,  2.6711e-02,  2.5514e-02,  1.2227e-02,  1.0302e-02,\n",
       "                      -1.5466e-02,  2.5603e-02, -1.0873e-02,  6.5474e-03,  8.3024e-03,\n",
       "                      -2.5161e-02,  2.3864e-02,  8.1847e-03,  4.5315e-05,  2.8938e-02,\n",
       "                       1.0951e-02,  1.3421e-03, -2.5517e-03,  2.4885e-02, -9.6300e-03,\n",
       "                       2.5707e-04, -2.1416e-02,  2.1314e-02,  4.6396e-03, -1.8362e-02,\n",
       "                       2.7516e-02, -1.7090e-03,  1.0273e-02,  1.5974e-02,  9.7636e-03,\n",
       "                       5.2465e-03, -7.7064e-03, -1.1803e-03], device='cuda:0')),\n",
       "             ('features.5.weight',\n",
       "              tensor([1.0004, 0.9998, 1.0005, 1.0002, 1.0008, 1.0001, 1.0001, 0.9995, 0.9998,\n",
       "                      0.9997, 0.9992, 0.9990, 1.0004, 0.9988, 1.0007, 1.0007, 1.0006, 0.9998,\n",
       "                      0.9996, 0.9995, 0.9997, 1.0000, 1.0002, 0.9991, 1.0014, 1.0001, 1.0003,\n",
       "                      1.0005, 0.9994, 0.9993, 1.0006, 0.9999, 1.0002, 1.0000, 1.0000, 1.0005,\n",
       "                      0.9997, 1.0002, 0.9996, 0.9996, 0.9986, 0.9995, 1.0012, 1.0004, 1.0001,\n",
       "                      0.9992, 1.0010, 0.9991, 0.9991, 0.9998, 1.0010, 0.9995, 0.9999, 1.0000,\n",
       "                      0.9999, 0.9997, 1.0008, 1.0003, 1.0000, 0.9997, 1.0007, 1.0007, 0.9999,\n",
       "                      1.0008, 1.0002, 0.9994, 0.9995, 1.0011, 0.9994, 0.9993, 1.0000, 1.0004,\n",
       "                      0.9999, 1.0001, 0.9997, 0.9995, 0.9998, 1.0008, 0.9998, 1.0004, 1.0001,\n",
       "                      0.9987, 1.0002, 0.9999, 1.0000, 0.9999, 1.0010, 0.9999, 0.9999, 0.9998,\n",
       "                      1.0000, 1.0002, 0.9991, 1.0001, 1.0003, 1.0000, 1.0000, 0.9998, 0.9996,\n",
       "                      0.9998, 0.9994, 1.0007, 1.0018, 0.9998, 1.0009, 1.0006, 0.9999, 1.0005,\n",
       "                      0.9999, 0.9990, 0.9994, 1.0006, 0.9994, 1.0000, 0.9998, 0.9999, 1.0000,\n",
       "                      1.0002, 0.9996, 1.0006, 1.0004, 1.0001, 1.0005, 0.9997, 0.9995, 0.9997,\n",
       "                      1.0000, 1.0001], device='cuda:0')),\n",
       "             ('features.5.bias',\n",
       "              tensor([-2.6416e-04, -2.5565e-04,  8.9755e-04,  1.5487e-04,  8.9316e-04,\n",
       "                      -2.3792e-04, -3.3329e-05, -5.6329e-04, -3.4127e-04, -4.7840e-04,\n",
       "                      -6.9765e-04, -7.6726e-04,  3.8237e-04, -5.8001e-04,  1.7012e-04,\n",
       "                       4.5978e-04,  3.3552e-04, -2.6072e-04, -4.3821e-04, -9.0586e-05,\n",
       "                      -3.3287e-04, -3.4484e-05, -4.4903e-04, -1.0491e-03,  8.6465e-04,\n",
       "                       8.4818e-05, -9.4993e-05,  1.0305e-04, -5.9453e-04, -2.7125e-04,\n",
       "                       4.2373e-04, -2.1235e-04, -5.5309e-05, -1.6335e-04,  1.5929e-06,\n",
       "                       1.4877e-04, -5.0591e-04,  1.1678e-04, -2.2419e-04,  1.1609e-04,\n",
       "                      -1.2984e-03, -3.2617e-04,  5.9194e-04,  1.8978e-04, -2.5988e-05,\n",
       "                      -5.5592e-04,  3.0629e-04, -4.5012e-04, -7.0077e-04,  6.4990e-04,\n",
       "                       7.0514e-04, -5.5967e-04, -4.4044e-04,  5.1874e-05, -3.3514e-04,\n",
       "                      -2.0748e-04,  4.6193e-04,  3.1272e-04, -2.9233e-05, -6.5393e-04,\n",
       "                       5.1128e-04,  5.9145e-04, -3.9203e-04,  3.7879e-04,  4.4282e-04,\n",
       "                      -7.1496e-04, -3.1216e-04,  9.2876e-04, -3.7147e-04, -7.5147e-04,\n",
       "                      -2.5887e-04,  2.3122e-04,  7.8994e-05,  1.6920e-04, -3.4882e-04,\n",
       "                      -6.5222e-04, -5.8891e-04,  4.5668e-04, -6.1909e-04,  1.0891e-04,\n",
       "                      -1.4832e-04, -7.1644e-04,  1.0399e-05, -1.9307e-04, -1.1226e-04,\n",
       "                       1.9495e-04,  4.8472e-04, -2.8323e-04,  3.8926e-05, -2.0606e-04,\n",
       "                      -2.2185e-04, -4.3038e-04, -5.7049e-04,  9.2207e-05,  9.6713e-05,\n",
       "                      -3.8758e-05,  1.8137e-05, -9.2791e-05, -5.6869e-04, -5.8850e-04,\n",
       "                      -2.1719e-04,  4.0521e-04,  8.5805e-04, -6.4702e-04,  5.7691e-04,\n",
       "                      -1.9541e-04, -6.8071e-04,  6.0376e-04, -3.2989e-04, -7.8945e-04,\n",
       "                      -5.2896e-04,  5.3231e-04, -2.9258e-04, -1.4342e-04, -3.7860e-04,\n",
       "                      -8.1333e-05,  1.4751e-04,  1.1848e-04, -7.2045e-04,  6.3578e-04,\n",
       "                       5.2505e-05, -3.7646e-05, -3.5411e-05, -2.2159e-05, -2.3796e-04,\n",
       "                      -1.3696e-04,  3.9782e-04,  4.9044e-05], device='cuda:0')),\n",
       "             ('features.8.weight',\n",
       "              tensor([[[[-2.2934e-02,  1.6231e-03,  2.2876e-02],\n",
       "                        [-3.3711e-03, -2.1487e-02, -3.6748e-03],\n",
       "                        [ 1.5013e-02,  1.0083e-02,  6.3090e-03]],\n",
       "              \n",
       "                       [[-2.7385e-02,  1.5324e-02,  2.7910e-02],\n",
       "                        [ 1.7717e-02,  2.6783e-02, -2.3802e-02],\n",
       "                        [-2.9689e-02,  2.8720e-02,  5.0791e-03]],\n",
       "              \n",
       "                       [[-1.9674e-02, -4.6194e-03, -1.7804e-02],\n",
       "                        [ 7.0164e-03,  1.0306e-02,  1.6407e-02],\n",
       "                        [-2.6770e-02, -9.7510e-03, -2.7693e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.2779e-03,  3.6100e-04, -1.2024e-02],\n",
       "                        [-2.4597e-02,  1.7720e-02,  1.3936e-02],\n",
       "                        [-9.0994e-04, -2.0565e-02,  2.0494e-02]],\n",
       "              \n",
       "                       [[-1.8250e-02,  3.7147e-03, -2.0077e-02],\n",
       "                        [-2.4608e-02,  5.6346e-03,  2.3522e-02],\n",
       "                        [-6.5637e-03, -1.4230e-02,  1.7055e-02]],\n",
       "              \n",
       "                       [[ 2.7831e-02, -1.5780e-02,  1.7731e-02],\n",
       "                        [ 2.9282e-02, -8.5826e-03,  1.3750e-02],\n",
       "                        [-1.3603e-02, -6.1082e-03,  7.2085e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4617e-02, -5.0678e-03, -7.7381e-03],\n",
       "                        [ 2.7504e-02,  5.2219e-03, -2.5855e-02],\n",
       "                        [-2.3227e-02,  2.3511e-02,  2.6337e-02]],\n",
       "              \n",
       "                       [[-2.1569e-02, -1.9850e-02, -8.0835e-03],\n",
       "                        [ 1.4633e-02,  4.3697e-03,  1.3506e-02],\n",
       "                        [-9.2271e-03, -6.5917e-03, -8.1761e-03]],\n",
       "              \n",
       "                       [[ 2.0893e-02, -1.0750e-02, -2.1470e-02],\n",
       "                        [ 1.0530e-02, -1.1537e-02, -3.7784e-03],\n",
       "                        [ 2.4622e-02,  1.4364e-02,  2.6834e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.4236e-02,  2.7438e-02,  1.0276e-02],\n",
       "                        [-2.0233e-02,  1.8752e-02,  1.5720e-03],\n",
       "                        [-2.4418e-03,  1.0714e-02,  1.3110e-02]],\n",
       "              \n",
       "                       [[-9.9075e-04,  1.0124e-02,  1.1462e-03],\n",
       "                        [-1.5134e-02, -1.3315e-02,  1.6119e-03],\n",
       "                        [-5.5998e-03, -4.2570e-03,  8.7196e-03]],\n",
       "              \n",
       "                       [[ 2.9402e-02,  1.8200e-02, -2.8536e-02],\n",
       "                        [-2.2487e-02,  1.9397e-02, -1.1342e-03],\n",
       "                        [ 5.5866e-03,  9.6175e-03,  3.0239e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.5177e-03,  1.2918e-02,  2.1218e-02],\n",
       "                        [ 2.9249e-04, -1.9520e-02,  7.7358e-04],\n",
       "                        [ 8.5360e-03,  2.8216e-02, -1.7464e-02]],\n",
       "              \n",
       "                       [[ 8.6811e-03,  2.6565e-02, -1.8978e-02],\n",
       "                        [ 7.0791e-03,  2.1263e-02,  1.1972e-02],\n",
       "                        [ 1.1862e-02, -1.0395e-02, -8.7752e-03]],\n",
       "              \n",
       "                       [[-1.0526e-02,  2.9172e-02, -6.8480e-03],\n",
       "                        [ 2.1687e-02, -2.7862e-02,  5.1432e-03],\n",
       "                        [ 1.0745e-02, -2.2633e-02,  6.9299e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.3377e-02, -2.7077e-03, -2.8894e-02],\n",
       "                        [ 2.5832e-02, -1.9196e-02,  1.8431e-02],\n",
       "                        [ 1.0789e-02, -1.8773e-03,  1.1536e-02]],\n",
       "              \n",
       "                       [[ 3.1080e-03,  1.5906e-02,  2.7957e-02],\n",
       "                        [-1.9921e-02, -1.5420e-02, -2.2358e-02],\n",
       "                        [ 3.2442e-03, -1.8841e-02,  2.1828e-02]],\n",
       "              \n",
       "                       [[ 5.5662e-03,  2.4190e-02,  2.0696e-02],\n",
       "                        [ 1.7411e-02,  2.6569e-02, -2.5754e-02],\n",
       "                        [ 1.1668e-02,  1.5156e-02, -2.3456e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 8.9694e-03, -1.3415e-02,  7.0138e-03],\n",
       "                        [-2.4548e-02,  2.9124e-03, -2.6470e-02],\n",
       "                        [-7.1481e-03,  9.1829e-03, -7.1346e-03]],\n",
       "              \n",
       "                       [[-1.1288e-02,  2.2837e-02, -2.5996e-02],\n",
       "                        [ 1.8643e-02, -7.4360e-05,  9.5481e-03],\n",
       "                        [ 4.2807e-03,  1.4242e-02,  1.3276e-02]],\n",
       "              \n",
       "                       [[ 3.1506e-03,  2.4982e-02,  3.4514e-03],\n",
       "                        [-5.2599e-03, -1.3380e-04, -2.7666e-02],\n",
       "                        [-1.3207e-02,  9.4506e-03,  1.1322e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0174e-02, -2.2993e-02, -2.0699e-02],\n",
       "                        [-2.3630e-02, -7.4981e-03, -2.6541e-02],\n",
       "                        [-2.7009e-02, -5.7722e-03, -2.5374e-03]],\n",
       "              \n",
       "                       [[-1.8234e-02, -3.5748e-03, -2.3275e-02],\n",
       "                        [-6.9212e-03,  2.6055e-02, -5.3558e-04],\n",
       "                        [ 2.0359e-02,  1.3523e-02,  4.9272e-04]],\n",
       "              \n",
       "                       [[ 2.2418e-02, -2.8384e-02,  2.6221e-02],\n",
       "                        [ 8.7470e-03, -4.5069e-03,  2.4528e-02],\n",
       "                        [ 5.7874e-03,  1.4460e-02, -5.0008e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4840e-02,  5.1034e-03, -2.0045e-02],\n",
       "                        [-1.3260e-02,  1.1909e-02, -1.6174e-02],\n",
       "                        [-1.7504e-02, -2.9286e-02,  1.2553e-02]],\n",
       "              \n",
       "                       [[-2.6984e-02, -7.7578e-04,  2.7030e-02],\n",
       "                        [-2.9551e-02, -2.1293e-02,  1.3310e-02],\n",
       "                        [ 1.4085e-02, -2.3393e-02, -7.0772e-03]],\n",
       "              \n",
       "                       [[ 1.9855e-02,  3.3751e-03,  2.7498e-02],\n",
       "                        [-1.5743e-02, -1.8343e-02, -3.1789e-03],\n",
       "                        [-4.8500e-03, -1.4179e-03,  9.6693e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-9.0816e-03, -1.5457e-02,  1.4001e-02],\n",
       "                        [-3.0496e-02,  2.0037e-02, -1.1584e-03],\n",
       "                        [ 9.4059e-03, -9.7893e-03, -4.9182e-03]],\n",
       "              \n",
       "                       [[ 3.7133e-03,  4.8994e-04, -8.3001e-03],\n",
       "                        [-1.2433e-02,  2.8616e-02, -1.1120e-02],\n",
       "                        [ 1.6137e-02, -1.8684e-02,  3.3031e-03]],\n",
       "              \n",
       "                       [[-2.2269e-02,  5.1775e-03,  6.5299e-03],\n",
       "                        [ 2.6086e-02,  2.0719e-02,  1.1538e-02],\n",
       "                        [-1.6710e-02,  2.8408e-02,  2.6936e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0687e-02,  2.9244e-02,  2.7578e-02],\n",
       "                        [-7.4294e-03, -5.1046e-03, -2.1871e-02],\n",
       "                        [ 2.5577e-02, -7.4841e-03, -1.0485e-02]],\n",
       "              \n",
       "                       [[-4.1377e-03,  3.6723e-03,  1.2761e-02],\n",
       "                        [-2.5637e-02, -7.7591e-03,  2.4756e-02],\n",
       "                        [-2.6800e-02, -1.4986e-02,  1.3371e-03]],\n",
       "              \n",
       "                       [[ 2.7770e-02, -2.5495e-02,  1.9206e-02],\n",
       "                        [-3.5568e-04, -1.4234e-03,  1.3674e-02],\n",
       "                        [-7.3858e-03, -8.7636e-03, -1.8921e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2168e-02,  2.6162e-02,  7.0709e-04],\n",
       "                        [-1.7235e-02,  1.6249e-02,  1.5399e-02],\n",
       "                        [-2.3672e-02,  9.7573e-03,  1.5754e-02]],\n",
       "              \n",
       "                       [[-2.7589e-02,  2.0772e-02, -2.3896e-02],\n",
       "                        [-2.3761e-02,  8.5190e-03,  1.6340e-02],\n",
       "                        [-2.1796e-02,  1.0248e-02,  2.3080e-02]],\n",
       "              \n",
       "                       [[ 2.5064e-04,  3.4872e-03,  1.1785e-02],\n",
       "                        [-9.1268e-03, -2.5409e-02,  9.6168e-03],\n",
       "                        [ 7.0330e-03,  2.1240e-02, -1.2959e-02]]]], device='cuda:0')),\n",
       "             ('features.8.bias',\n",
       "              tensor([-0.0123, -0.0142, -0.0243, -0.0014, -0.0075, -0.0027, -0.0085, -0.0258,\n",
       "                       0.0281, -0.0238,  0.0291,  0.0033,  0.0110,  0.0118, -0.0198, -0.0078,\n",
       "                      -0.0210, -0.0290,  0.0185, -0.0104, -0.0102,  0.0012, -0.0008,  0.0081,\n",
       "                       0.0081, -0.0191, -0.0098, -0.0245,  0.0201,  0.0142, -0.0160,  0.0197,\n",
       "                       0.0201, -0.0080, -0.0045,  0.0011,  0.0094, -0.0154,  0.0005,  0.0037,\n",
       "                      -0.0031, -0.0109, -0.0230, -0.0279,  0.0059,  0.0129,  0.0010, -0.0258,\n",
       "                       0.0152,  0.0108, -0.0196, -0.0170,  0.0124,  0.0076, -0.0199,  0.0274,\n",
       "                      -0.0213, -0.0118, -0.0074, -0.0093, -0.0245,  0.0009,  0.0255, -0.0076,\n",
       "                       0.0020, -0.0274, -0.0213, -0.0117, -0.0226,  0.0132, -0.0202, -0.0292,\n",
       "                       0.0124, -0.0269, -0.0234, -0.0160,  0.0290, -0.0284,  0.0003,  0.0113,\n",
       "                       0.0192,  0.0215, -0.0037,  0.0107,  0.0133,  0.0219, -0.0120,  0.0201,\n",
       "                      -0.0048, -0.0065, -0.0203, -0.0054,  0.0152,  0.0104, -0.0081, -0.0176,\n",
       "                      -0.0189,  0.0038,  0.0136, -0.0024,  0.0060, -0.0062,  0.0256, -0.0285,\n",
       "                       0.0078, -0.0182, -0.0024, -0.0106,  0.0105,  0.0083, -0.0053,  0.0073,\n",
       "                       0.0071, -0.0294, -0.0018,  0.0228,  0.0113,  0.0097,  0.0121,  0.0221,\n",
       "                      -0.0215,  0.0184,  0.0194,  0.0015, -0.0126, -0.0131,  0.0203,  0.0061],\n",
       "                     device='cuda:0')),\n",
       "             ('features.9.weight',\n",
       "              tensor([1.0005, 1.0012, 1.0015, 1.0014, 1.0025, 1.0015, 1.0025, 1.0020, 1.0018,\n",
       "                      1.0010, 1.0019, 1.0018, 1.0010, 1.0018, 1.0009, 1.0012, 1.0016, 1.0018,\n",
       "                      1.0024, 1.0027, 1.0031, 1.0032, 1.0016, 1.0021, 1.0021, 1.0011, 1.0018,\n",
       "                      1.0003, 1.0018, 1.0007, 1.0027, 1.0012, 1.0020, 1.0022, 1.0005, 1.0019,\n",
       "                      1.0016, 1.0015, 1.0015, 1.0009, 1.0007, 1.0019, 1.0014, 1.0015, 1.0020,\n",
       "                      1.0013, 1.0014, 1.0025, 1.0019, 1.0022, 1.0018, 1.0007, 1.0007, 1.0025,\n",
       "                      1.0018, 1.0014, 1.0021, 1.0018, 1.0016, 1.0008, 1.0018, 1.0015, 1.0014,\n",
       "                      1.0025, 1.0030, 1.0022, 1.0012, 1.0021, 1.0018, 1.0016, 1.0009, 1.0011,\n",
       "                      1.0025, 1.0011, 1.0024, 1.0016, 1.0017, 1.0028, 1.0011, 1.0024, 1.0014,\n",
       "                      1.0016, 1.0018, 1.0014, 1.0009, 1.0013, 1.0017, 1.0024, 1.0020, 1.0014,\n",
       "                      1.0015, 1.0010, 1.0036, 1.0013, 1.0009, 1.0023, 1.0031, 1.0010, 1.0015,\n",
       "                      1.0007, 1.0024, 1.0017, 1.0021, 1.0021, 1.0020, 1.0010, 1.0012, 1.0005,\n",
       "                      1.0015, 1.0006, 1.0016, 1.0016, 1.0011, 1.0015, 1.0022, 1.0016, 1.0016,\n",
       "                      1.0003, 1.0022, 1.0017, 1.0025, 1.0040, 1.0023, 1.0018, 1.0026, 1.0014,\n",
       "                      1.0007, 1.0011], device='cuda:0')),\n",
       "             ('features.9.bias',\n",
       "              tensor([ 2.1550e-04,  1.2339e-03,  7.1602e-04,  7.1027e-04,  1.5214e-03,\n",
       "                       5.5485e-04,  1.5668e-03,  1.0382e-03,  8.2057e-04,  6.5612e-04,\n",
       "                       9.1667e-04,  9.2382e-04,  5.0720e-04,  7.8228e-04,  5.4527e-04,\n",
       "                       7.6253e-04,  1.0642e-03,  9.5630e-04,  1.3953e-03,  1.4476e-03,\n",
       "                       2.0732e-03,  1.7404e-03,  4.7110e-04,  1.1911e-03,  1.3421e-03,\n",
       "                       9.1901e-04,  9.7274e-04,  1.3400e-04,  6.5719e-04,  2.5205e-05,\n",
       "                       1.8962e-03,  1.1691e-03,  1.4000e-03,  1.3695e-03,  5.6979e-04,\n",
       "                       1.3312e-03,  1.2304e-03,  3.4198e-04,  9.4468e-04,  3.2754e-04,\n",
       "                       6.8822e-04,  8.7564e-04,  1.1344e-03,  8.2434e-04,  1.3763e-03,\n",
       "                       8.0558e-04,  9.5768e-04,  1.1163e-03,  1.0025e-03,  1.0072e-03,\n",
       "                       6.2537e-04, -1.5054e-04,  3.5982e-04,  1.1890e-03,  8.9209e-04,\n",
       "                       7.9306e-04,  1.1469e-03,  1.3127e-03,  9.7250e-04,  3.1836e-04,\n",
       "                       1.3379e-03,  1.9691e-04,  1.1603e-03,  8.0464e-04,  1.6229e-03,\n",
       "                       1.2735e-03,  8.7249e-04,  1.4246e-03,  8.4899e-04,  1.1716e-03,\n",
       "                       4.6591e-04,  4.3386e-04,  1.6108e-03,  6.6783e-04,  1.3991e-03,\n",
       "                       9.6518e-04,  1.0393e-03,  9.2590e-04,  5.6946e-04,  1.5766e-03,\n",
       "                       6.8532e-04,  9.8536e-04,  1.3523e-03,  6.0679e-04,  8.2030e-04,\n",
       "                       9.7813e-04,  4.9313e-04,  1.6418e-03,  6.2066e-04,  9.0385e-04,\n",
       "                       1.2758e-03,  1.4564e-04,  2.1467e-03,  5.1327e-04,  5.1818e-04,\n",
       "                       1.1581e-03,  1.6038e-03,  4.3389e-04,  8.4878e-04,  4.7771e-05,\n",
       "                       1.0915e-03,  9.6718e-04,  9.8442e-04,  1.3361e-03,  9.9810e-04,\n",
       "                       3.2597e-04,  7.8088e-04,  4.0056e-05,  6.8616e-04,  2.5586e-04,\n",
       "                       9.0657e-04,  1.1741e-03,  3.9047e-04,  8.3206e-04,  9.3682e-04,\n",
       "                       1.0494e-03,  7.5773e-04,  1.9367e-04,  1.2401e-03,  7.8403e-04,\n",
       "                       1.2441e-03,  2.8238e-03,  1.2794e-03,  1.1168e-03,  1.7583e-03,\n",
       "                       8.3729e-04,  3.1493e-04,  6.0256e-04], device='cuda:0')),\n",
       "             ('classifier.weight',\n",
       "              tensor([[-0.0040,  0.0060,  0.0062,  ..., -0.0253, -0.0153, -0.0161],\n",
       "                      [ 0.0135,  0.0110, -0.0115,  ..., -0.0134, -0.0049, -0.0145],\n",
       "                      [ 0.0043, -0.0101,  0.0060,  ..., -0.0100, -0.0003,  0.0081],\n",
       "                      ...,\n",
       "                      [ 0.0201,  0.0173, -0.0164,  ...,  0.0003,  0.0044, -0.0140],\n",
       "                      [-0.0110,  0.0119, -0.0028,  ...,  0.0279, -0.0070,  0.0183],\n",
       "                      [ 0.0256, -0.0107, -0.0082,  ..., -0.0188, -0.0048,  0.0177]],\n",
       "                     device='cuda:0')),\n",
       "             ('classifier.bias',\n",
       "              tensor([-0.0126,  0.0153, -0.0088, -0.0032,  0.0054,  0.0150, -0.0053, -0.0210,\n",
       "                       0.0027,  0.0208], device='cuda:0'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of the layers\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_model_weights(model1, model2):\n",
    "    \"\"\"\n",
    "    Compare the weights of two PyTorch models layer by layer using bar charts.\n",
    "    \n",
    "    Args:\n",
    "        model1 (torch.nn.Module): The first model to compare.\n",
    "        model2 (torch.nn.Module): The second model to compare.\n",
    "    \n",
    "    Returns:\n",
    "        None (displays a bar chart of L2 distance and cosine dissimilarity).\n",
    "    \"\"\"\n",
    "    layer_names = []\n",
    "    l2_distances = []\n",
    "    cos_dissimilarities = []\n",
    "    \n",
    "    for (name1, param1), (name2, param2) in zip(model1.named_parameters(), model2.named_parameters()):\n",
    "        if name1 != name2:\n",
    "            raise ValueError(f\"Layer mismatch: {name1} vs {name2}\")\n",
    "        \n",
    "        layer_names.append(name1)\n",
    "        param1_flat = param1.view(-1)\n",
    "        param2_flat = param2.view(-1)\n",
    "        \n",
    "        l2_distance = torch.norm(param1_flat - param2_flat, p=2).item()\n",
    "        l2_distances.append(l2_distance)\n",
    "        \n",
    "        cos_sim = torch.nn.functional.cosine_similarity(param1_flat, param2_flat, dim=0).item()\n",
    "        cos_dissimilarities.append(1 - cos_sim)\n",
    "    \n",
    "    \n",
    "    flat_grad_model1 = flat_dict(filter_trainable_state_dict(model1))\n",
    "    flat_grad_model2 = flat_dict(filter_trainable_state_dict(model2))\n",
    "    layer_names.append(\"all\")\n",
    "    \n",
    "    l2_distance = torch.norm(flat_grad_model1 - flat_grad_model2, p=2).item()\n",
    "    l2_distances.append(l2_distance)\n",
    "        \n",
    "    cos_sim = torch.nn.functional.cosine_similarity(flat_grad_model1, flat_grad_model2, dim=0).item()\n",
    "    cos_dissimilarities.append(1 - cos_sim)\n",
    "    \n",
    "    # Plot results as bar charts\n",
    "    x = np.arange(len(layer_names))  # Layer indices\n",
    "    width = 0.35  # Width of the bars\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    # Bar chart for L2 Distance\n",
    "    ax1.bar(x - width/2, l2_distances, width, label=\"L2 Distance\", color='tab:blue')\n",
    "    ax1.set_xlabel(\"Layer\")\n",
    "    ax1.set_ylabel(\"L2 Distance\", color='tab:blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "    \n",
    "    # Bar chart for Cosine Dissimilarity\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.bar(x + width/2, cos_dissimilarities, width, label=\"Cos Disimilarity\", color='tab:red')\n",
    "    ax2.set_ylabel(\"Cos Disimilarity\", color='tab:red')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "    \n",
    "    # Add layer names to x-axis\n",
    "    plt.xticks(x, layer_names, rotation=45, ha='right')\n",
    "    for tick in ax1.get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "    \n",
    "    # Add legends\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    # Add title and layout adjustments\n",
    "    plt.title(\"Layer-wise L2 Distance and Cosine Dissimilarity (Bar Chart)\")\n",
    "    # fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_model_weights(model1, model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L2 and Cosine distince is small in this attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['0.weight', '0.bias', '1.weight', '1.bias', '2.weight', '2.bias'])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Example model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 5),\n",
    "    nn.BatchNorm1d(5),  # This has buffers (running_mean, running_var) in state_dict but not in parameters\n",
    "    nn.Linear(5, 2)\n",
    ")\n",
    "\n",
    "# Get parameter names (those in model.parameters())\n",
    "param_names = {name for name, param in model.named_parameters()}\n",
    "\n",
    "# Filter state_dict keys that are in param_names\n",
    "filtered_state_dict = {k: v for k, v in model.state_dict().items() if k in param_names}\n",
    "\n",
    "# Display results\n",
    "print(filtered_state_dict.keys())  # Only includes layers that are in model.parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity of A and X: 0.5976142883300781\n",
      "Cosine similarity of B and X: 0.591607928276062\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a reference tensor X\n",
    "X = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# Construct two different tensors A and B that are not scalar multiples but have the same cosine similarity to X\n",
    "A = torch.tensor([2.0, 0.0, 1.0])  \n",
    "B = torch.tensor([1.0, 3.0, 0.0])  \n",
    "\n",
    "# Compute cosine similarities\n",
    "cos_sim_A = F.cosine_similarity(A.unsqueeze(0), X.unsqueeze(0), dim=1)\n",
    "cos_sim_B = F.cosine_similarity(B.unsqueeze(0), X.unsqueeze(0), dim=1)\n",
    "\n",
    "print(f\"Cosine similarity of A and X: {cos_sim_A.item()}\")\n",
    "print(f\"Cosine similarity of B and X: {cos_sim_B.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
