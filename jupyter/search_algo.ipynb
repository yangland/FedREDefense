{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: x = [ 0.9 18.   1.1], f(x) = 9.32\n",
      "Step 2: x = [ 0.9 17.   1.1], f(x) = 4.32\n",
      "Step 3: x = [ 0.9 16.   1.1], f(x) = 1.32\n",
      "Step 4: x = [ 0.9 15.   1.1], f(x) = 0.31999999999999995\n",
      "Step 5: x = [ 0.9 15.   1.1], f(x) = 0.31999999999999995\n",
      "Step 6: x = [ 0.4 15.   1.6], f(x) = 0.02000000000000001\n",
      "Step 7: x = [ 0.4 15.   1.6], f(x) = 0.02000000000000001\n",
      "Step 8: x = [ 0.4 15.   1.6], f(x) = 0.02000000000000001\n",
      "Step 9: x = [ 0.525 15.     1.475], f(x) = 0.0012499999999999968\n",
      "Step 10: x = [ 0.525 15.     1.475], f(x) = 0.0012499999999999968\n",
      "Step 11: x = [ 0.525 15.     1.475], f(x) = 0.0012499999999999968\n",
      "Step 12: x = [ 0.49375 15.       1.50625], f(x) = 7.812500000000083e-05\n",
      "Step 13: x = [ 0.49375 15.       1.50625], f(x) = 7.812500000000083e-05\n",
      "Step 14: x = [ 0.49375 15.       1.50625], f(x) = 7.812500000000083e-05\n",
      "Step 15: x = [ 0.5015625 15.         1.4984375], f(x) = 4.882812499999793e-06\n",
      "Step 16: x = [ 0.5015625 15.         1.4984375], f(x) = 4.882812499999793e-06\n",
      "Step 17: x = [ 0.5015625 15.         1.4984375], f(x) = 4.882812499999793e-06\n",
      "Step 18: x = [ 0.49960938 15.          1.50039063], f(x) = 3.0517578125005205e-07\n",
      "Step 19: x = [ 0.49960938 15.          1.50039063], f(x) = 3.0517578125005205e-07\n",
      "Step 20: x = [ 0.49960938 15.          1.50039063], f(x) = 3.0517578125005205e-07\n",
      "Step 21: x = [ 0.50009766 15.          1.49990234], f(x) = 1.9073486328111987e-08\n",
      "Step 22: x = [ 0.50009766 15.          1.49990234], f(x) = 1.9073486328111987e-08\n",
      "Step 23: x = [ 0.50009766 15.          1.49990234], f(x) = 1.9073486328111987e-08\n",
      "Step 24: x = [ 0.49997559 15.          1.50002441], f(x) = 1.1920928955110652e-09\n",
      "Step 25: x = [ 0.49997559 15.          1.50002441], f(x) = 1.1920928955110652e-09\n",
      "Step 26: x = [ 0.49997559 15.          1.50002441], f(x) = 1.1920928955110652e-09\n",
      "Step 27: x = [ 0.5000061 15.         1.4999939], f(x) = 7.450580596842513e-11\n",
      "Step 28: x = [ 0.5000061 15.         1.4999939], f(x) = 7.450580596842513e-11\n",
      "Step 29: x = [ 0.5000061 15.         1.4999939], f(x) = 7.450580596842513e-11\n",
      "Step 30: x = [ 0.49999847 15.          1.50000153], f(x) = 4.656612873280681e-12\n",
      "Step 31: x = [ 0.49999847 15.          1.50000153], f(x) = 4.656612873280681e-12\n",
      "Step 32: x = [ 0.49999847 15.          1.50000153], f(x) = 4.656612873280681e-12\n",
      "Step 33: x = [ 0.50000038 15.          1.49999962], f(x) = 2.9103830451651506e-13\n",
      "Step 34: x = [ 0.50000038 15.          1.49999962], f(x) = 2.9103830451651506e-13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def objective(x):\n",
    "    a, b, c = x\n",
    "    return (a - 0.5)**2 + (b - 15)**2 + (c - 1.5)**2  # Example function\n",
    "\n",
    "# Bounds for each variable\n",
    "bounds = np.array([[0, 1], [10, 20], [0, 3]])\n",
    "\n",
    "# Initial guess\n",
    "x0 = np.array([0.9, 19, 0.1])\n",
    "\n",
    "def mads(func, x0, bounds, delta=1.0, tol=1e-6, max_iter=100):\n",
    "    \"\"\" Mesh Adaptive Direct Search (MADS) implementation. \"\"\"\n",
    "    n = len(x0)\n",
    "    x = x0.copy()\n",
    "    delta_min = tol\n",
    "    iteration = 0\n",
    "    \n",
    "    while delta > delta_min and iteration < max_iter:\n",
    "        improved = False\n",
    "        \n",
    "        # Generate trial points\n",
    "        for i in range(n):\n",
    "            for direction in [-1, 1]:\n",
    "                x_new = x.copy()\n",
    "                x_new[i] += direction * delta\n",
    "                x_new = np.clip(x_new, bounds[:, 0], bounds[:, 1])  # Enforce bounds\n",
    "                \n",
    "                if func(x_new) < func(x):\n",
    "                    x = x_new\n",
    "                    improved = True\n",
    "        \n",
    "        # Reduce mesh size if no improvement\n",
    "        if not improved:\n",
    "            delta /= 2.0\n",
    "        \n",
    "        iteration += 1\n",
    "        yield x, func(x), iteration\n",
    "\n",
    "# Run MADS optimization\n",
    "mads_iter = mads(objective, x0, bounds)\n",
    "for x, fval, step in mads_iter:\n",
    "    print(f\"Step {step}: x = {x}, f(x) = {fval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MADS:\n",
    "    def __init__(self, x0, bounds, delta=1.0, tol=1e-6, max_iter=100):\n",
    "        self.x = np.array(x0)\n",
    "        self.bounds = np.array(bounds)\n",
    "        self.delta = delta\n",
    "        self.delta_min = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.iteration = 0\n",
    "        self.history = [(self.x.copy(), float('inf'))]  # Store initial point\n",
    "        self.waiting_for_reward = False\n",
    "        self.last_trial = None\n",
    "    \n",
    "    def step(self, reward=None):\n",
    "        \"\"\" Perform one step of MADS. Provide reward when available. \"\"\"\n",
    "        if self.waiting_for_reward:\n",
    "            if reward is None:\n",
    "                raise ValueError(\"Reward must be provided for the last trial step.\")\n",
    "            \n",
    "            # Accept the trial point if the reward is better\n",
    "            if reward < self.history[-1][1]:\n",
    "                self.x = self.last_trial\n",
    "            self.history.append((self.x.copy(), reward))\n",
    "            self.waiting_for_reward = False\n",
    "            \n",
    "        if self.delta <= self.delta_min or self.iteration >= self.max_iter:\n",
    "            return None  # Termination condition\n",
    "        \n",
    "        improved = False\n",
    "        trial_points = []\n",
    "        \n",
    "        for i in range(len(self.x)):\n",
    "            for direction in [-1, 1]:\n",
    "                x_new = self.x.copy()\n",
    "                x_new[i] += direction * self.delta\n",
    "                x_new = np.clip(x_new, self.bounds[:, 0], self.bounds[:, 1])\n",
    "                trial_points.append(x_new)\n",
    "        \n",
    "        self.last_trial = trial_points.pop(0)  # Pick the first trial point\n",
    "        self.waiting_for_reward = True\n",
    "        self.iteration += 1\n",
    "        return self.last_trial\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "bounds = [(0, 1), (10, 20), (0, 3)]\n",
    "x0 = [0.5, 12, 1]\n",
    "mads = MADS(x0, bounds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next = mads.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = (x_next[0] - 0.5)**2 + (x_next[1] - 15)**2 + (x_next[2] - 1.5)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9.5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., 12.,  1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mads.step(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0.5, 12. ,  1. ]), inf), (array([ 0., 12.,  1.]), np.float64(9.5))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mads.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Reward must be provided for the last trial step.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     x_next \u001b[38;5;241m=\u001b[39m \u001b[43mmads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x_next \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m, in \u001b[0;36mMADS.step\u001b[0;34m(self, reward)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwaiting_for_reward:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reward \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReward must be provided for the last trial step.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Accept the trial point if the reward is better\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reward \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]:\n",
      "\u001b[0;31mValueError\u001b[0m: Reward must be provided for the last trial step."
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    x_next = mads.step()\n",
    "    if x_next is None:\n",
    "        break\n",
    "    \n",
    "    # Simulate delayed function evaluation\n",
    "    reward = (x_next[0] - 0.5)**2 + (x_next[1] - 15)**2 + (x_next[2] - 1.5)**2\n",
    "    print(\"x, reward\", x_next, reward)\n",
    "    mads.step(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next [ 0. 12.  1.]\n",
      "9.5\n",
      "x_next None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MADS:\n",
    "    def __init__(self, x0, bounds, delta=1.0, tol=1e-6, max_iter=100):\n",
    "        self.x = np.array(x0)\n",
    "        self.bounds = np.array(bounds)\n",
    "        self.delta = delta\n",
    "        self.delta_min = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.iteration = 0\n",
    "        self.history = []\n",
    "        self.waiting_for_reward = False\n",
    "        self.last_trial = None\n",
    "    \n",
    "    def get_next_trial(self):\n",
    "        \"\"\" Generate the next trial point for evaluation. \"\"\"\n",
    "        if self.waiting_for_reward:\n",
    "            raise RuntimeError(\"Provide a reward for the last trial before requesting a new one.\")\n",
    "        \n",
    "        if self.delta <= self.delta_min or self.iteration >= self.max_iter:\n",
    "            return None  # Termination condition\n",
    "        \n",
    "        trial_points = []\n",
    "        for i in range(len(self.x)):\n",
    "            for direction in [-1, 1]:\n",
    "                x_new = self.x.copy()\n",
    "                x_new[i] += direction * self.delta\n",
    "                x_new = np.clip(x_new, self.bounds[:, 0], self.bounds[:, 1])\n",
    "                trial_points.append(x_new)\n",
    "        \n",
    "        self.last_trial = trial_points.pop(0)  # Pick the first trial point\n",
    "        self.waiting_for_reward = True\n",
    "        return self.last_trial\n",
    "    \n",
    "    def update_with_reward(self, reward):\n",
    "        \"\"\" Update the MADS algorithm with the reward from the last trial. \"\"\"\n",
    "        if not self.waiting_for_reward:\n",
    "            raise RuntimeError(\"No trial is pending a reward update.\")\n",
    "        \n",
    "        if not self.history or reward < self.history[-1][1]:\n",
    "            self.x = self.last_trial\n",
    "        \n",
    "        self.history.append((self.x.copy(), reward))\n",
    "        self.waiting_for_reward = False\n",
    "        self.iteration += 1\n",
    "        \n",
    "        if not any(reward < r for _, r in self.history):\n",
    "            self.delta /= 2.0  # Reduce the mesh size if no improvement\n",
    "\n",
    "# Example usage:\n",
    "bounds = [(0, 1), (10, 20), (0, 3)]\n",
    "x0 = [0.5, 12, 1]\n",
    "mads = MADS(x0, bounds)\n",
    "\n",
    "while True:\n",
    "    x_next = mads.get_next_trial()\n",
    "    print(\"x_next\",x_next)\n",
    "    if x_next is None:\n",
    "        break\n",
    "    \n",
    "    # Simulate delayed function evaluation\n",
    "    reward = (x_next[0] - 0.5)**2 + (x_next[1] - 15)**2 + (x_next[2] - 1.5)**2\n",
    "    print(reward)\n",
    "    mads.update_with_reward(reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n",
      "x_next [ 0.5 12.   0. ] 11.25\n",
      "x_next [ 0.5 12.   2. ] 9.25\n",
      "x_next [ 0. 12.  1.] 9.5\n",
      "x_next [ 1. 12.  1.] 9.5\n",
      "x_next [ 0.5 11.   1. ] 16.25\n",
      "x_next [ 0.5 13.   1. ] 4.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MADS:\n",
    "    def __init__(self, x0, bounds, delta=1.0, tol=1e-6, max_iter=100):\n",
    "        self.x = np.array(x0)\n",
    "        self.bounds = np.array(bounds)\n",
    "        self.delta = delta\n",
    "        self.delta_min = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.iteration = 0\n",
    "        self.history = []\n",
    "        self.waiting_for_reward = False\n",
    "        self.last_trial = None\n",
    "        self.trial_queue = []\n",
    "    \n",
    "    def get_next_trial(self):\n",
    "        \"\"\" Generate the next trial point for evaluation. \"\"\"\n",
    "        if self.waiting_for_reward:\n",
    "            raise RuntimeError(\"Provide a reward for the last trial before requesting a new one.\")\n",
    "        \n",
    "        if self.delta <= self.delta_min or self.iteration >= self.max_iter:\n",
    "            return None  # Termination condition\n",
    "        \n",
    "        if not self.trial_queue:\n",
    "            # Generate new trial points only when the queue is empty\n",
    "            for i in range(len(self.x)):\n",
    "                for direction in [-1, 1]:\n",
    "                    x_new = self.x.copy()\n",
    "                    x_new[i] += direction * self.delta\n",
    "                    x_new = np.clip(x_new, self.bounds[:, 0], self.bounds[:, 1])\n",
    "                    self.trial_queue.append(x_new)\n",
    "        \n",
    "        self.last_trial = self.trial_queue.pop(0)  # Pick the next trial point\n",
    "        self.waiting_for_reward = True\n",
    "        return self.last_trial\n",
    "    \n",
    "    def update_with_reward(self, reward):\n",
    "        \"\"\" Update the MADS algorithm with the reward from the last trial. \"\"\"\n",
    "        if not self.waiting_for_reward:\n",
    "            raise RuntimeError(\"No trial is pending a reward update.\")\n",
    "        \n",
    "        self.history.append((self.last_trial.copy(), reward))\n",
    "        if not self.history or reward < min(r for _, r in self.history):\n",
    "            self.x = self.last_trial  # Accept the trial if it improves\n",
    "        \n",
    "        self.waiting_for_reward = False\n",
    "        self.iteration += 1\n",
    "        \n",
    "        if not self.trial_queue and all(reward >= r for _, r in self.history[-len(self.x)*2:]):\n",
    "            self.delta /= 2.0  # Reduce the mesh size if no improvement\n",
    "\n",
    "# Example usage:\n",
    "bounds = [(0, 1), (10, 20), (0, 3)]\n",
    "x0 = [0.5, 12, 1]\n",
    "mads = MADS(x0, bounds)\n",
    "\n",
    "while True:\n",
    "    x_next = mads.get_next_trial()\n",
    "    if x_next is None:\n",
    "        break\n",
    "    \n",
    "    # Simulate delayed function evaluation\n",
    "    reward = (x_next[0] - 0.5)**2 + (x_next[1] - 15)**2 + (x_next[2] - 1.5)**2\n",
    "    print(\"x_next\", x_next, reward)\n",
    "    mads.update_with_reward(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.lower()==\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
